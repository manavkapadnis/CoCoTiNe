{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HiCoTiNe1 v3 MNIST.ipynb","provenance":[{"file_id":"19guF-U3KgRWG2yOuNYWGUTWs2FP2582B","timestamp":1615843192315}],"collapsed_sections":[],"authorship_tag":"ABX9TyP71ob2pVXNqK/hTX5/RLOd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OVQ7Bo8hJIUb"},"source":["# Variants-Experiment 3.1, 3.2, 3.3.1, 3.3.2. Adapted from HiCoTiNe v2.1\n","## Concatenated hidden representations.\n","## No raw input"]},{"cell_type":"code","metadata":{"id":"AW5zp22ze_5Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620323956479,"user_tz":-480,"elapsed":1384,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"70adfb2a-001f-4139-ff62-5924f441f243"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten\n","from keras.datasets import mnist\n","from keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import random\n","from scipy import stats\n","from sklearn.metrics import accuracy_score\n","from keras import backend as K\n","\n","import os\n","import pickle\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pL2zNY1Pqo43"},"source":["SUB_REGION_SCALE = 14\n","NUM_HICO_LAYER = 5\n","NUM_TN = [10, 8, 6 , 4, 2]\n","NUM_CONNECTION = [0, 5, 4, 3, 2]\n","ALPHA = 0.1\n","\n","#dataset specific parameters\n","NUM_CLASS = 10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sV1QzfMXoD_c"},"source":["## Data Pre-Processing"]},{"cell_type":"code","metadata":{"id":"CK8Jo8eFjW0R"},"source":["with open('/content/drive/My Drive/fyp/MNIST.pickle', 'rb') as f:\n","    X_train_cropped_list, y_train_one_hot, X_test_cropped_list, y_test_one_hot, coordinate_list, scale_list = pickle.load(f)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NYkFwl7RbAnt"},"source":["## HiCo Layer 1"]},{"cell_type":"code","metadata":{"id":"mZxSK0dGZsGo"},"source":["#build ANN model\n","ensemble = []\n","for i in range(NUM_TN[0]):\n","  model = Sequential()\n","  model.add(Dense(64, activation='relu', input_dim=SUB_REGION_SCALE*SUB_REGION_SCALE))\n","  model.add(Dense(64, activation='relu'))\n","  model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","  ensemble.append((model, i, coordinate_list[i], scale_list[i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2K4jfWOkcSz"},"source":["for i in range(NUM_TN[0]):\n","  ensemble[i][0].load_weights('/content/drive/My Drive/fyp/MNIST_' + str(i) + '.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-r3DBZWMb9eX"},"source":["hico_layers = []\n","hico_layers.append(ensemble)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AKc-KKMj278"},"source":["del hico_layers[1:]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CvSwQtBibHqz"},"source":["## HiCo Layer 2+"]},{"cell_type":"code","metadata":{"id":"MCxjRA6lqoaA"},"source":["# Function to get input of layer i-1\n","def get_previous_layer_input(hico_layers, layer, tn, train_image):\n","  input = []\n","    \n","  if layer == 0:\n","    previous_layer_input = train_image[tn[1]]\n","    return previous_layer_input\n","\n","  elif layer > 0:\n","    for i in range(NUM_CONNECTION[layer]):\n","      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[1].output))\n","      input.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n","      \n","    input = np.array(input)\n","    input = np.concatenate(input, axis=1)\n","    previous_layer_input = input\n","    return previous_layer_input"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZLXI5D6lneY","executionInfo":{"status":"ok","timestamp":1620324174172,"user_tz":-480,"elapsed":219030,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"adee5dee-9a96-4185-dbbf-402bb87b0cc6"},"source":["for i in range(1, NUM_HICO_LAYER):\n","  print('Layer %d' %i)\n","  ensemble = []\n","  X_train_input_list = []\n","  X_test_input_list = []\n","\n","  for j in range(NUM_TN[i]):\n","    # Build model of HiCo layer i\n","    connection = tuple(random.sample(range(len(hico_layers[i-1])), k=NUM_CONNECTION[i]))\n","    model = Sequential()\n","    model.add(Dense(64, activation='relu', input_dim=64*NUM_CONNECTION[i]))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    ensemble.append((model, connection))\n","  hico_layers.append(ensemble)\n","  print('HICO LENGTH')\n","  print(len(hico_layers))\n","\n","  for j in range(NUM_TN[i]):\n","    # Get train hidden representation from HiCo layer i-1\n","    X_train_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_train_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n","    X_train_input = np.array(X_train_input)\n","    X_train_input = np.concatenate(X_train_input, axis=1)\n","    X_train_input_list.append(X_train_input)\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    X_test_input_list.append(X_test_input)\n","\n","  #train model of HiCo layer i\n","  for j in range(NUM_TN[i]):\n","    print('Model %d' %j)\n","    hico_layers[i][j][0].fit(X_train_input_list[j], y_train_one_hot, validation_data=(X_test_input_list[j], y_test_one_hot), epochs=5, batch_size=128)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Layer 1\n","HICO LENGTH\n","2\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4268 - accuracy: 0.8706 - val_loss: 0.0907 - val_accuracy: 0.9700\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0821 - accuracy: 0.9744 - val_loss: 0.0754 - val_accuracy: 0.9767\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0722 - accuracy: 0.9780 - val_loss: 0.0743 - val_accuracy: 0.9755\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9798 - val_loss: 0.0698 - val_accuracy: 0.9780\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0573 - accuracy: 0.9815 - val_loss: 0.0672 - val_accuracy: 0.9787\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4072 - accuracy: 0.8813 - val_loss: 0.0785 - val_accuracy: 0.9759\n","Epoch 2/5\n","469/469 [==============================] - 2s 4ms/step - loss: 0.0737 - accuracy: 0.9773 - val_loss: 0.0795 - val_accuracy: 0.9773\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0673 - accuracy: 0.9799 - val_loss: 0.0626 - val_accuracy: 0.9808\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0575 - accuracy: 0.9816 - val_loss: 0.0750 - val_accuracy: 0.9769\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0517 - accuracy: 0.9835 - val_loss: 0.0627 - val_accuracy: 0.9793\n","Model 2\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3914 - accuracy: 0.8873 - val_loss: 0.0802 - val_accuracy: 0.9759\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0775 - accuracy: 0.9752 - val_loss: 0.0750 - val_accuracy: 0.9771\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0671 - accuracy: 0.9783 - val_loss: 0.0678 - val_accuracy: 0.9789\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0615 - accuracy: 0.9808 - val_loss: 0.0775 - val_accuracy: 0.9769\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0588 - accuracy: 0.9818 - val_loss: 0.0676 - val_accuracy: 0.9800\n","Model 3\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3838 - accuracy: 0.8842 - val_loss: 0.0789 - val_accuracy: 0.9744\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0795 - accuracy: 0.9753 - val_loss: 0.0739 - val_accuracy: 0.9765\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0653 - accuracy: 0.9791 - val_loss: 0.0609 - val_accuracy: 0.9805\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0557 - accuracy: 0.9820 - val_loss: 0.0578 - val_accuracy: 0.9816\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0551 - accuracy: 0.9818 - val_loss: 0.0528 - val_accuracy: 0.9830\n","Model 4\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4090 - accuracy: 0.8784 - val_loss: 0.0994 - val_accuracy: 0.9672\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.1017 - accuracy: 0.9673 - val_loss: 0.1087 - val_accuracy: 0.9639\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0859 - accuracy: 0.9719 - val_loss: 0.0867 - val_accuracy: 0.9723\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0774 - accuracy: 0.9753 - val_loss: 0.0886 - val_accuracy: 0.9718\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0708 - accuracy: 0.9761 - val_loss: 0.0838 - val_accuracy: 0.9720\n","Model 5\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4979 - accuracy: 0.8645 - val_loss: 0.0798 - val_accuracy: 0.9748\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0714 - accuracy: 0.9785 - val_loss: 0.0649 - val_accuracy: 0.9798\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9815 - val_loss: 0.0598 - val_accuracy: 0.9815\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0561 - accuracy: 0.9824 - val_loss: 0.0718 - val_accuracy: 0.9776\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0492 - accuracy: 0.9852 - val_loss: 0.0611 - val_accuracy: 0.9809\n","Model 6\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3782 - accuracy: 0.8925 - val_loss: 0.0820 - val_accuracy: 0.9746\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0739 - accuracy: 0.9765 - val_loss: 0.0649 - val_accuracy: 0.9798\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0674 - accuracy: 0.9796 - val_loss: 0.0657 - val_accuracy: 0.9798\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0567 - accuracy: 0.9821 - val_loss: 0.0612 - val_accuracy: 0.9814\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.0766 - val_accuracy: 0.9760\n","Model 7\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.4301 - accuracy: 0.8802 - val_loss: 0.0920 - val_accuracy: 0.9709\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.9747 - val_loss: 0.0840 - val_accuracy: 0.9745\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0759 - accuracy: 0.9764 - val_loss: 0.0765 - val_accuracy: 0.9746\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0638 - accuracy: 0.9799 - val_loss: 0.0728 - val_accuracy: 0.9773\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0626 - accuracy: 0.9797 - val_loss: 0.0738 - val_accuracy: 0.9760\n","Layer 2\n","HICO LENGTH\n","3\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.2672 - accuracy: 0.9337 - val_loss: 0.0542 - val_accuracy: 0.9833\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.0514 - val_accuracy: 0.9860\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0392 - accuracy: 0.9872 - val_loss: 0.0510 - val_accuracy: 0.9856\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0383 - accuracy: 0.9876 - val_loss: 0.0590 - val_accuracy: 0.9817\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0332 - accuracy: 0.9893 - val_loss: 0.0471 - val_accuracy: 0.9855\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.2612 - accuracy: 0.9270 - val_loss: 0.0626 - val_accuracy: 0.9804\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0407 - accuracy: 0.9868 - val_loss: 0.0493 - val_accuracy: 0.9842\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0372 - accuracy: 0.9883 - val_loss: 0.0500 - val_accuracy: 0.9847\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0369 - accuracy: 0.9884 - val_loss: 0.0524 - val_accuracy: 0.9840\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0346 - accuracy: 0.9891 - val_loss: 0.0507 - val_accuracy: 0.9845\n","Model 2\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.2510 - accuracy: 0.9390 - val_loss: 0.0546 - val_accuracy: 0.9824\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0423 - accuracy: 0.9865 - val_loss: 0.0599 - val_accuracy: 0.9816\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0404 - accuracy: 0.9871 - val_loss: 0.0511 - val_accuracy: 0.9835\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0395 - accuracy: 0.9872 - val_loss: 0.0566 - val_accuracy: 0.9826\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0356 - accuracy: 0.9886 - val_loss: 0.0518 - val_accuracy: 0.9843\n","Model 3\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.3122 - accuracy: 0.9270 - val_loss: 0.0531 - val_accuracy: 0.9834\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0412 - accuracy: 0.9875 - val_loss: 0.0559 - val_accuracy: 0.9832\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0382 - accuracy: 0.9878 - val_loss: 0.0520 - val_accuracy: 0.9843\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0393 - accuracy: 0.9871 - val_loss: 0.0582 - val_accuracy: 0.9822\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0358 - accuracy: 0.9886 - val_loss: 0.0516 - val_accuracy: 0.9850\n","Model 4\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.2215 - accuracy: 0.9421 - val_loss: 0.0521 - val_accuracy: 0.9831\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0433 - accuracy: 0.9869 - val_loss: 0.0599 - val_accuracy: 0.9824\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.0611 - val_accuracy: 0.9822\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0359 - accuracy: 0.9884 - val_loss: 0.0586 - val_accuracy: 0.9815\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0329 - accuracy: 0.9893 - val_loss: 0.0641 - val_accuracy: 0.9809\n","Model 5\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.2867 - accuracy: 0.9308 - val_loss: 0.0504 - val_accuracy: 0.9849\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0449 - accuracy: 0.9864 - val_loss: 0.0491 - val_accuracy: 0.9846\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0395 - accuracy: 0.9877 - val_loss: 0.0512 - val_accuracy: 0.9842\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0364 - accuracy: 0.9878 - val_loss: 0.0478 - val_accuracy: 0.9848\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.0461 - val_accuracy: 0.9857\n","Layer 3\n","HICO LENGTH\n","4\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.2328 - accuracy: 0.9393 - val_loss: 0.0473 - val_accuracy: 0.9866\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.0532 - val_accuracy: 0.9846\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0304 - accuracy: 0.9905 - val_loss: 0.0507 - val_accuracy: 0.9845\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9909 - val_loss: 0.0513 - val_accuracy: 0.9851\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.0488 - val_accuracy: 0.9858\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.2813 - accuracy: 0.9348 - val_loss: 0.0507 - val_accuracy: 0.9848\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 0.0510 - val_accuracy: 0.9853\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0311 - accuracy: 0.9903 - val_loss: 0.0484 - val_accuracy: 0.9865\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0283 - accuracy: 0.9910 - val_loss: 0.0486 - val_accuracy: 0.9860\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.0485 - val_accuracy: 0.9874\n","Model 2\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.2387 - accuracy: 0.9385 - val_loss: 0.0466 - val_accuracy: 0.9866\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 0.0510 - val_accuracy: 0.9847\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0295 - accuracy: 0.9910 - val_loss: 0.0535 - val_accuracy: 0.9846\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0306 - accuracy: 0.9900 - val_loss: 0.0498 - val_accuracy: 0.9856\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0485 - val_accuracy: 0.9854\n","Model 3\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.2418 - accuracy: 0.9342 - val_loss: 0.0502 - val_accuracy: 0.9859\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0309 - accuracy: 0.9903 - val_loss: 0.0480 - val_accuracy: 0.9856\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0298 - accuracy: 0.9904 - val_loss: 0.0503 - val_accuracy: 0.9861\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.0487 - val_accuracy: 0.9847\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0268 - accuracy: 0.9914 - val_loss: 0.0500 - val_accuracy: 0.9849\n","Layer 4\n","HICO LENGTH\n","5\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 2s 2ms/step - loss: 0.3036 - accuracy: 0.9321 - val_loss: 0.0503 - val_accuracy: 0.9867\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0279 - accuracy: 0.9916 - val_loss: 0.0563 - val_accuracy: 0.9846\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0255 - accuracy: 0.9917 - val_loss: 0.0520 - val_accuracy: 0.9863\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0500 - val_accuracy: 0.9847\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.0505 - val_accuracy: 0.9869\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 2s 2ms/step - loss: 0.2489 - accuracy: 0.9381 - val_loss: 0.0481 - val_accuracy: 0.9871\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0264 - accuracy: 0.9923 - val_loss: 0.0493 - val_accuracy: 0.9855\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0256 - accuracy: 0.9917 - val_loss: 0.0512 - val_accuracy: 0.9855\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0254 - accuracy: 0.9921 - val_loss: 0.0491 - val_accuracy: 0.9857\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9921 - val_loss: 0.0510 - val_accuracy: 0.9859\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4ZCjVj0ioNb6"},"source":["## Model Evaluation"]},{"cell_type":"code","metadata":{"id":"hn8WGeu-rl-U"},"source":["y_test = np.argmax(y_test_one_hot, axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5hLPV9-XgZcY"},"source":["### HiCoTiNe1 v3.1\n","cc1. Mode. Compute classifications of all tiny networks, in all HiCo layers, and take the mode as the final classification."]},{"cell_type":"code","metadata":{"id":"-wsBlIBONSIN"},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = np.argmax(hico_layers[0][j][0].predict(X_test_cropped_list[j]), axis=1)\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = np.argmax(hico_layers[i][j][0].predict(X_test_input), axis=1)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0))\n","y_pred_list = stats.mode(y_pred_list, axis=1)[0]\n","y_pred_list = np.squeeze(y_pred_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZ6nor6wRK_k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620324199024,"user_tz":-480,"elapsed":243865,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"b1de84df-907e-4151-8982-4e0fe6946be2"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9863"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"kSjNM3tzg4C9"},"source":["### HiCoTiNe v3.2\n","cc2. Sum the logits of all TNs. Take the max logit as the final classification."]},{"cell_type":"code","metadata":{"id":"7AKpmhMtg-IX"},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = hico_layers[0][j][0].predict(X_test_cropped_list[j])\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = hico_layers[i][j][0].predict(X_test_input)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0, 2))\n","y_pred_list = np.argmax(np.sum(y_pred_list, axis=1), axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3AmcOiQh4QM","executionInfo":{"status":"ok","timestamp":1620324222640,"user_tz":-480,"elapsed":267470,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"9a4d6743-60c6-4f38-db5e-ce1c51f1e3f6"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9865"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"EvqdeEpVo0IU"},"source":["### HiCoTiNe v3.3.1\n","cc3. Weighted function. Compute classifications (votes) of all tiny networks, in all HiCo layers. Compute weight of each classifier/vote. Compute weighted sum of votes. Weights can be computed in different ways, e.g.:\n","- cc3w1. The weight of each classifier/TN is inversely proportional to the number of TNs in its HiCo layer, relative to the HiCo layer with the most TNs. E.g. if n is the number of TNs in the layer with the most TNs, then compute v/n for each layer, where v is the number of TNs in each layer; then compute the weight of each layer as (1+alpha)-(v/n), where alpha is some small threshold; and finally define the weight of each TN as the weight of its layer.\n"]},{"cell_type":"code","metadata":{"id":"1E2-2iH5pIzI"},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = hico_layers[0][j][0].predict(X_test_cropped_list[j])\n","  y_pred = y_pred * ((1 + ALPHA) - (NUM_TN[0] / max(NUM_TN)))\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = hico_layers[i][j][0].predict(X_test_input)\n","    y_pred = y_pred * ((1 + ALPHA) - (NUM_TN[i] / max(NUM_TN)))\n","    y_pred_list.append(y_pred)\n","\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0, 2))\n","y_pred_list = np.argmax(np.sum(y_pred_list, axis=1), axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K2HPvU_NvSvT","executionInfo":{"status":"ok","timestamp":1620327814214,"user_tz":-480,"elapsed":1022,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"3a3491c5-cbc2-462c-cc79-7f778e58be8b"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9871"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"markdown","metadata":{"id":"lCCv0nO9pJnb"},"source":["### HiCoTiNe v3.3.2\n","cc3. Weighted function. Compute classifications (votes) of all tiny networks, in all HiCo layers. Compute weight of each classifier/vote. Compute weighted sum of votes. Weights can be computed in different ways, e.g.:\n","- cc3w2. The weight of each classifier is directly proportional to the depth of the HiCo layer within which it resides. \n"]},{"cell_type":"code","metadata":{"id":"YqBbgiRqpQeC"},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = hico_layers[0][j][0].predict(X_test_cropped_list[j])\n","  y_pred = y_pred * (1 / NUM_HICO_LAYER)\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = hico_layers[i][j][0].predict(X_test_input)\n","    y_pred = y_pred * (i / NUM_HICO_LAYER)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0, 2))\n","y_pred_list = np.argmax(np.sum(y_pred_list, axis=1), axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfK2nrhzdX-e","executionInfo":{"status":"ok","timestamp":1620327734015,"user_tz":-480,"elapsed":1395,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"2b54f509-5715-483a-983f-650f2af5d5cc"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9867"]},"metadata":{"tags":[]},"execution_count":45}]}]}