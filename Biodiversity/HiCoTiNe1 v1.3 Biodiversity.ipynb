{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Variants-Experiment 1.3\n\n## Concatenated hidden representations and summed output logits.\n## Mode. Compute classifications of all tiny networks, in all HiCo layers, and take the mode as the final classification.\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom os import listdir\nfrom os.path import join\nimport cv2\nimport pandas as pd\nimport os\nimport random as rn\nfrom scipy import stats\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport pickle\nfrom keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:57:35.190621Z","iopub.execute_input":"2021-07-12T17:57:35.191008Z","iopub.status.idle":"2021-07-12T17:57:35.200799Z","shell.execute_reply.started":"2021-07-12T17:57:35.190971Z","shell.execute_reply":"2021-07-12T17:57:35.199719Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"SEED = 321\nrn.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:57:35.202237Z","iopub.execute_input":"2021-07-12T17:57:35.202730Z","iopub.status.idle":"2021-07-12T17:57:35.210640Z","shell.execute_reply.started":"2021-07-12T17:57:35.202695Z","shell.execute_reply":"2021-07-12T17:57:35.209496Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"SUB_REGION_SCALE = 14\nNUM_HICO_LAYER = 5\nNUM_TN = [10, 8, 6, 4, 2]\nNUM_CONNECTION = [0, 5, 4, 3, 2]\n\n#dataset specific parameters\nNUM_CLASS = 5","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:57:35.212010Z","iopub.execute_input":"2021-07-12T17:57:35.212540Z","iopub.status.idle":"2021-07-12T17:57:35.219973Z","shell.execute_reply.started":"2021-07-12T17:57:35.212495Z","shell.execute_reply":"2021-07-12T17:57:35.218844Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"with open('../input/hicotine1-layer1-biodiversity/fyp/CIFAR-10.pickle', 'rb') as f:\n    X_train_cropped_list, y_train_one_hot, X_val_cropped_list, y_val_one_hot, X_test_cropped_list, y_test_one_hot, coordinate_list, scale_list = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:57:37.968485Z","iopub.execute_input":"2021-07-12T17:57:37.968799Z","iopub.status.idle":"2021-07-12T17:57:39.937006Z","shell.execute_reply.started":"2021-07-12T17:57:37.968771Z","shell.execute_reply":"2021-07-12T17:57:39.936145Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## HiCo Layer 1","metadata":{}},{"cell_type":"code","source":"#build ANN model\nensemble = []\nfor i in range(NUM_TN[0]):\n  model = Sequential()\n  model.add(Dense(64, activation='relu', input_dim=SUB_REGION_SCALE*SUB_REGION_SCALE*3))\n  model.add(Dense(64, activation='relu'))\n  model.add(Dense(NUM_CLASS, activation = 'softmax'))\n  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n  ensemble.append((model, i, coordinate_list[i], scale_list[i]))","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:57:48.768070Z","iopub.execute_input":"2021-07-12T17:57:48.768413Z","iopub.status.idle":"2021-07-12T17:57:50.917759Z","shell.execute_reply.started":"2021-07-12T17:57:48.768381Z","shell.execute_reply":"2021-07-12T17:57:50.916971Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for i in range(NUM_TN[0]):\n  ensemble[i][0].load_weights('../input/hicotine1-layer1-biodiversity/fyp/CIFAR-10_' + str(i) + '.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:57:50.921055Z","iopub.execute_input":"2021-07-12T17:57:50.921311Z","iopub.status.idle":"2021-07-12T17:57:51.119194Z","shell.execute_reply.started":"2021-07-12T17:57:50.921286Z","shell.execute_reply":"2021-07-12T17:57:51.118398Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"hico_layers = []\nhico_layers.append(ensemble)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:57:51.120826Z","iopub.execute_input":"2021-07-12T17:57:51.121179Z","iopub.status.idle":"2021-07-12T17:57:51.127267Z","shell.execute_reply.started":"2021-07-12T17:57:51.121143Z","shell.execute_reply":"2021-07-12T17:57:51.126569Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"del hico_layers[1:]","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:57:57.196941Z","iopub.execute_input":"2021-07-12T17:57:57.197257Z","iopub.status.idle":"2021-07-12T17:57:57.203371Z","shell.execute_reply.started":"2021-07-12T17:57:57.197228Z","shell.execute_reply":"2021-07-12T17:57:57.202415Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## HiCo Layer 2+","metadata":{}},{"cell_type":"code","source":"# Function to get input of layer i-1\ndef get_previous_layer_input(hico_layers, layer, tn, train_image):\n  input_hr = []\n  input_ol = []\n    \n  if layer == 0:\n    previous_layer_input = train_image[tn[1]]\n    return previous_layer_input\n\n  elif layer > 0:\n    for i in range(NUM_CONNECTION[layer]):\n      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[1].output))\n      input_hr.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n      \n    input_hr = np.array(input_hr)\n    input_hr = np.concatenate(input_hr, axis=1)\n\n    for i in range(NUM_CONNECTION[layer]):\n      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[2].output))\n      input_ol.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n\n    input_ol = np.array(input_ol)\n    input_ol = np.sum(input_ol, axis=0)\n\n    input = np.concatenate((input_hr, input_ol), axis=1)\n    \n    previous_layer_input = input\n    return previous_layer_input","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:58:12.978530Z","iopub.execute_input":"2021-07-12T17:58:12.978851Z","iopub.status.idle":"2021-07-12T17:58:13.135761Z","shell.execute_reply.started":"2021-07-12T17:58:12.978821Z","shell.execute_reply":"2021-07-12T17:58:13.134450Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"for i in range(1, NUM_HICO_LAYER):\n  print('Layer %d' %i)\n  ensemble = []\n  X_train_input_list = []\n  X_test_input_list = []\n\n  for j in range(NUM_TN[i]):\n    # Build model of HiCo layer i\n    connection = tuple(rn.sample(range(len(hico_layers[i-1])), k=NUM_CONNECTION[i]))\n    model = Sequential()\n    model.add(Dense(64, activation='relu', input_dim=64*NUM_CONNECTION[i]+NUM_CLASS))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(NUM_CLASS, activation = 'softmax'))\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    ensemble.append((model, connection))\n  hico_layers.append(ensemble)\n  print('HICO LENGTH')\n  print(len(hico_layers))\n\n  for j in range(NUM_TN[i]):\n    # Get train hidden representation from HiCo layer i-1\n    X_train_input_hr = []\n    X_train_input_ol = []\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n      X_train_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n    X_train_input_hr = np.array(X_train_input_hr)\n    X_train_input_hr = np.concatenate(X_train_input_hr, axis=1)\n\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n      X_train_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n    X_train_input_ol = np.array(X_train_input_ol)\n    X_train_input_ol = np.sum(X_train_input_ol, axis=0)\n\n    X_train_input = np.concatenate((X_train_input_hr, X_train_input_ol), axis=1)\n    X_train_input_list.append(X_train_input)\n\n    # Get test hidden representation from HiCo layer i-1\n    X_test_input_hr = []\n    X_test_input_ol = []\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n      X_test_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n    X_test_input_hr = np.array(X_test_input_hr)\n    X_test_input_hr = np.concatenate(X_test_input_hr, axis=1)\n\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n      X_test_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n    X_test_input_ol = np.array(X_test_input_ol)\n    X_test_input_ol = np.sum(X_test_input_ol, axis=0)\n\n    X_test_input = np.concatenate((X_test_input_hr, X_test_input_ol), axis=1)\n    X_test_input_list.append(X_test_input)\n\n  #train model of HiCo layer i\n  for j in range(NUM_TN[i]):\n    print('Model %d' %j)\n    hico_layers[i][j][0].fit(X_train_input_list[j], y_train_one_hot, validation_data=(X_test_input_list[j], y_test_one_hot), epochs=5, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:58:50.271378Z","iopub.execute_input":"2021-07-12T17:58:50.271708Z","iopub.status.idle":"2021-07-12T18:00:25.147740Z","shell.execute_reply.started":"2021-07-12T17:58:50.271680Z","shell.execute_reply":"2021-07-12T18:00:25.146808Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Layer 1\nHICO LENGTH\n2\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 21ms/step - loss: 1.5583 - accuracy: 0.3052 - val_loss: 1.3062 - val_accuracy: 0.4134\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2418 - accuracy: 0.4558 - val_loss: 1.2652 - val_accuracy: 0.4527\nEpoch 3/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.2330 - accuracy: 0.4738 - val_loss: 1.2672 - val_accuracy: 0.4388\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2026 - accuracy: 0.4929 - val_loss: 1.2483 - val_accuracy: 0.4734\nEpoch 5/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.1513 - accuracy: 0.5034 - val_loss: 1.2529 - val_accuracy: 0.4180\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.5305 - accuracy: 0.3086 - val_loss: 1.3040 - val_accuracy: 0.3972\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2340 - accuracy: 0.4518 - val_loss: 1.2633 - val_accuracy: 0.4480\nEpoch 3/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.2331 - accuracy: 0.4692 - val_loss: 1.2790 - val_accuracy: 0.4342\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1965 - accuracy: 0.4978 - val_loss: 1.2534 - val_accuracy: 0.4573\nEpoch 5/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.1469 - accuracy: 0.5065 - val_loss: 1.2613 - val_accuracy: 0.4619\nModel 2\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4700 - accuracy: 0.3660 - val_loss: 1.3123 - val_accuracy: 0.4249\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2382 - accuracy: 0.4513 - val_loss: 1.2731 - val_accuracy: 0.4273\nEpoch 3/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.2312 - accuracy: 0.4714 - val_loss: 1.2781 - val_accuracy: 0.4596\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2128 - accuracy: 0.4911 - val_loss: 1.2581 - val_accuracy: 0.4573\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1619 - accuracy: 0.4945 - val_loss: 1.2611 - val_accuracy: 0.4342\nModel 3\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.5038 - accuracy: 0.3095 - val_loss: 1.3179 - val_accuracy: 0.4088\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2431 - accuracy: 0.4505 - val_loss: 1.2785 - val_accuracy: 0.4411\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2282 - accuracy: 0.4774 - val_loss: 1.2834 - val_accuracy: 0.4457\nEpoch 4/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.2027 - accuracy: 0.4904 - val_loss: 1.2563 - val_accuracy: 0.4388\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1662 - accuracy: 0.5006 - val_loss: 1.2630 - val_accuracy: 0.4342\nModel 4\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.5039 - accuracy: 0.3090 - val_loss: 1.3199 - val_accuracy: 0.4226\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2309 - accuracy: 0.4520 - val_loss: 1.2807 - val_accuracy: 0.4573\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2301 - accuracy: 0.4832 - val_loss: 1.2779 - val_accuracy: 0.4550\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1985 - accuracy: 0.4913 - val_loss: 1.2600 - val_accuracy: 0.4480\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1557 - accuracy: 0.5119 - val_loss: 1.2625 - val_accuracy: 0.4642\nModel 5\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.5573 - accuracy: 0.2905 - val_loss: 1.3067 - val_accuracy: 0.4111\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2455 - accuracy: 0.4375 - val_loss: 1.2912 - val_accuracy: 0.4550\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2423 - accuracy: 0.4582 - val_loss: 1.3049 - val_accuracy: 0.4619\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2255 - accuracy: 0.4772 - val_loss: 1.2601 - val_accuracy: 0.4711\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1765 - accuracy: 0.4861 - val_loss: 1.2755 - val_accuracy: 0.4434\nModel 6\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4633 - accuracy: 0.3606 - val_loss: 1.3241 - val_accuracy: 0.3972\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2109 - accuracy: 0.4689 - val_loss: 1.2849 - val_accuracy: 0.4527\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2151 - accuracy: 0.4815 - val_loss: 1.2991 - val_accuracy: 0.4619\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1825 - accuracy: 0.4955 - val_loss: 1.2680 - val_accuracy: 0.4619\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1405 - accuracy: 0.5077 - val_loss: 1.2559 - val_accuracy: 0.4503\nModel 7\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.4711 - accuracy: 0.3503 - val_loss: 1.3160 - val_accuracy: 0.4319\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2308 - accuracy: 0.4491 - val_loss: 1.2624 - val_accuracy: 0.4457\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2232 - accuracy: 0.4940 - val_loss: 1.2732 - val_accuracy: 0.4550\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1975 - accuracy: 0.4899 - val_loss: 1.2452 - val_accuracy: 0.4527\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1583 - accuracy: 0.5028 - val_loss: 1.2418 - val_accuracy: 0.4896\nLayer 2\nHICO LENGTH\n3\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.5181 - accuracy: 0.3274 - val_loss: 1.2768 - val_accuracy: 0.4296\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1758 - accuracy: 0.4869 - val_loss: 1.2580 - val_accuracy: 0.4550\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1855 - accuracy: 0.5048 - val_loss: 1.2600 - val_accuracy: 0.4619\nEpoch 4/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.1534 - accuracy: 0.5278 - val_loss: 1.2439 - val_accuracy: 0.4642\nEpoch 5/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.5298 - val_loss: 1.2553 - val_accuracy: 0.4388\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.5152 - accuracy: 0.3123 - val_loss: 1.2751 - val_accuracy: 0.4411\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1718 - accuracy: 0.5165 - val_loss: 1.2463 - val_accuracy: 0.4758\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1756 - accuracy: 0.5184 - val_loss: 1.2512 - val_accuracy: 0.4781\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1388 - accuracy: 0.5395 - val_loss: 1.2478 - val_accuracy: 0.4827\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1003 - accuracy: 0.5413 - val_loss: 1.2521 - val_accuracy: 0.4665\nModel 2\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.4951 - accuracy: 0.3551 - val_loss: 1.2729 - val_accuracy: 0.4550\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1743 - accuracy: 0.4907 - val_loss: 1.2537 - val_accuracy: 0.4919\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1729 - accuracy: 0.5081 - val_loss: 1.2574 - val_accuracy: 0.4665\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1503 - accuracy: 0.5261 - val_loss: 1.2410 - val_accuracy: 0.4781\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1003 - accuracy: 0.5379 - val_loss: 1.2494 - val_accuracy: 0.4596\nModel 3\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.5038 - accuracy: 0.3496 - val_loss: 1.2802 - val_accuracy: 0.4342\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1829 - accuracy: 0.4971 - val_loss: 1.2482 - val_accuracy: 0.4619\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1865 - accuracy: 0.5024 - val_loss: 1.2516 - val_accuracy: 0.4457\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1591 - accuracy: 0.5270 - val_loss: 1.2330 - val_accuracy: 0.4619\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1093 - accuracy: 0.5364 - val_loss: 1.2460 - val_accuracy: 0.4573\nModel 4\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.4715 - accuracy: 0.3715 - val_loss: 1.2825 - val_accuracy: 0.4180\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1864 - accuracy: 0.4839 - val_loss: 1.2539 - val_accuracy: 0.4873\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1803 - accuracy: 0.5099 - val_loss: 1.2524 - val_accuracy: 0.4573\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1478 - accuracy: 0.5169 - val_loss: 1.2375 - val_accuracy: 0.4827\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1031 - accuracy: 0.5324 - val_loss: 1.2353 - val_accuracy: 0.4850\nModel 5\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.4464 - accuracy: 0.3785 - val_loss: 1.2879 - val_accuracy: 0.4411\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1698 - accuracy: 0.4933 - val_loss: 1.2640 - val_accuracy: 0.4873\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1766 - accuracy: 0.5150 - val_loss: 1.2639 - val_accuracy: 0.4619\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1497 - accuracy: 0.5257 - val_loss: 1.2570 - val_accuracy: 0.4665\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1045 - accuracy: 0.5308 - val_loss: 1.2561 - val_accuracy: 0.4480\nLayer 3\nHICO LENGTH\n4\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.4303 - accuracy: 0.3825 - val_loss: 1.2634 - val_accuracy: 0.4665\nEpoch 2/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.1506 - accuracy: 0.5201 - val_loss: 1.2456 - val_accuracy: 0.4965\nEpoch 3/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.1426 - accuracy: 0.5280 - val_loss: 1.2471 - val_accuracy: 0.4711\nEpoch 4/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.1199 - accuracy: 0.5475 - val_loss: 1.2347 - val_accuracy: 0.4873\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0739 - accuracy: 0.5621 - val_loss: 1.2472 - val_accuracy: 0.4665\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 11ms/step - loss: 1.5937 - accuracy: 0.3542 - val_loss: 1.2711 - val_accuracy: 0.4550\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1413 - accuracy: 0.5286 - val_loss: 1.2433 - val_accuracy: 0.4665\nEpoch 3/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.1437 - accuracy: 0.5342 - val_loss: 1.2385 - val_accuracy: 0.4665\nEpoch 4/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.1182 - accuracy: 0.5474 - val_loss: 1.2372 - val_accuracy: 0.4965\nEpoch 5/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.0757 - accuracy: 0.5479 - val_loss: 1.2449 - val_accuracy: 0.4480\nModel 2\nEpoch 1/5\n28/28 [==============================] - 1s 10ms/step - loss: 1.4785 - accuracy: 0.3583 - val_loss: 1.2808 - val_accuracy: 0.4573\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1381 - accuracy: 0.5381 - val_loss: 1.2465 - val_accuracy: 0.4734\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1393 - accuracy: 0.5269 - val_loss: 1.2442 - val_accuracy: 0.4688\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1234 - accuracy: 0.5413 - val_loss: 1.2410 - val_accuracy: 0.4804\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0811 - accuracy: 0.5548 - val_loss: 1.2529 - val_accuracy: 0.4573\nModel 3\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.3645 - accuracy: 0.4083 - val_loss: 1.2552 - val_accuracy: 0.4965\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1376 - accuracy: 0.5304 - val_loss: 1.2347 - val_accuracy: 0.4850\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1436 - accuracy: 0.5352 - val_loss: 1.2427 - val_accuracy: 0.4781\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1208 - accuracy: 0.5402 - val_loss: 1.2346 - val_accuracy: 0.4965\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0774 - accuracy: 0.5587 - val_loss: 1.2369 - val_accuracy: 0.4550\nLayer 4\nHICO LENGTH\n5\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.4461 - accuracy: 0.3976 - val_loss: 1.2531 - val_accuracy: 0.4896\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1228 - accuracy: 0.5538 - val_loss: 1.2526 - val_accuracy: 0.4850\nEpoch 3/5\n28/28 [==============================] - 0s 3ms/step - loss: 1.1341 - accuracy: 0.5421 - val_loss: 1.2535 - val_accuracy: 0.4734\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1078 - accuracy: 0.5431 - val_loss: 1.2509 - val_accuracy: 0.4873\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0711 - accuracy: 0.5561 - val_loss: 1.2596 - val_accuracy: 0.4596\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.4140 - accuracy: 0.3992 - val_loss: 1.2590 - val_accuracy: 0.4734\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1221 - accuracy: 0.5490 - val_loss: 1.2473 - val_accuracy: 0.4850\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1271 - accuracy: 0.5489 - val_loss: 1.2483 - val_accuracy: 0.4688\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1052 - accuracy: 0.5465 - val_loss: 1.2451 - val_accuracy: 0.5081\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0692 - accuracy: 0.5576 - val_loss: 1.2503 - val_accuracy: 0.4596\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Predict on test image\ny_pred_list = []\nfor j in range(NUM_TN[0]):\n  y_pred = np.argmax(hico_layers[0][j][0].predict(X_test_cropped_list[j]), axis=1)\n  y_pred_list.append(y_pred)\n\nfor i in range(1, NUM_HICO_LAYER):\n  for j in range(NUM_TN[i]):\n\n    # Get test hidden representation from HiCo layer i-1\n    X_test_input_hr = []\n    X_test_input_ol = []\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n      X_test_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n    X_test_input_hr = np.array(X_test_input_hr)\n    X_test_input_hr = np.concatenate(X_test_input_hr, axis=1)\n\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n      X_test_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n    X_test_input_ol = np.array(X_test_input_ol)\n    X_test_input_ol = np.sum(X_test_input_ol, axis=0)\n\n    X_test_input = np.concatenate((X_test_input_hr, X_test_input_ol), axis=1)\n\n    y_pred = np.argmax(hico_layers[i][j][0].predict(X_test_input), axis=1)\n    y_pred_list.append(y_pred)\n\n# HiCo voting (mode)\ny_pred_list = np.array(y_pred_list)\ny_pred_list = np.transpose(y_pred_list, (1, 0))\ny_pred_list = stats.mode(y_pred_list, axis=1)[0]\ny_pred_list = np.squeeze(y_pred_list)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:00:25.149634Z","iopub.execute_input":"2021-07-12T18:00:25.149956Z","iopub.status.idle":"2021-07-12T18:00:55.725375Z","shell.execute_reply.started":"2021-07-12T18:00:25.149921Z","shell.execute_reply":"2021-07-12T18:00:55.724526Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"y_test = np.argmax(y_test_one_hot, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:00:55.726928Z","iopub.execute_input":"2021-07-12T18:00:55.727235Z","iopub.status.idle":"2021-07-12T18:00:55.730665Z","shell.execute_reply.started":"2021-07-12T18:00:55.727200Z","shell.execute_reply":"2021-07-12T18:00:55.729871Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred_list)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:00:55.731978Z","iopub.execute_input":"2021-07-12T18:00:55.732468Z","iopub.status.idle":"2021-07-12T18:00:55.748615Z","shell.execute_reply.started":"2021-07-12T18:00:55.732425Z","shell.execute_reply":"2021-07-12T18:00:55.747639Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"0.4618937644341801"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}