{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BC 4\n## Flat ensemble of tiny networks\n## Input = whole image","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom os import listdir\nfrom os.path import join\nimport cv2\nimport pandas as pd\nimport os\nimport random as rn\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:24:40.437432Z","iopub.execute_input":"2021-07-12T17:24:40.437817Z","iopub.status.idle":"2021-07-12T17:24:45.388731Z","shell.execute_reply.started":"2021-07-12T17:24:40.437739Z","shell.execute_reply":"2021-07-12T17:24:45.387921Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"SEED = 321\nrn.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:24:45.390056Z","iopub.execute_input":"2021-07-12T17:24:45.390362Z","iopub.status.idle":"2021-07-12T17:24:45.396775Z","shell.execute_reply.started":"2021-07-12T17:24:45.390329Z","shell.execute_reply":"2021-07-12T17:24:45.395000Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"NUM_TN = 30\n\n#dataset specific parameters\nNUM_CLASS = 5\nSCALE = 32","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:24:45.398938Z","iopub.execute_input":"2021-07-12T17:24:45.399288Z","iopub.status.idle":"2021-07-12T17:24:45.404202Z","shell.execute_reply.started":"2021-07-12T17:24:45.399255Z","shell.execute_reply":"2021-07-12T17:24:45.403084Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = \"../input/flowers-recognition/flowers/\"\nfolders = os.listdir(data)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:24:45.406172Z","iopub.execute_input":"2021-07-12T17:24:45.406708Z","iopub.status.idle":"2021-07-12T17:24:45.419420Z","shell.execute_reply.started":"2021-07-12T17:24:45.406672Z","shell.execute_reply":"2021-07-12T17:24:45.418749Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"image_names = []\ntrain_labels = []\ntrain_images = []\n\nsize = 32,32\n\nfor folder in folders:\n    for file in os.listdir(os.path.join(data,folder)):\n        if file.endswith(\"jpg\"):\n            image_names.append(os.path.join(data,folder,file))\n            train_labels.append(folder)\n            img = cv2.imread(os.path.join(data,folder,file))\n            im = cv2.resize(img,size)\n            train_images.append(im)\n        else:\n            continue","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:24:45.420612Z","iopub.execute_input":"2021-07-12T17:24:45.420937Z","iopub.status.idle":"2021-07-12T17:25:14.921811Z","shell.execute_reply.started":"2021-07-12T17:24:45.420905Z","shell.execute_reply":"2021-07-12T17:25:14.920935Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train = np.array(train_images)\ntrain = train.astype('float32')\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:25:14.923116Z","iopub.execute_input":"2021-07-12T17:25:14.923449Z","iopub.status.idle":"2021-07-12T17:25:14.954096Z","shell.execute_reply.started":"2021-07-12T17:25:14.923415Z","shell.execute_reply":"2021-07-12T17:25:14.953096Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(4323, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# Train, Val, Test split = 0.8, 0.1, 0.1 of the dataset\nX_train,X_val,y_train,y_val = train_test_split(train,train_labels, test_size = 0.2)\nX_val,X_test,y_val,y_test = train_test_split(X_val,y_val, test_size = 0.5)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:25:14.955523Z","iopub.execute_input":"2021-07-12T17:25:14.955866Z","iopub.status.idle":"2021-07-12T17:25:14.985326Z","shell.execute_reply.started":"2021-07-12T17:25:14.955831Z","shell.execute_reply":"2021-07-12T17:25:14.984542Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"#Generate subset of train image\nX_train_subset_list = []\ny_train_subset_list = []\ntrain_zipped = zip(X_train, y_train)\ntrain_zipped = np.array(tuple(train_zipped))\n\nfor i in range(NUM_TN):\n  train_zipped_subset = rn.choices(train_zipped, k=int(len(train_zipped)*60/100))\n  X_train_subset = []\n  y_train_subset = []\n  for a in train_zipped_subset:\n    X_train_subset.append(a[0])\n    y_train_subset.append(a[1])\n  X_train_subset = np.array(X_train_subset)\n  y_train_subset = np.array(y_train_subset)\n\n  X_train_subset_list.append(X_train_subset)\n  y_train_subset_list.append(y_train_subset)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:25:14.986623Z","iopub.execute_input":"2021-07-12T17:25:14.986961Z","iopub.status.idle":"2021-07-12T17:25:15.353236Z","shell.execute_reply.started":"2021-07-12T17:25:14.986927Z","shell.execute_reply":"2021-07-12T17:25:15.352254Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n  \"\"\"\n","output_type":"stream"}]},{"cell_type":"code","source":"#normalizing dataset\nfor i in range(NUM_TN):\n    X_train_subset_list[i] = X_train_subset_list[i]/255\n\nX_test = X_test/255\nX_val = X_val/255","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:25:15.355664Z","iopub.execute_input":"2021-07-12T17:25:15.356015Z","iopub.status.idle":"2021-07-12T17:25:15.603011Z","shell.execute_reply.started":"2021-07-12T17:25:15.355978Z","shell.execute_reply":"2021-07-12T17:25:15.602149Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#transform to vector\nfor i in range(NUM_TN):\n    X_train_subset_list[i] = X_train_subset_list[i].reshape((-1, SCALE*SCALE*3))\n\nX_val = X_val.reshape((-1, SCALE*SCALE*3))\nX_test = X_test.reshape((-1, SCALE*SCALE*3))","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:25:15.604618Z","iopub.execute_input":"2021-07-12T17:25:15.604954Z","iopub.status.idle":"2021-07-12T17:25:15.610390Z","shell.execute_reply.started":"2021-07-12T17:25:15.604918Z","shell.execute_reply":"2021-07-12T17:25:15.609475Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#one-hot encoding\nfor i in range(NUM_TN):\n    y_train_subset_list[i] = pd.get_dummies(y_train_subset_list[i])\n    y_train_subset_list[i] = y_train_subset_list[i].values.argmax(1)\n    y_train_subset_list[i] = to_categorical(y_train_subset_list[i])\n    \n\ny_val_one_hot = pd.get_dummies(y_val)\ny_val_one_hot = y_val_one_hot.values.argmax(1)\ny_val_one_hot = to_categorical(y_val_one_hot)\n\ny_test_one_hot = pd.get_dummies(y_test)\ny_test_one_hot = y_test_one_hot.values.argmax(1)\ny_test_one_hot = to_categorical(y_test_one_hot)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:25:15.611714Z","iopub.execute_input":"2021-07-12T17:25:15.612290Z","iopub.status.idle":"2021-07-12T17:25:15.661977Z","shell.execute_reply.started":"2021-07-12T17:25:15.612253Z","shell.execute_reply":"2021-07-12T17:25:15.661288Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"#build ANN model\nensemble = []\nfor i in range(NUM_TN):\n    model = Sequential()\n    model.add(Dense(64, activation='relu', input_dim=SCALE*SCALE*3))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(NUM_CLASS, activation = 'softmax'))\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    ensemble.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:25:15.663050Z","iopub.execute_input":"2021-07-12T17:25:15.663369Z","iopub.status.idle":"2021-07-12T17:25:18.545234Z","shell.execute_reply.started":"2021-07-12T17:25:15.663336Z","shell.execute_reply":"2021-07-12T17:25:18.544362Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#train model\nhistory = []\nfor i in range(NUM_TN):\n    print()\n    print('Model %d' %i)\n    hist = ensemble[i].fit(X_train_subset_list[i], y_train_subset_list[i], validation_data=(X_val, y_val_one_hot), epochs=5, batch_size=128)\n    history.append(hist)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:25:18.546553Z","iopub.execute_input":"2021-07-12T17:25:18.546883Z","iopub.status.idle":"2021-07-12T17:25:49.410164Z","shell.execute_reply.started":"2021-07-12T17:25:18.546849Z","shell.execute_reply":"2021-07-12T17:25:49.409369Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\nModel 0\nEpoch 1/5\n17/17 [==============================] - 2s 35ms/step - loss: 1.6261 - accuracy: 0.2690 - val_loss: 1.4881 - val_accuracy: 0.3796\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.4344 - accuracy: 0.3764 - val_loss: 1.3779 - val_accuracy: 0.4074\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3157 - accuracy: 0.4420 - val_loss: 1.2614 - val_accuracy: 0.4444\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2362 - accuracy: 0.4661 - val_loss: 1.3057 - val_accuracy: 0.4375\nEpoch 5/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2315 - accuracy: 0.4711 - val_loss: 1.2651 - val_accuracy: 0.4514\n\nModel 1\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.6431 - accuracy: 0.2451 - val_loss: 1.4429 - val_accuracy: 0.3611\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.4269 - accuracy: 0.3592 - val_loss: 1.3505 - val_accuracy: 0.4491\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3146 - accuracy: 0.4333 - val_loss: 1.2741 - val_accuracy: 0.4491\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2394 - accuracy: 0.4704 - val_loss: 1.2304 - val_accuracy: 0.4630\nEpoch 5/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.1825 - accuracy: 0.4808 - val_loss: 1.2174 - val_accuracy: 0.4676\n\nModel 2\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.5580 - accuracy: 0.3028 - val_loss: 1.3979 - val_accuracy: 0.4097\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3787 - accuracy: 0.4182 - val_loss: 1.2856 - val_accuracy: 0.4421\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2566 - accuracy: 0.4647 - val_loss: 1.2655 - val_accuracy: 0.4190\nEpoch 4/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1916 - accuracy: 0.4834 - val_loss: 1.2315 - val_accuracy: 0.4537\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1507 - accuracy: 0.5195 - val_loss: 1.2066 - val_accuracy: 0.4630\n\nModel 3\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.5923 - accuracy: 0.2720 - val_loss: 1.3998 - val_accuracy: 0.4259\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3546 - accuracy: 0.4300 - val_loss: 1.2334 - val_accuracy: 0.4745\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2211 - accuracy: 0.4771 - val_loss: 1.3672 - val_accuracy: 0.4306\nEpoch 4/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1970 - accuracy: 0.4957 - val_loss: 1.2354 - val_accuracy: 0.4444\nEpoch 5/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.1384 - accuracy: 0.5206 - val_loss: 1.2118 - val_accuracy: 0.4838\n\nModel 4\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.5655 - accuracy: 0.2947 - val_loss: 1.4333 - val_accuracy: 0.4028\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3582 - accuracy: 0.4278 - val_loss: 1.2666 - val_accuracy: 0.4282\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2527 - accuracy: 0.4545 - val_loss: 1.2391 - val_accuracy: 0.4583\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2049 - accuracy: 0.4746 - val_loss: 1.2100 - val_accuracy: 0.4769\nEpoch 5/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.0971 - accuracy: 0.5336 - val_loss: 1.1964 - val_accuracy: 0.4792\n\nModel 5\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.6721 - accuracy: 0.2717 - val_loss: 1.3958 - val_accuracy: 0.3981\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3466 - accuracy: 0.4243 - val_loss: 1.2829 - val_accuracy: 0.4306\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2377 - accuracy: 0.4711 - val_loss: 1.2537 - val_accuracy: 0.4491\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.1964 - accuracy: 0.5052 - val_loss: 1.2870 - val_accuracy: 0.4352\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1636 - accuracy: 0.4940 - val_loss: 1.2879 - val_accuracy: 0.4144\n\nModel 6\nEpoch 1/5\n17/17 [==============================] - 1s 13ms/step - loss: 1.6415 - accuracy: 0.2644 - val_loss: 1.4544 - val_accuracy: 0.3889\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.4275 - accuracy: 0.3814 - val_loss: 1.3762 - val_accuracy: 0.3866\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.3204 - accuracy: 0.4074 - val_loss: 1.3090 - val_accuracy: 0.4514\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2688 - accuracy: 0.4486 - val_loss: 1.3084 - val_accuracy: 0.4074\nEpoch 5/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.1801 - accuracy: 0.5083 - val_loss: 1.2587 - val_accuracy: 0.4167\n\nModel 7\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.6029 - accuracy: 0.2821 - val_loss: 1.4769 - val_accuracy: 0.3426\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3813 - accuracy: 0.3737 - val_loss: 1.2796 - val_accuracy: 0.4306\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2341 - accuracy: 0.4640 - val_loss: 1.2479 - val_accuracy: 0.4583\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.1701 - accuracy: 0.4899 - val_loss: 1.2299 - val_accuracy: 0.4560\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1506 - accuracy: 0.5087 - val_loss: 1.2284 - val_accuracy: 0.4329\n\nModel 8\nEpoch 1/5\n17/17 [==============================] - 1s 21ms/step - loss: 1.6144 - accuracy: 0.2774 - val_loss: 1.4828 - val_accuracy: 0.3171\nEpoch 2/5\n17/17 [==============================] - 0s 9ms/step - loss: 1.4396 - accuracy: 0.3518 - val_loss: 1.3548 - val_accuracy: 0.4074\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3374 - accuracy: 0.4484 - val_loss: 1.2699 - val_accuracy: 0.4907\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2463 - accuracy: 0.4444 - val_loss: 1.2710 - val_accuracy: 0.4491\nEpoch 5/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2231 - accuracy: 0.4695 - val_loss: 1.2532 - val_accuracy: 0.4537\n\nModel 9\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.5856 - accuracy: 0.2922 - val_loss: 1.4007 - val_accuracy: 0.3426\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3928 - accuracy: 0.3894 - val_loss: 1.3224 - val_accuracy: 0.4282\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2861 - accuracy: 0.4233 - val_loss: 1.2552 - val_accuracy: 0.4213\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.1969 - accuracy: 0.4819 - val_loss: 1.3115 - val_accuracy: 0.4329\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1631 - accuracy: 0.5228 - val_loss: 1.2276 - val_accuracy: 0.4583\n\nModel 10\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.5561 - accuracy: 0.2711 - val_loss: 1.3575 - val_accuracy: 0.4583\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3388 - accuracy: 0.4274 - val_loss: 1.3604 - val_accuracy: 0.3912\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2733 - accuracy: 0.4606 - val_loss: 1.3225 - val_accuracy: 0.4306\nEpoch 4/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1857 - accuracy: 0.5090 - val_loss: 1.3219 - val_accuracy: 0.4144\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1623 - accuracy: 0.5143 - val_loss: 1.3153 - val_accuracy: 0.4005\n\nModel 11\nEpoch 1/5\n17/17 [==============================] - 1s 26ms/step - loss: 1.6576 - accuracy: 0.2603 - val_loss: 1.4284 - val_accuracy: 0.3634\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3851 - accuracy: 0.3947 - val_loss: 1.3749 - val_accuracy: 0.3796\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3032 - accuracy: 0.4371 - val_loss: 1.2838 - val_accuracy: 0.4398\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2067 - accuracy: 0.4932 - val_loss: 1.2721 - val_accuracy: 0.4537\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1529 - accuracy: 0.5182 - val_loss: 1.2530 - val_accuracy: 0.4537\n\nModel 12\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.6792 - accuracy: 0.2504 - val_loss: 1.4446 - val_accuracy: 0.4167\nEpoch 2/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.4119 - accuracy: 0.4000 - val_loss: 1.3289 - val_accuracy: 0.4329\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.3111 - accuracy: 0.4062 - val_loss: 1.2602 - val_accuracy: 0.4792\nEpoch 4/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2695 - accuracy: 0.4278 - val_loss: 1.2562 - val_accuracy: 0.4421\nEpoch 5/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2172 - accuracy: 0.4713 - val_loss: 1.2177 - val_accuracy: 0.4977\n\nModel 13\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.7820 - accuracy: 0.2572 - val_loss: 1.4254 - val_accuracy: 0.3657\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.4346 - accuracy: 0.3769 - val_loss: 1.3778 - val_accuracy: 0.3542\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.3198 - accuracy: 0.4281 - val_loss: 1.2913 - val_accuracy: 0.4167\nEpoch 4/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2852 - accuracy: 0.4543 - val_loss: 1.2684 - val_accuracy: 0.4653\nEpoch 5/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2191 - accuracy: 0.4740 - val_loss: 1.2403 - val_accuracy: 0.4537\n\nModel 14\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.6289 - accuracy: 0.2691 - val_loss: 1.5633 - val_accuracy: 0.2847\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.4554 - accuracy: 0.3841 - val_loss: 1.3278 - val_accuracy: 0.4375\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2866 - accuracy: 0.4702 - val_loss: 1.3053 - val_accuracy: 0.4514\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2145 - accuracy: 0.4851 - val_loss: 1.2330 - val_accuracy: 0.4815\nEpoch 5/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.1659 - accuracy: 0.5283 - val_loss: 1.2297 - val_accuracy: 0.4653\n\nModel 15\nEpoch 1/5\n17/17 [==============================] - 1s 13ms/step - loss: 1.6110 - accuracy: 0.2754 - val_loss: 1.4304 - val_accuracy: 0.3704\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3486 - accuracy: 0.4364 - val_loss: 1.3249 - val_accuracy: 0.4282\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2306 - accuracy: 0.4846 - val_loss: 1.3876 - val_accuracy: 0.4097\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2231 - accuracy: 0.5006 - val_loss: 1.2531 - val_accuracy: 0.4514\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1175 - accuracy: 0.5564 - val_loss: 1.2344 - val_accuracy: 0.4537\n\nModel 16\nEpoch 1/5\n17/17 [==============================] - 1s 13ms/step - loss: 1.6983 - accuracy: 0.2503 - val_loss: 1.4657 - val_accuracy: 0.4074\nEpoch 2/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.4397 - accuracy: 0.3851 - val_loss: 1.3473 - val_accuracy: 0.4051\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.3228 - accuracy: 0.4473 - val_loss: 1.2836 - val_accuracy: 0.4282\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2559 - accuracy: 0.4603 - val_loss: 1.2396 - val_accuracy: 0.4745\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1981 - accuracy: 0.5097 - val_loss: 1.2367 - val_accuracy: 0.4699\n\nModel 17\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.6038 - accuracy: 0.2682 - val_loss: 1.3895 - val_accuracy: 0.4167\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3669 - accuracy: 0.3947 - val_loss: 1.2578 - val_accuracy: 0.4444\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2552 - accuracy: 0.4351 - val_loss: 1.2192 - val_accuracy: 0.4653\nEpoch 4/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1942 - accuracy: 0.5016 - val_loss: 1.2447 - val_accuracy: 0.4653\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1347 - accuracy: 0.5433 - val_loss: 1.2658 - val_accuracy: 0.4537\n\nModel 18\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.6073 - accuracy: 0.2592 - val_loss: 1.4256 - val_accuracy: 0.3935\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.4001 - accuracy: 0.3840 - val_loss: 1.3251 - val_accuracy: 0.4537\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2959 - accuracy: 0.4442 - val_loss: 1.2618 - val_accuracy: 0.4630\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2177 - accuracy: 0.4951 - val_loss: 1.2431 - val_accuracy: 0.4606\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1559 - accuracy: 0.5366 - val_loss: 1.2186 - val_accuracy: 0.4630\n\nModel 19\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.6862 - accuracy: 0.2364 - val_loss: 1.4449 - val_accuracy: 0.4097\nEpoch 2/5\n17/17 [==============================] - 0s 10ms/step - loss: 1.3875 - accuracy: 0.4237 - val_loss: 1.3638 - val_accuracy: 0.3843\nEpoch 3/5\n17/17 [==============================] - 0s 8ms/step - loss: 1.3177 - accuracy: 0.4536 - val_loss: 1.3514 - val_accuracy: 0.3981\nEpoch 4/5\n17/17 [==============================] - 0s 8ms/step - loss: 1.2646 - accuracy: 0.4544 - val_loss: 1.3174 - val_accuracy: 0.4236\nEpoch 5/5\n17/17 [==============================] - 0s 7ms/step - loss: 1.2142 - accuracy: 0.4926 - val_loss: 1.3083 - val_accuracy: 0.4028\n\nModel 20\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.5818 - accuracy: 0.3044 - val_loss: 1.3533 - val_accuracy: 0.4306\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3441 - accuracy: 0.4335 - val_loss: 1.3002 - val_accuracy: 0.4583\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2657 - accuracy: 0.4588 - val_loss: 1.2145 - val_accuracy: 0.5069\nEpoch 4/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1826 - accuracy: 0.4870 - val_loss: 1.2861 - val_accuracy: 0.4468\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1481 - accuracy: 0.5295 - val_loss: 1.2877 - val_accuracy: 0.4282\n\nModel 21\nEpoch 1/5\n17/17 [==============================] - 1s 15ms/step - loss: 1.5797 - accuracy: 0.2698 - val_loss: 1.4934 - val_accuracy: 0.3426\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3910 - accuracy: 0.3955 - val_loss: 1.2754 - val_accuracy: 0.4653\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2476 - accuracy: 0.4881 - val_loss: 1.2342 - val_accuracy: 0.4699\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2086 - accuracy: 0.5094 - val_loss: 1.2744 - val_accuracy: 0.4375\nEpoch 5/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.1616 - accuracy: 0.5208 - val_loss: 1.2252 - val_accuracy: 0.4630\n\nModel 22\nEpoch 1/5\n17/17 [==============================] - 1s 22ms/step - loss: 1.7272 - accuracy: 0.2158 - val_loss: 1.5421 - val_accuracy: 0.3264\nEpoch 2/5\n17/17 [==============================] - 0s 9ms/step - loss: 1.4936 - accuracy: 0.3492 - val_loss: 1.4287 - val_accuracy: 0.4074\nEpoch 3/5\n17/17 [==============================] - 0s 9ms/step - loss: 1.3816 - accuracy: 0.4127 - val_loss: 1.3403 - val_accuracy: 0.3912\nEpoch 4/5\n17/17 [==============================] - 0s 9ms/step - loss: 1.3104 - accuracy: 0.4300 - val_loss: 1.2911 - val_accuracy: 0.4259\nEpoch 5/5\n17/17 [==============================] - 0s 9ms/step - loss: 1.2489 - accuracy: 0.4756 - val_loss: 1.2267 - val_accuracy: 0.4769\n\nModel 23\nEpoch 1/5\n17/17 [==============================] - 1s 15ms/step - loss: 1.7468 - accuracy: 0.2203 - val_loss: 1.4965 - val_accuracy: 0.3472\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.4512 - accuracy: 0.3804 - val_loss: 1.3937 - val_accuracy: 0.3819\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3662 - accuracy: 0.4056 - val_loss: 1.3079 - val_accuracy: 0.4491\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2750 - accuracy: 0.4945 - val_loss: 1.2721 - val_accuracy: 0.4583\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2086 - accuracy: 0.4807 - val_loss: 1.2351 - val_accuracy: 0.4560\n\nModel 24\nEpoch 1/5\n17/17 [==============================] - 1s 13ms/step - loss: 1.6698 - accuracy: 0.2331 - val_loss: 1.4215 - val_accuracy: 0.3958\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3725 - accuracy: 0.4136 - val_loss: 1.3175 - val_accuracy: 0.4167\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2749 - accuracy: 0.4532 - val_loss: 1.2450 - val_accuracy: 0.4560\nEpoch 4/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1883 - accuracy: 0.5107 - val_loss: 1.2042 - val_accuracy: 0.4769\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1656 - accuracy: 0.5136 - val_loss: 1.1963 - val_accuracy: 0.4792\n\nModel 25\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.6355 - accuracy: 0.2374 - val_loss: 1.3920 - val_accuracy: 0.4005\nEpoch 2/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.3660 - accuracy: 0.4189 - val_loss: 1.3544 - val_accuracy: 0.4167\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.3212 - accuracy: 0.4271 - val_loss: 1.3360 - val_accuracy: 0.4213\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2540 - accuracy: 0.4856 - val_loss: 1.2594 - val_accuracy: 0.4537\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2037 - accuracy: 0.4810 - val_loss: 1.2122 - val_accuracy: 0.5093\n\nModel 26\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.5940 - accuracy: 0.2768 - val_loss: 1.4104 - val_accuracy: 0.3958\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.4148 - accuracy: 0.3759 - val_loss: 1.3582 - val_accuracy: 0.4005\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.3071 - accuracy: 0.4458 - val_loss: 1.2988 - val_accuracy: 0.4144\nEpoch 4/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2257 - accuracy: 0.4917 - val_loss: 1.3753 - val_accuracy: 0.4259\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2076 - accuracy: 0.5028 - val_loss: 1.2816 - val_accuracy: 0.4398\n\nModel 27\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.6415 - accuracy: 0.2523 - val_loss: 1.4115 - val_accuracy: 0.4051\nEpoch 2/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.3792 - accuracy: 0.4127 - val_loss: 1.3440 - val_accuracy: 0.4190\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.2909 - accuracy: 0.4204 - val_loss: 1.2765 - val_accuracy: 0.4444\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.1908 - accuracy: 0.4839 - val_loss: 1.2309 - val_accuracy: 0.4676\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1639 - accuracy: 0.4983 - val_loss: 1.2711 - val_accuracy: 0.4630\n\nModel 28\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.5705 - accuracy: 0.2713 - val_loss: 1.3649 - val_accuracy: 0.4097\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3680 - accuracy: 0.4208 - val_loss: 1.2826 - val_accuracy: 0.4306\nEpoch 3/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2507 - accuracy: 0.4428 - val_loss: 1.2271 - val_accuracy: 0.4838\nEpoch 4/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.1884 - accuracy: 0.5006 - val_loss: 1.2748 - val_accuracy: 0.4560\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.1711 - accuracy: 0.4891 - val_loss: 1.2579 - val_accuracy: 0.4468\n\nModel 29\nEpoch 1/5\n17/17 [==============================] - 1s 14ms/step - loss: 1.7357 - accuracy: 0.2292 - val_loss: 1.4995 - val_accuracy: 0.3542\nEpoch 2/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.4776 - accuracy: 0.3564 - val_loss: 1.3858 - val_accuracy: 0.4074\nEpoch 3/5\n17/17 [==============================] - 0s 6ms/step - loss: 1.3723 - accuracy: 0.4051 - val_loss: 1.2989 - val_accuracy: 0.4491\nEpoch 4/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2715 - accuracy: 0.4524 - val_loss: 1.2435 - val_accuracy: 0.4630\nEpoch 5/5\n17/17 [==============================] - 0s 5ms/step - loss: 1.2086 - accuracy: 0.4858 - val_loss: 1.2362 - val_accuracy: 0.4537\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Predict on test image\ny_pred_list = []\nfor i in range(NUM_TN):\n    y_pred = ensemble[i].predict(X_test)\n    y_pred_list.append(y_pred)\n\n# Ensemble voting\ny_pred_list = np.array(y_pred_list)\ny_pred_list = np.argmax(np.sum(y_pred_list, axis=0), axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:25:49.411697Z","iopub.execute_input":"2021-07-12T17:25:49.412027Z","iopub.status.idle":"2021-07-12T17:25:51.913146Z","shell.execute_reply.started":"2021-07-12T17:25:49.411991Z","shell.execute_reply":"2021-07-12T17:25:51.912234Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y_test_label_encoded = pd.get_dummies(y_test)\ny_test_label_encoded = y_test_label_encoded.values.argmax(1)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:25:51.914417Z","iopub.execute_input":"2021-07-12T17:25:51.914781Z","iopub.status.idle":"2021-07-12T17:25:51.922412Z","shell.execute_reply.started":"2021-07-12T17:25:51.914748Z","shell.execute_reply":"2021-07-12T17:25:51.920748Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test_label_encoded, y_pred_list)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:25:51.923685Z","iopub.execute_input":"2021-07-12T17:25:51.924034Z","iopub.status.idle":"2021-07-12T17:25:51.932958Z","shell.execute_reply.started":"2021-07-12T17:25:51.923999Z","shell.execute_reply":"2021-07-12T17:25:51.931971Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"0.4457274826789838"},"metadata":{}}]}]}