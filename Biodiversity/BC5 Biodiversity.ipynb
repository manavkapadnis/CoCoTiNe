{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# BC 5\n## Flat ensemble of tiny networks\n## Input = sub-region","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom os import listdir\nfrom os.path import join\nimport cv2\nimport pandas as pd\nimport os\nimport random as rn\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:28:27.188168Z","iopub.execute_input":"2021-07-12T17:28:27.188579Z","iopub.status.idle":"2021-07-12T17:28:32.220952Z","shell.execute_reply.started":"2021-07-12T17:28:27.188489Z","shell.execute_reply":"2021-07-12T17:28:32.219998Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"SEED = 321\nrn.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:28:32.222317Z","iopub.execute_input":"2021-07-12T17:28:32.222644Z","iopub.status.idle":"2021-07-12T17:28:32.229123Z","shell.execute_reply.started":"2021-07-12T17:28:32.222608Z","shell.execute_reply":"2021-07-12T17:28:32.226882Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"NUM_TN = 30\nSUB_REGION_SCALE = 14\n\n#dataset specific parameters\nNUM_CLASS = 5","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:28:32.231583Z","iopub.execute_input":"2021-07-12T17:28:32.231990Z","iopub.status.idle":"2021-07-12T17:28:32.243305Z","shell.execute_reply.started":"2021-07-12T17:28:32.231953Z","shell.execute_reply":"2021-07-12T17:28:32.242472Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = \"../input/flowers-recognition/flowers/\"\nfolders = os.listdir(data)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:28:32.245054Z","iopub.execute_input":"2021-07-12T17:28:32.245434Z","iopub.status.idle":"2021-07-12T17:28:32.260962Z","shell.execute_reply.started":"2021-07-12T17:28:32.245397Z","shell.execute_reply":"2021-07-12T17:28:32.260122Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"image_names = []\ntrain_labels = []\ntrain_images = []\n\nsize = 32,32\n\nfor folder in folders:\n    for file in os.listdir(os.path.join(data,folder)):\n        if file.endswith(\"jpg\"):\n            image_names.append(os.path.join(data,folder,file))\n            train_labels.append(folder)\n            img = cv2.imread(os.path.join(data,folder,file))\n            im = cv2.resize(img,size)\n            train_images.append(im)\n        else:\n            continue","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:28:32.262086Z","iopub.execute_input":"2021-07-12T17:28:32.262454Z","iopub.status.idle":"2021-07-12T17:29:12.159556Z","shell.execute_reply.started":"2021-07-12T17:28:32.262419Z","shell.execute_reply":"2021-07-12T17:29:12.158756Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train = np.array(train_images)\ntrain = train.astype('float32')\ntrain.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:29:12.160963Z","iopub.execute_input":"2021-07-12T17:29:12.161302Z","iopub.status.idle":"2021-07-12T17:29:12.192059Z","shell.execute_reply.started":"2021-07-12T17:29:12.161267Z","shell.execute_reply":"2021-07-12T17:29:12.191083Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"(4323, 32, 32, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# Train, Val, Test split = 0.8, 0.1, 0.1 of the dataset\nX_train,X_val,y_train,y_val = train_test_split(train,train_labels, test_size = 0.2)\nX_val,X_test,y_val,y_test = train_test_split(X_val,y_val, test_size = 0.5)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:29:12.193388Z","iopub.execute_input":"2021-07-12T17:29:12.193751Z","iopub.status.idle":"2021-07-12T17:29:12.222655Z","shell.execute_reply.started":"2021-07-12T17:29:12.193694Z","shell.execute_reply":"2021-07-12T17:29:12.221866Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"#Generate cropped train image\nX_train_cropped_list = []\ny_train_cropped_list = []\n\nfor i in range(NUM_TN):\n  X_train_cropped = []\n  y_train_cropped = []\n  for i in range (X_train.shape[0]):\n    image_cropped = tf.image.random_crop(X_train[i], size=[SUB_REGION_SCALE, SUB_REGION_SCALE, 3])\n    image_cropped = np.array(image_cropped)\n    X_train_cropped.append(image_cropped)\n    y_train_cropped.append(y_train[i])\n  X_train_cropped = np.array(X_train_cropped)\n  y_train_cropped = np.array(y_train_cropped)\n\n  X_train_cropped_list.append(X_train_cropped)\n  y_train_cropped_list.append(y_train_cropped)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:29:12.223910Z","iopub.execute_input":"2021-07-12T17:29:12.224255Z","iopub.status.idle":"2021-07-12T17:31:11.626135Z","shell.execute_reply.started":"2021-07-12T17:29:12.224219Z","shell.execute_reply":"2021-07-12T17:31:11.625259Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#Generate cropped val image\nX_val_cropped_list = []\ny_val_cropped_list = []\n\nfor i in range(NUM_TN):\n    X_val_cropped = []\n    y_val_cropped = []\n    for i in range (X_val.shape[0]):\n        image_cropped = tf.image.random_crop(X_val[i], size=[SUB_REGION_SCALE, SUB_REGION_SCALE, 3])\n        image_cropped = np.array(image_cropped)\n        X_val_cropped.append(image_cropped)\n        y_val_cropped.append(y_val[i])\n    X_val_cropped = np.array(X_val_cropped)\n    y_val_cropped = np.array(y_val_cropped)\n\n    X_val_cropped_list.append(X_val_cropped)\n    y_val_cropped_list.append(y_val_cropped)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:31:11.628751Z","iopub.execute_input":"2021-07-12T17:31:11.629086Z","iopub.status.idle":"2021-07-12T17:31:26.317037Z","shell.execute_reply.started":"2021-07-12T17:31:11.629051Z","shell.execute_reply":"2021-07-12T17:31:26.316180Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"#Generate cropped test image\nX_test_cropped_list = []\ny_test_cropped_list = []\n\nfor i in range(NUM_TN):\n    X_test_cropped = []\n    y_test_cropped = []\n    for i in range (X_test.shape[0]):\n        image_cropped = tf.image.random_crop(X_test[i], size=[SUB_REGION_SCALE, SUB_REGION_SCALE, 3])\n        image_cropped = np.array(image_cropped)\n        X_test_cropped.append(image_cropped)\n        y_test_cropped.append(y_test[i])\n    X_test_cropped = np.array(X_test_cropped)\n    y_test_cropped = np.array(y_test_cropped)\n\n    X_test_cropped_list.append(X_test_cropped)\n    y_test_cropped_list.append(y_test_cropped)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:31:26.318522Z","iopub.execute_input":"2021-07-12T17:31:26.318851Z","iopub.status.idle":"2021-07-12T17:31:40.960398Z","shell.execute_reply.started":"2021-07-12T17:31:26.318817Z","shell.execute_reply":"2021-07-12T17:31:40.959544Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#normalizing dataset\nfor i in range(NUM_TN):\n    X_train_cropped_list[i] = X_train_cropped_list[i]/255\n    X_val_cropped_list[i] = X_val_cropped_list[i]/255\n    X_test_cropped_list[i] = X_test_cropped_list[i]/255","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:31:40.961784Z","iopub.execute_input":"2021-07-12T17:31:40.962117Z","iopub.status.idle":"2021-07-12T17:31:41.017555Z","shell.execute_reply.started":"2021-07-12T17:31:40.962083Z","shell.execute_reply":"2021-07-12T17:31:41.016724Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#transform to vector\nfor i in range(NUM_TN):\n    X_train_cropped_list[i] = X_train_cropped_list[i].reshape((-1, SUB_REGION_SCALE*SUB_REGION_SCALE*3))\n    X_val_cropped_list[i] = X_val_cropped_list[i].reshape((-1, SUB_REGION_SCALE*SUB_REGION_SCALE*3))\n    X_test_cropped_list[i] = X_test_cropped_list[i].reshape((-1, SUB_REGION_SCALE*SUB_REGION_SCALE*3))","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:31:41.018818Z","iopub.execute_input":"2021-07-12T17:31:41.019182Z","iopub.status.idle":"2021-07-12T17:31:41.025392Z","shell.execute_reply.started":"2021-07-12T17:31:41.019146Z","shell.execute_reply":"2021-07-12T17:31:41.024236Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#one-hot encoding\nfor i in range(NUM_TN):\n    y_train_cropped_list[i] = pd.get_dummies(y_train_cropped_list[i])\n    y_train_cropped_list[i] = y_train_cropped_list[i].values.argmax(1)\n    y_train_cropped_list[i] = to_categorical(y_train_cropped_list[i])\n    \n    y_val_cropped_list[i] = pd.get_dummies(y_val_cropped_list[i])\n    y_val_cropped_list[i] = y_val_cropped_list[i].values.argmax(1)\n    y_val_cropped_list[i] = to_categorical(y_val_cropped_list[i])\n    \n    y_test_cropped_list[i] = pd.get_dummies(y_test_cropped_list[i])\n    y_test_cropped_list[i] = y_test_cropped_list[i].values.argmax(1)\n    y_test_cropped_list[i] = to_categorical(y_test_cropped_list[i])","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:31:41.026751Z","iopub.execute_input":"2021-07-12T17:31:41.027100Z","iopub.status.idle":"2021-07-12T17:31:41.131872Z","shell.execute_reply.started":"2021-07-12T17:31:41.027063Z","shell.execute_reply":"2021-07-12T17:31:41.131164Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"#build ANN model\nensemble = []\nfor i in range(NUM_TN):\n    model = Sequential()\n    model.add(Dense(64, activation='relu', input_dim=SUB_REGION_SCALE*SUB_REGION_SCALE*3))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(NUM_CLASS, activation = 'softmax'))\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    ensemble.append(model)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:31:41.132960Z","iopub.execute_input":"2021-07-12T17:31:41.133305Z","iopub.status.idle":"2021-07-12T17:31:42.070023Z","shell.execute_reply.started":"2021-07-12T17:31:41.133267Z","shell.execute_reply":"2021-07-12T17:31:42.069195Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#train model\nhistory = []\nfor i in range(NUM_TN):\n    print()\n    print('Model %d' %i)\n    print()\n    hist = ensemble[i].fit(X_train_cropped_list[i], y_train_cropped_list[i], validation_data=(X_val_cropped_list[i], y_val_cropped_list[i]), epochs=5, batch_size=128)\n    history.append(hist)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:31:42.071324Z","iopub.execute_input":"2021-07-12T17:31:42.071660Z","iopub.status.idle":"2021-07-12T17:32:14.942890Z","shell.execute_reply.started":"2021-07-12T17:31:42.071627Z","shell.execute_reply":"2021-07-12T17:32:14.942093Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\nModel 0\n\nEpoch 1/5\n28/28 [==============================] - 2s 21ms/step - loss: 1.5896 - accuracy: 0.2732 - val_loss: 1.4724 - val_accuracy: 0.3171\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4540 - accuracy: 0.3487 - val_loss: 1.3989 - val_accuracy: 0.3657\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4115 - accuracy: 0.3686 - val_loss: 1.3824 - val_accuracy: 0.3681\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3849 - accuracy: 0.3855 - val_loss: 1.3755 - val_accuracy: 0.3935\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3742 - accuracy: 0.3833 - val_loss: 1.3778 - val_accuracy: 0.3657\n\nModel 1\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5909 - accuracy: 0.2483 - val_loss: 1.4592 - val_accuracy: 0.3634\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4339 - accuracy: 0.3569 - val_loss: 1.4064 - val_accuracy: 0.3472\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4169 - accuracy: 0.3728 - val_loss: 1.3974 - val_accuracy: 0.3750\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3783 - accuracy: 0.3952 - val_loss: 1.3684 - val_accuracy: 0.3843\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3491 - accuracy: 0.3857 - val_loss: 1.3676 - val_accuracy: 0.3912\n\nModel 2\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.6339 - accuracy: 0.2382 - val_loss: 1.4858 - val_accuracy: 0.3241\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4688 - accuracy: 0.3516 - val_loss: 1.4487 - val_accuracy: 0.3403\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4535 - accuracy: 0.3551 - val_loss: 1.3930 - val_accuracy: 0.3819\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3843 - accuracy: 0.3894 - val_loss: 1.3657 - val_accuracy: 0.3681\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3901 - accuracy: 0.3737 - val_loss: 1.3796 - val_accuracy: 0.3866\n\nModel 3\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5854 - accuracy: 0.2468 - val_loss: 1.4573 - val_accuracy: 0.3449\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4247 - accuracy: 0.3679 - val_loss: 1.4187 - val_accuracy: 0.3843\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4153 - accuracy: 0.3710 - val_loss: 1.3833 - val_accuracy: 0.3958\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3783 - accuracy: 0.3824 - val_loss: 1.3691 - val_accuracy: 0.4120\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3444 - accuracy: 0.4257 - val_loss: 1.3634 - val_accuracy: 0.3843\n\nModel 4\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.6030 - accuracy: 0.2504 - val_loss: 1.5194 - val_accuracy: 0.2986\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4738 - accuracy: 0.3439 - val_loss: 1.4572 - val_accuracy: 0.3449\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4317 - accuracy: 0.3751 - val_loss: 1.3991 - val_accuracy: 0.3935\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3561 - accuracy: 0.4013 - val_loss: 1.3721 - val_accuracy: 0.4028\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3518 - accuracy: 0.3969 - val_loss: 1.3781 - val_accuracy: 0.3819\n\nModel 5\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5631 - accuracy: 0.2618 - val_loss: 1.4529 - val_accuracy: 0.3495\nEpoch 2/5\n28/28 [==============================] - 0s 7ms/step - loss: 1.4126 - accuracy: 0.3768 - val_loss: 1.3988 - val_accuracy: 0.3773\nEpoch 3/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.4090 - accuracy: 0.3642 - val_loss: 1.3885 - val_accuracy: 0.3588\nEpoch 4/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.3709 - accuracy: 0.3832 - val_loss: 1.3908 - val_accuracy: 0.3750\nEpoch 5/5\n28/28 [==============================] - 0s 5ms/step - loss: 1.3766 - accuracy: 0.3742 - val_loss: 1.3681 - val_accuracy: 0.3773\n\nModel 6\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.6069 - accuracy: 0.2459 - val_loss: 1.4850 - val_accuracy: 0.3287\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4520 - accuracy: 0.3476 - val_loss: 1.4251 - val_accuracy: 0.3773\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4111 - accuracy: 0.3650 - val_loss: 1.4053 - val_accuracy: 0.3681\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3832 - accuracy: 0.3667 - val_loss: 1.3991 - val_accuracy: 0.3403\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3895 - accuracy: 0.3510 - val_loss: 1.4110 - val_accuracy: 0.3333\n\nModel 7\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.6080 - accuracy: 0.2495 - val_loss: 1.4981 - val_accuracy: 0.3310\nEpoch 2/5\n28/28 [==============================] - 0s 5ms/step - loss: 1.4634 - accuracy: 0.3515 - val_loss: 1.4308 - val_accuracy: 0.3866\nEpoch 3/5\n28/28 [==============================] - 0s 7ms/step - loss: 1.4119 - accuracy: 0.3757 - val_loss: 1.4012 - val_accuracy: 0.3819\nEpoch 4/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.4127 - accuracy: 0.3707 - val_loss: 1.3920 - val_accuracy: 0.3495\nEpoch 5/5\n28/28 [==============================] - 0s 7ms/step - loss: 1.3788 - accuracy: 0.3938 - val_loss: 1.3674 - val_accuracy: 0.3542\n\nModel 8\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5706 - accuracy: 0.2638 - val_loss: 1.4608 - val_accuracy: 0.3194\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4220 - accuracy: 0.3576 - val_loss: 1.4034 - val_accuracy: 0.3657\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4198 - accuracy: 0.3568 - val_loss: 1.3968 - val_accuracy: 0.3542\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3663 - accuracy: 0.3798 - val_loss: 1.3976 - val_accuracy: 0.3542\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3819 - accuracy: 0.3728 - val_loss: 1.3851 - val_accuracy: 0.3495\n\nModel 9\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5851 - accuracy: 0.2508 - val_loss: 1.4688 - val_accuracy: 0.3380\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4368 - accuracy: 0.3446 - val_loss: 1.4106 - val_accuracy: 0.3912\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4341 - accuracy: 0.3728 - val_loss: 1.4007 - val_accuracy: 0.3565\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3710 - accuracy: 0.3911 - val_loss: 1.3814 - val_accuracy: 0.3912\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3894 - accuracy: 0.3658 - val_loss: 1.3764 - val_accuracy: 0.3912\n\nModel 10\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5887 - accuracy: 0.2545 - val_loss: 1.4757 - val_accuracy: 0.3472\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4324 - accuracy: 0.3532 - val_loss: 1.4150 - val_accuracy: 0.3495\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4069 - accuracy: 0.3666 - val_loss: 1.4223 - val_accuracy: 0.3542\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3778 - accuracy: 0.3660 - val_loss: 1.4253 - val_accuracy: 0.3356\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3876 - accuracy: 0.3688 - val_loss: 1.4281 - val_accuracy: 0.3333\n\nModel 11\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.6318 - accuracy: 0.2426 - val_loss: 1.4974 - val_accuracy: 0.3333\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4729 - accuracy: 0.3435 - val_loss: 1.4134 - val_accuracy: 0.3657\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4269 - accuracy: 0.3626 - val_loss: 1.3943 - val_accuracy: 0.3727\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3917 - accuracy: 0.3779 - val_loss: 1.3853 - val_accuracy: 0.3657\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3789 - accuracy: 0.3810 - val_loss: 1.3827 - val_accuracy: 0.3727\n\nModel 12\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5779 - accuracy: 0.2730 - val_loss: 1.4406 - val_accuracy: 0.3519\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4268 - accuracy: 0.3725 - val_loss: 1.4030 - val_accuracy: 0.3773\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4152 - accuracy: 0.3670 - val_loss: 1.3692 - val_accuracy: 0.3935\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3717 - accuracy: 0.3898 - val_loss: 1.3863 - val_accuracy: 0.3843\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4058 - accuracy: 0.3692 - val_loss: 1.3615 - val_accuracy: 0.4005\n\nModel 13\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5889 - accuracy: 0.2652 - val_loss: 1.4888 - val_accuracy: 0.3171\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4323 - accuracy: 0.3480 - val_loss: 1.4378 - val_accuracy: 0.3657\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4166 - accuracy: 0.3675 - val_loss: 1.4088 - val_accuracy: 0.3750\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3557 - accuracy: 0.3912 - val_loss: 1.3936 - val_accuracy: 0.3866\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3545 - accuracy: 0.3907 - val_loss: 1.4110 - val_accuracy: 0.3519\n\nModel 14\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5772 - accuracy: 0.2651 - val_loss: 1.4781 - val_accuracy: 0.3449\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4329 - accuracy: 0.3602 - val_loss: 1.4131 - val_accuracy: 0.3750\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4301 - accuracy: 0.3741 - val_loss: 1.3963 - val_accuracy: 0.3750\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4154 - accuracy: 0.3540 - val_loss: 1.3794 - val_accuracy: 0.3657\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3563 - accuracy: 0.3964 - val_loss: 1.3827 - val_accuracy: 0.3519\n\nModel 15\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.6154 - accuracy: 0.2421 - val_loss: 1.4835 - val_accuracy: 0.3611\nEpoch 2/5\n28/28 [==============================] - 0s 7ms/step - loss: 1.4393 - accuracy: 0.3567 - val_loss: 1.4327 - val_accuracy: 0.3588\nEpoch 3/5\n28/28 [==============================] - 0s 5ms/step - loss: 1.4077 - accuracy: 0.3685 - val_loss: 1.3993 - val_accuracy: 0.3796\nEpoch 4/5\n28/28 [==============================] - 0s 5ms/step - loss: 1.3747 - accuracy: 0.3823 - val_loss: 1.4012 - val_accuracy: 0.3495\nEpoch 5/5\n28/28 [==============================] - 0s 5ms/step - loss: 1.3853 - accuracy: 0.3699 - val_loss: 1.3975 - val_accuracy: 0.3681\n\nModel 16\n\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.5934 - accuracy: 0.2556 - val_loss: 1.4888 - val_accuracy: 0.3472\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4556 - accuracy: 0.3343 - val_loss: 1.4249 - val_accuracy: 0.3819\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4321 - accuracy: 0.3647 - val_loss: 1.3814 - val_accuracy: 0.3981\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3859 - accuracy: 0.3695 - val_loss: 1.3814 - val_accuracy: 0.3866\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3711 - accuracy: 0.3903 - val_loss: 1.3663 - val_accuracy: 0.4028\n\nModel 17\n\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.6121 - accuracy: 0.2359 - val_loss: 1.4990 - val_accuracy: 0.3009\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4820 - accuracy: 0.3448 - val_loss: 1.4502 - val_accuracy: 0.3542\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4380 - accuracy: 0.3575 - val_loss: 1.3697 - val_accuracy: 0.3750\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3967 - accuracy: 0.3816 - val_loss: 1.3701 - val_accuracy: 0.3750\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3807 - accuracy: 0.3871 - val_loss: 1.3598 - val_accuracy: 0.3843\n\nModel 18\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.6003 - accuracy: 0.2570 - val_loss: 1.4537 - val_accuracy: 0.3426\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4198 - accuracy: 0.3542 - val_loss: 1.4084 - val_accuracy: 0.3727\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4195 - accuracy: 0.3579 - val_loss: 1.4077 - val_accuracy: 0.3866\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3697 - accuracy: 0.3817 - val_loss: 1.3698 - val_accuracy: 0.3912\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3639 - accuracy: 0.3911 - val_loss: 1.3755 - val_accuracy: 0.3704\n\nModel 19\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5979 - accuracy: 0.2546 - val_loss: 1.4656 - val_accuracy: 0.3449\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4447 - accuracy: 0.3597 - val_loss: 1.4186 - val_accuracy: 0.3426\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4185 - accuracy: 0.3726 - val_loss: 1.3928 - val_accuracy: 0.3565\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3801 - accuracy: 0.3785 - val_loss: 1.3721 - val_accuracy: 0.3611\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3610 - accuracy: 0.3969 - val_loss: 1.3700 - val_accuracy: 0.3634\n\nModel 20\n\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.6044 - accuracy: 0.2597 - val_loss: 1.4659 - val_accuracy: 0.3472\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4445 - accuracy: 0.3655 - val_loss: 1.4200 - val_accuracy: 0.3843\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4269 - accuracy: 0.3714 - val_loss: 1.4071 - val_accuracy: 0.3634\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4197 - accuracy: 0.3562 - val_loss: 1.3946 - val_accuracy: 0.3657\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3874 - accuracy: 0.3809 - val_loss: 1.3672 - val_accuracy: 0.3773\n\nModel 21\n\nEpoch 1/5\n28/28 [==============================] - 1s 8ms/step - loss: 1.6021 - accuracy: 0.2367 - val_loss: 1.4868 - val_accuracy: 0.3356\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4654 - accuracy: 0.3401 - val_loss: 1.4523 - val_accuracy: 0.3819\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4241 - accuracy: 0.3702 - val_loss: 1.4047 - val_accuracy: 0.3611\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3687 - accuracy: 0.3973 - val_loss: 1.4010 - val_accuracy: 0.3796\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3591 - accuracy: 0.3813 - val_loss: 1.3816 - val_accuracy: 0.3912\n\nModel 22\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5784 - accuracy: 0.2549 - val_loss: 1.4508 - val_accuracy: 0.3519\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4315 - accuracy: 0.3709 - val_loss: 1.3796 - val_accuracy: 0.3727\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4031 - accuracy: 0.3636 - val_loss: 1.3606 - val_accuracy: 0.3912\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3580 - accuracy: 0.3945 - val_loss: 1.3755 - val_accuracy: 0.3681\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3874 - accuracy: 0.3760 - val_loss: 1.3491 - val_accuracy: 0.4074\n\nModel 23\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.6095 - accuracy: 0.2513 - val_loss: 1.4933 - val_accuracy: 0.3403\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4702 - accuracy: 0.3436 - val_loss: 1.4085 - val_accuracy: 0.3889\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4285 - accuracy: 0.3592 - val_loss: 1.3895 - val_accuracy: 0.3634\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3838 - accuracy: 0.3755 - val_loss: 1.3708 - val_accuracy: 0.3819\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3798 - accuracy: 0.3844 - val_loss: 1.3782 - val_accuracy: 0.3657\n\nModel 24\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5893 - accuracy: 0.2686 - val_loss: 1.4519 - val_accuracy: 0.3310\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4152 - accuracy: 0.3602 - val_loss: 1.4106 - val_accuracy: 0.3912\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4220 - accuracy: 0.3600 - val_loss: 1.3866 - val_accuracy: 0.3819\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3584 - accuracy: 0.3968 - val_loss: 1.3667 - val_accuracy: 0.3681\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3473 - accuracy: 0.4019 - val_loss: 1.3844 - val_accuracy: 0.3704\n\nModel 25\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.6100 - accuracy: 0.2428 - val_loss: 1.4832 - val_accuracy: 0.3495\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4448 - accuracy: 0.3575 - val_loss: 1.4185 - val_accuracy: 0.3657\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4132 - accuracy: 0.3625 - val_loss: 1.3844 - val_accuracy: 0.3681\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3770 - accuracy: 0.3807 - val_loss: 1.3723 - val_accuracy: 0.3681\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3689 - accuracy: 0.3686 - val_loss: 1.3759 - val_accuracy: 0.3773\n\nModel 26\n\nEpoch 1/5\n28/28 [==============================] - 1s 10ms/step - loss: 1.5701 - accuracy: 0.2764 - val_loss: 1.4303 - val_accuracy: 0.3495\nEpoch 2/5\n28/28 [==============================] - 0s 7ms/step - loss: 1.4212 - accuracy: 0.3812 - val_loss: 1.3698 - val_accuracy: 0.3773\nEpoch 3/5\n28/28 [==============================] - 0s 5ms/step - loss: 1.3962 - accuracy: 0.3649 - val_loss: 1.3527 - val_accuracy: 0.3958\nEpoch 4/5\n28/28 [==============================] - 0s 5ms/step - loss: 1.3712 - accuracy: 0.3851 - val_loss: 1.3472 - val_accuracy: 0.3912\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3603 - accuracy: 0.3848 - val_loss: 1.3669 - val_accuracy: 0.3495\n\nModel 27\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5901 - accuracy: 0.2604 - val_loss: 1.4860 - val_accuracy: 0.3148\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4530 - accuracy: 0.3540 - val_loss: 1.4211 - val_accuracy: 0.3472\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4091 - accuracy: 0.3475 - val_loss: 1.3906 - val_accuracy: 0.4005\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3631 - accuracy: 0.3799 - val_loss: 1.3786 - val_accuracy: 0.3819\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3669 - accuracy: 0.3922 - val_loss: 1.4023 - val_accuracy: 0.3333\n\nModel 28\n\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5714 - accuracy: 0.2787 - val_loss: 1.4602 - val_accuracy: 0.3333\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4303 - accuracy: 0.3748 - val_loss: 1.4139 - val_accuracy: 0.3519\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4066 - accuracy: 0.3652 - val_loss: 1.3807 - val_accuracy: 0.3681\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3719 - accuracy: 0.3866 - val_loss: 1.3704 - val_accuracy: 0.3611\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3553 - accuracy: 0.4078 - val_loss: 1.3760 - val_accuracy: 0.3588\n\nModel 29\n\nEpoch 1/5\n28/28 [==============================] - 1s 18ms/step - loss: 1.5642 - accuracy: 0.2651 - val_loss: 1.4645 - val_accuracy: 0.3241\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4284 - accuracy: 0.3594 - val_loss: 1.4142 - val_accuracy: 0.3843\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4152 - accuracy: 0.3630 - val_loss: 1.3858 - val_accuracy: 0.3889\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3666 - accuracy: 0.3941 - val_loss: 1.4115 - val_accuracy: 0.3704\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4038 - accuracy: 0.3672 - val_loss: 1.3804 - val_accuracy: 0.3958\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Predict on test image\ny_pred_list = []\nfor i in range(NUM_TN):\n    y_pred = ensemble[i].predict(X_test_cropped_list[i])\n    y_pred_list.append(y_pred)\n    \n# Ensemble voting\ny_pred_list = np.array(y_pred_list)\ny_pred_list = np.argmax(np.sum(y_pred_list, axis=0), axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:32:14.944661Z","iopub.execute_input":"2021-07-12T17:32:14.945030Z","iopub.status.idle":"2021-07-12T17:32:16.869896Z","shell.execute_reply.started":"2021-07-12T17:32:14.944993Z","shell.execute_reply":"2021-07-12T17:32:16.869063Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"y_test_label_encoded_list =[]","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:32:16.871241Z","iopub.execute_input":"2021-07-12T17:32:16.871577Z","iopub.status.idle":"2021-07-12T17:32:16.876575Z","shell.execute_reply.started":"2021-07-12T17:32:16.871542Z","shell.execute_reply":"2021-07-12T17:32:16.875674Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for k in y_test_cropped_list:\n    y_test_label_encoded_list.append(k)\n    \ny_test_label_encoded_list  = np.array(y_test_label_encoded_list)\ny_test_label_encoded_list = np.argmax(np.sum(y_test_label_encoded_list, axis=0), axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:32:16.877865Z","iopub.execute_input":"2021-07-12T17:32:16.878231Z","iopub.status.idle":"2021-07-12T17:32:16.886558Z","shell.execute_reply.started":"2021-07-12T17:32:16.878182Z","shell.execute_reply":"2021-07-12T17:32:16.885751Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test_label_encoded_list, y_pred_list)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:32:16.889635Z","iopub.execute_input":"2021-07-12T17:32:16.889912Z","iopub.status.idle":"2021-07-12T17:32:16.901557Z","shell.execute_reply.started":"2021-07-12T17:32:16.889886Z","shell.execute_reply":"2021-07-12T17:32:16.900687Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0.4341801385681293"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}