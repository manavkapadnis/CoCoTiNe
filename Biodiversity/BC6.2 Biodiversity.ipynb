{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hierarchical ensemble\n\n## Summed output logits","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom os import listdir\nfrom os.path import join\nimport cv2\nimport pandas as pd\nimport os\nimport random as rn\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport pickle\nfrom keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:43:11.858252Z","iopub.execute_input":"2021-07-12T17:43:11.858658Z","iopub.status.idle":"2021-07-12T17:43:16.778881Z","shell.execute_reply.started":"2021-07-12T17:43:11.858559Z","shell.execute_reply":"2021-07-12T17:43:16.777902Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"SEED = 321\nrn.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:43:16.780330Z","iopub.execute_input":"2021-07-12T17:43:16.780697Z","iopub.status.idle":"2021-07-12T17:43:16.786954Z","shell.execute_reply.started":"2021-07-12T17:43:16.780658Z","shell.execute_reply":"2021-07-12T17:43:16.786144Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"SUB_REGION_SCALE = 14\nNUM_HICO_LAYER = 5\nNUM_TN = [10, 8, 6, 4, 2]\nNUM_CONNECTION = [0, 5, 4, 3, 2]\nALPHA = 0.1\n\n#dataset specific parameters\nNUM_CLASS = 5","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:43:20.910156Z","iopub.execute_input":"2021-07-12T17:43:20.910512Z","iopub.status.idle":"2021-07-12T17:43:20.917185Z","shell.execute_reply.started":"2021-07-12T17:43:20.910481Z","shell.execute_reply":"2021-07-12T17:43:20.916354Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"with open('../input/hicotine1-layer1-biodiversity/fyp/CIFAR-10.pickle', 'rb') as f:\n    X_train_cropped_list, y_train_one_hot, X_val_cropped_list, y_val_one_hot, X_test_cropped_list, y_test_one_hot, coordinate_list, scale_list = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:43:23.051004Z","iopub.execute_input":"2021-07-12T17:43:23.051339Z","iopub.status.idle":"2021-07-12T17:43:25.099884Z","shell.execute_reply.started":"2021-07-12T17:43:23.051307Z","shell.execute_reply":"2021-07-12T17:43:25.098920Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## HiCo Layer 1","metadata":{}},{"cell_type":"code","source":"#build ANN model\nensemble = []\nfor i in range(NUM_TN[0]):\n  model = Sequential()\n  model.add(Dense(64, activation='relu', input_dim=SUB_REGION_SCALE*SUB_REGION_SCALE*3))\n  model.add(Dense(64, activation='relu'))\n  model.add(Dense(NUM_CLASS, activation = 'softmax'))\n  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n  ensemble.append((model, i, coordinate_list[i], scale_list[i]))","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:43:33.310531Z","iopub.execute_input":"2021-07-12T17:43:33.310861Z","iopub.status.idle":"2021-07-12T17:43:35.446396Z","shell.execute_reply.started":"2021-07-12T17:43:33.310834Z","shell.execute_reply":"2021-07-12T17:43:35.445560Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for i in range(NUM_TN[0]):\n  ensemble[i][0].load_weights('../input/hicotine1-layer1-biodiversity/fyp/CIFAR-10_' + str(i) + '.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:43:36.490660Z","iopub.execute_input":"2021-07-12T17:43:36.490997Z","iopub.status.idle":"2021-07-12T17:43:36.744482Z","shell.execute_reply.started":"2021-07-12T17:43:36.490969Z","shell.execute_reply":"2021-07-12T17:43:36.743630Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"hico_layers = []\nhico_layers.append(ensemble)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:43:36.745897Z","iopub.execute_input":"2021-07-12T17:43:36.746239Z","iopub.status.idle":"2021-07-12T17:43:36.751533Z","shell.execute_reply.started":"2021-07-12T17:43:36.746200Z","shell.execute_reply":"2021-07-12T17:43:36.749892Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## HiCo Layer 2+","metadata":{}},{"cell_type":"code","source":"del hico_layers[1:]","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:43:44.568331Z","iopub.execute_input":"2021-07-12T17:43:44.568703Z","iopub.status.idle":"2021-07-12T17:43:44.573226Z","shell.execute_reply.started":"2021-07-12T17:43:44.568670Z","shell.execute_reply":"2021-07-12T17:43:44.572199Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Function to get input of layer i-1\ndef get_previous_layer_input(hico_layers, layer, tn, train_image):\n  input = []\n    \n  if layer == 0:\n    previous_layer_input = train_image[tn[1]]\n    return previous_layer_input\n\n  elif layer > 0:\n    for i in range(NUM_CONNECTION[layer]):\n      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[2].output))\n      input.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n      \n    input = np.array(input)\n    input = np.sum(input, axis=0)\n    previous_layer_input = input\n    return previous_layer_input","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:43:48.240661Z","iopub.execute_input":"2021-07-12T17:43:48.240998Z","iopub.status.idle":"2021-07-12T17:43:48.251164Z","shell.execute_reply.started":"2021-07-12T17:43:48.240967Z","shell.execute_reply":"2021-07-12T17:43:48.250109Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for i in range(1, NUM_HICO_LAYER):\n  print('Layer %d' %i)\n  ensemble = []\n  X_train_input_list = []\n  X_test_input_list = []\n\n  for j in range(NUM_TN[i]):\n    # Build model of HiCo layer i\n    connection = tuple(rn.sample(range(len(hico_layers[i-1])), k=NUM_CONNECTION[i]))\n    model = Sequential()\n    model.add(Dense(64, activation='relu', input_dim=NUM_CLASS))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(NUM_CLASS, activation = 'softmax'))\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    ensemble.append((model, connection))\n  hico_layers.append(ensemble)\n  print('HICO LENGTH')\n  print(len(hico_layers))\n\n  for j in range(NUM_TN[i]):\n    # Get train hidden representation from HiCo layer i-1\n    X_train_input = []\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n      X_train_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n    X_train_input = np.array(X_train_input)\n    X_train_input = np.sum(X_train_input, axis=0)\n    X_train_input_list.append(X_train_input)\n\n    # Get test hidden representation from HiCo layer i-1\n    X_test_input = []\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n    X_test_input = np.array(X_test_input)\n    X_test_input = np.sum(X_test_input, axis=0)\n    X_test_input_list.append(X_test_input)\n\n  #train model of HiCo layer i\n  for j in range(NUM_TN[i]):\n    print('Model %d' %j)\n    hico_layers[i][j][0].fit(X_train_input_list[j], y_train_one_hot, validation_data=(X_test_input_list[j], y_test_one_hot), epochs=5, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:44:11.573191Z","iopub.execute_input":"2021-07-12T17:44:11.573570Z","iopub.status.idle":"2021-07-12T17:44:42.742404Z","shell.execute_reply.started":"2021-07-12T17:44:11.573527Z","shell.execute_reply":"2021-07-12T17:44:42.741622Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Layer 1\nHICO LENGTH\n2\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 11ms/step - loss: 1.5508 - accuracy: 0.3108 - val_loss: 1.3748 - val_accuracy: 0.3949\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3087 - accuracy: 0.4518 - val_loss: 1.2881 - val_accuracy: 0.4249\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2407 - accuracy: 0.4849 - val_loss: 1.2760 - val_accuracy: 0.4342\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2045 - accuracy: 0.4995 - val_loss: 1.2778 - val_accuracy: 0.4480\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1867 - accuracy: 0.4857 - val_loss: 1.2809 - val_accuracy: 0.4550\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 10ms/step - loss: 1.5528 - accuracy: 0.2965 - val_loss: 1.3606 - val_accuracy: 0.4088\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2953 - accuracy: 0.4426 - val_loss: 1.2886 - val_accuracy: 0.4273\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2425 - accuracy: 0.4657 - val_loss: 1.2790 - val_accuracy: 0.4411\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2074 - accuracy: 0.4899 - val_loss: 1.2789 - val_accuracy: 0.4434\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1884 - accuracy: 0.4840 - val_loss: 1.2853 - val_accuracy: 0.4365\nModel 2\nEpoch 1/5\n28/28 [==============================] - 1s 10ms/step - loss: 1.5256 - accuracy: 0.3320 - val_loss: 1.3322 - val_accuracy: 0.4018\nEpoch 2/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.2654 - accuracy: 0.4627 - val_loss: 1.2928 - val_accuracy: 0.4134\nEpoch 3/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.2356 - accuracy: 0.4875 - val_loss: 1.2849 - val_accuracy: 0.4319\nEpoch 4/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.2104 - accuracy: 0.4963 - val_loss: 1.2907 - val_accuracy: 0.4319\nEpoch 5/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.1951 - accuracy: 0.4870 - val_loss: 1.2973 - val_accuracy: 0.4411\nModel 3\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.6243 - accuracy: 0.2457 - val_loss: 1.4016 - val_accuracy: 0.3972\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3391 - accuracy: 0.4301 - val_loss: 1.3023 - val_accuracy: 0.4596\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2638 - accuracy: 0.4616 - val_loss: 1.2878 - val_accuracy: 0.4457\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2231 - accuracy: 0.4836 - val_loss: 1.2853 - val_accuracy: 0.4457\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2029 - accuracy: 0.4855 - val_loss: 1.2865 - val_accuracy: 0.4665\nModel 4\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5824 - accuracy: 0.2780 - val_loss: 1.3918 - val_accuracy: 0.3857\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3099 - accuracy: 0.4434 - val_loss: 1.3005 - val_accuracy: 0.4249\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2419 - accuracy: 0.4743 - val_loss: 1.2933 - val_accuracy: 0.4388\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2060 - accuracy: 0.5024 - val_loss: 1.2949 - val_accuracy: 0.4434\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1917 - accuracy: 0.4834 - val_loss: 1.2938 - val_accuracy: 0.4411\nModel 5\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5188 - accuracy: 0.3424 - val_loss: 1.3642 - val_accuracy: 0.4226\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2875 - accuracy: 0.4665 - val_loss: 1.2999 - val_accuracy: 0.4665\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2413 - accuracy: 0.4663 - val_loss: 1.2940 - val_accuracy: 0.4550\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2140 - accuracy: 0.4767 - val_loss: 1.2934 - val_accuracy: 0.4434\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1931 - accuracy: 0.4840 - val_loss: 1.2975 - val_accuracy: 0.4457\nModel 6\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5515 - accuracy: 0.3240 - val_loss: 1.3853 - val_accuracy: 0.4157\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3104 - accuracy: 0.4608 - val_loss: 1.3033 - val_accuracy: 0.4365\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2370 - accuracy: 0.4781 - val_loss: 1.2952 - val_accuracy: 0.4434\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1941 - accuracy: 0.5067 - val_loss: 1.2981 - val_accuracy: 0.4503\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1783 - accuracy: 0.4975 - val_loss: 1.3001 - val_accuracy: 0.4457\nModel 7\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5727 - accuracy: 0.2727 - val_loss: 1.4182 - val_accuracy: 0.3764\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3443 - accuracy: 0.4167 - val_loss: 1.3152 - val_accuracy: 0.4457\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2612 - accuracy: 0.4768 - val_loss: 1.2987 - val_accuracy: 0.4457\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2186 - accuracy: 0.4792 - val_loss: 1.2982 - val_accuracy: 0.4411\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1954 - accuracy: 0.4784 - val_loss: 1.2992 - val_accuracy: 0.4527\nLayer 2\nHICO LENGTH\n3\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5789 - accuracy: 0.2741 - val_loss: 1.3825 - val_accuracy: 0.4249\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3241 - accuracy: 0.4402 - val_loss: 1.3094 - val_accuracy: 0.4457\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2481 - accuracy: 0.4956 - val_loss: 1.2994 - val_accuracy: 0.4411\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2109 - accuracy: 0.5008 - val_loss: 1.3007 - val_accuracy: 0.4342\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1984 - accuracy: 0.4933 - val_loss: 1.2990 - val_accuracy: 0.4457\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5636 - accuracy: 0.2891 - val_loss: 1.3844 - val_accuracy: 0.4619\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3150 - accuracy: 0.4958 - val_loss: 1.3021 - val_accuracy: 0.4434\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2295 - accuracy: 0.5008 - val_loss: 1.3003 - val_accuracy: 0.4365\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1980 - accuracy: 0.5091 - val_loss: 1.3024 - val_accuracy: 0.4319\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1900 - accuracy: 0.5023 - val_loss: 1.3020 - val_accuracy: 0.4411\nModel 2\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5805 - accuracy: 0.3206 - val_loss: 1.3984 - val_accuracy: 0.4249\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3260 - accuracy: 0.4613 - val_loss: 1.3109 - val_accuracy: 0.4550\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2352 - accuracy: 0.4937 - val_loss: 1.3076 - val_accuracy: 0.4457\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2059 - accuracy: 0.5021 - val_loss: 1.3036 - val_accuracy: 0.4480\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1926 - accuracy: 0.4976 - val_loss: 1.3017 - val_accuracy: 0.4411\nModel 3\nEpoch 1/5\n28/28 [==============================] - 1s 17ms/step - loss: 1.5161 - accuracy: 0.3348 - val_loss: 1.3525 - val_accuracy: 0.4434\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2788 - accuracy: 0.4833 - val_loss: 1.3015 - val_accuracy: 0.4480\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2310 - accuracy: 0.4920 - val_loss: 1.3028 - val_accuracy: 0.4480\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1988 - accuracy: 0.5089 - val_loss: 1.2998 - val_accuracy: 0.4503\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1910 - accuracy: 0.4919 - val_loss: 1.2979 - val_accuracy: 0.4480\nModel 4\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5559 - accuracy: 0.3235 - val_loss: 1.3644 - val_accuracy: 0.4596\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2843 - accuracy: 0.4947 - val_loss: 1.3033 - val_accuracy: 0.4711\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2283 - accuracy: 0.4986 - val_loss: 1.2949 - val_accuracy: 0.4596\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1963 - accuracy: 0.5169 - val_loss: 1.2939 - val_accuracy: 0.4596\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1894 - accuracy: 0.5093 - val_loss: 1.2897 - val_accuracy: 0.4457\nModel 5\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5572 - accuracy: 0.3087 - val_loss: 1.3743 - val_accuracy: 0.4365\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2856 - accuracy: 0.4891 - val_loss: 1.3151 - val_accuracy: 0.4434\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2260 - accuracy: 0.5012 - val_loss: 1.3084 - val_accuracy: 0.4457\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1964 - accuracy: 0.5136 - val_loss: 1.3025 - val_accuracy: 0.4527\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1905 - accuracy: 0.5036 - val_loss: 1.3017 - val_accuracy: 0.4480\nLayer 3\nHICO LENGTH\n4\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4921 - accuracy: 0.3778 - val_loss: 1.3789 - val_accuracy: 0.4388\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2860 - accuracy: 0.4907 - val_loss: 1.3218 - val_accuracy: 0.4527\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2405 - accuracy: 0.4992 - val_loss: 1.3153 - val_accuracy: 0.4480\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2111 - accuracy: 0.5107 - val_loss: 1.3094 - val_accuracy: 0.4457\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2062 - accuracy: 0.5007 - val_loss: 1.3122 - val_accuracy: 0.4480\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5238 - accuracy: 0.3414 - val_loss: 1.3845 - val_accuracy: 0.4365\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3157 - accuracy: 0.4747 - val_loss: 1.3180 - val_accuracy: 0.4434\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2454 - accuracy: 0.4916 - val_loss: 1.3146 - val_accuracy: 0.4342\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2156 - accuracy: 0.5058 - val_loss: 1.3091 - val_accuracy: 0.4365\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2059 - accuracy: 0.5017 - val_loss: 1.3112 - val_accuracy: 0.4480\nModel 2\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5471 - accuracy: 0.3507 - val_loss: 1.3895 - val_accuracy: 0.4296\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3141 - accuracy: 0.4829 - val_loss: 1.3132 - val_accuracy: 0.4527\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2382 - accuracy: 0.4984 - val_loss: 1.3122 - val_accuracy: 0.4434\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2103 - accuracy: 0.5118 - val_loss: 1.3128 - val_accuracy: 0.4411\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2039 - accuracy: 0.5053 - val_loss: 1.3144 - val_accuracy: 0.4457\nModel 3\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5206 - accuracy: 0.3858 - val_loss: 1.4058 - val_accuracy: 0.4203\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3121 - accuracy: 0.4847 - val_loss: 1.3191 - val_accuracy: 0.4411\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2385 - accuracy: 0.4907 - val_loss: 1.3107 - val_accuracy: 0.4573\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2081 - accuracy: 0.5086 - val_loss: 1.3052 - val_accuracy: 0.4527\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2003 - accuracy: 0.5009 - val_loss: 1.3062 - val_accuracy: 0.4550\nLayer 4\nHICO LENGTH\n5\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5817 - accuracy: 0.2935 - val_loss: 1.4729 - val_accuracy: 0.4180\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.4121 - accuracy: 0.4673 - val_loss: 1.3556 - val_accuracy: 0.4273\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2902 - accuracy: 0.4810 - val_loss: 1.3155 - val_accuracy: 0.4411\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2247 - accuracy: 0.5087 - val_loss: 1.3132 - val_accuracy: 0.4319\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2161 - accuracy: 0.5006 - val_loss: 1.3202 - val_accuracy: 0.4411\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5374 - accuracy: 0.3808 - val_loss: 1.4285 - val_accuracy: 0.4203\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.3601 - accuracy: 0.4613 - val_loss: 1.3324 - val_accuracy: 0.4411\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2626 - accuracy: 0.4893 - val_loss: 1.3135 - val_accuracy: 0.4527\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2245 - accuracy: 0.5081 - val_loss: 1.3118 - val_accuracy: 0.4457\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2162 - accuracy: 0.4988 - val_loss: 1.3172 - val_accuracy: 0.4480\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Predict on test image\ny_pred_list = []\nfor j in range(NUM_TN[0]):\n  y_pred = hico_layers[0][j][0].predict(X_test_cropped_list[j])\n  y_pred = y_pred * ((1 + ALPHA) - (NUM_TN[0] / max(NUM_TN)))\n  y_pred_list.append(y_pred)\n\nfor i in range(1, NUM_HICO_LAYER):\n  for j in range(NUM_TN[i]):\n\n    # Get test hidden representation from HiCo layer i-1\n    X_test_input = []\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n    X_test_input = np.array(X_test_input)\n    X_test_input = np.sum(X_test_input, axis=0)\n    y_pred = hico_layers[i][j][0].predict(X_test_input)\n    y_pred = y_pred * ((1 + ALPHA) - (NUM_TN[i] / max(NUM_TN)))\n    y_pred_list.append(y_pred)\n\n\n# HiCo voting\ny_pred_list = np.array(y_pred_list)\ny_pred_list = np.transpose(y_pred_list, (1, 0, 2))\ny_pred_list = np.argmax(np.sum(y_pred_list, axis=1), axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:44:42.744046Z","iopub.execute_input":"2021-07-12T17:44:42.744379Z","iopub.status.idle":"2021-07-12T17:44:48.219576Z","shell.execute_reply.started":"2021-07-12T17:44:42.744346Z","shell.execute_reply":"2021-07-12T17:44:48.218684Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"y_test = np.argmax(y_test_one_hot, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:44:48.221316Z","iopub.execute_input":"2021-07-12T17:44:48.221662Z","iopub.status.idle":"2021-07-12T17:44:48.227246Z","shell.execute_reply.started":"2021-07-12T17:44:48.221626Z","shell.execute_reply":"2021-07-12T17:44:48.226231Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred_list)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-07-12T17:44:48.229191Z","iopub.execute_input":"2021-07-12T17:44:48.229549Z","iopub.status.idle":"2021-07-12T17:44:48.243828Z","shell.execute_reply.started":"2021-07-12T17:44:48.229515Z","shell.execute_reply":"2021-07-12T17:44:48.242768Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.4503464203233256"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}