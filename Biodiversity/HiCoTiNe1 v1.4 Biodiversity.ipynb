{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Variants-Experiment 1.4\n\n## Concatenated hidden representations and concatenated output logits.\n## Mode. Compute classifications of all tiny networks, in all HiCo layers, and take the mode as the final classification.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\nfrom keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom os import listdir\nfrom os.path import join\nimport cv2\nimport pandas as pd\nimport os\nimport random as rn\nfrom scipy import stats\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nimport pickle\nfrom keras import backend as K","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:09:23.692644Z","iopub.execute_input":"2021-07-12T18:09:23.693040Z","iopub.status.idle":"2021-07-12T18:09:28.896624Z","shell.execute_reply.started":"2021-07-12T18:09:23.692959Z","shell.execute_reply":"2021-07-12T18:09:28.895803Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"SEED = 321\nrn.seed(SEED)\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:09:28.898770Z","iopub.execute_input":"2021-07-12T18:09:28.899056Z","iopub.status.idle":"2021-07-12T18:09:28.906040Z","shell.execute_reply.started":"2021-07-12T18:09:28.899028Z","shell.execute_reply":"2021-07-12T18:09:28.905240Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"SUB_REGION_SCALE = 14\nNUM_HICO_LAYER = 5\nNUM_TN = [10, 8, 6, 4, 2]\nNUM_CONNECTION = [0, 5, 4, 3, 2]\n\n#dataset specific parameters\nNUM_CLASS = 5","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:09:28.909509Z","iopub.execute_input":"2021-07-12T18:09:28.909874Z","iopub.status.idle":"2021-07-12T18:09:28.917660Z","shell.execute_reply.started":"2021-07-12T18:09:28.909845Z","shell.execute_reply":"2021-07-12T18:09:28.916872Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data Pre-Processing","metadata":{}},{"cell_type":"code","source":"with open('../input/hicotine1-layer1-biodiversity/fyp/CIFAR-10.pickle', 'rb') as f:\n    X_train_cropped_list, y_train_one_hot, X_val_cropped_list, y_val_one_hot, X_test_cropped_list, y_test_one_hot, coordinate_list, scale_list = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:09:28.920918Z","iopub.execute_input":"2021-07-12T18:09:28.921208Z","iopub.status.idle":"2021-07-12T18:09:30.965744Z","shell.execute_reply.started":"2021-07-12T18:09:28.921177Z","shell.execute_reply":"2021-07-12T18:09:30.964724Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## HiCo Layer 1","metadata":{}},{"cell_type":"code","source":"#build ANN model\nensemble = []\nfor i in range(NUM_TN[0]):\n  model = Sequential()\n  model.add(Dense(64, activation='relu', input_dim=SUB_REGION_SCALE*SUB_REGION_SCALE*3))\n  model.add(Dense(64, activation='relu'))\n  model.add(Dense(NUM_CLASS, activation = 'softmax'))\n  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n  ensemble.append((model, i, coordinate_list[i], scale_list[i]))","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:09:30.969332Z","iopub.execute_input":"2021-07-12T18:09:30.969833Z","iopub.status.idle":"2021-07-12T18:09:33.351394Z","shell.execute_reply.started":"2021-07-12T18:09:30.969791Z","shell.execute_reply":"2021-07-12T18:09:33.350580Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for i in range(NUM_TN[0]):\n  ensemble[i][0].load_weights('../input/hicotine1-layer1-biodiversity/fyp/CIFAR-10_' + str(i) + '.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:09:33.352671Z","iopub.execute_input":"2021-07-12T18:09:33.353011Z","iopub.status.idle":"2021-07-12T18:09:33.551554Z","shell.execute_reply.started":"2021-07-12T18:09:33.352973Z","shell.execute_reply":"2021-07-12T18:09:33.550796Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"hico_layers = []\nhico_layers.append(ensemble)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:09:33.553283Z","iopub.execute_input":"2021-07-12T18:09:33.553535Z","iopub.status.idle":"2021-07-12T18:09:33.560356Z","shell.execute_reply.started":"2021-07-12T18:09:33.553510Z","shell.execute_reply":"2021-07-12T18:09:33.559516Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"del hico_layers[1:]","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:09:33.561774Z","iopub.execute_input":"2021-07-12T18:09:33.562140Z","iopub.status.idle":"2021-07-12T18:09:33.566927Z","shell.execute_reply.started":"2021-07-12T18:09:33.562106Z","shell.execute_reply":"2021-07-12T18:09:33.565904Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## HiCo Layer 2+","metadata":{}},{"cell_type":"code","source":"# Function to get input of layer i-1\ndef get_previous_layer_input(hico_layers, layer, tn, train_image):\n  input_hr = []\n  input_ol = []\n    \n  if layer == 0:\n    previous_layer_input = train_image[tn[1]]\n    return previous_layer_input\n\n  elif layer > 0:\n    for i in range(NUM_CONNECTION[layer]):\n      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[1].output))\n      input_hr.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n      \n    input_hr = np.array(input_hr)\n    input_hr = np.concatenate(input_hr, axis=1)\n\n    for i in range(NUM_CONNECTION[layer]):\n      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[2].output))\n      input_ol.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n\n    input_ol = np.array(input_ol)\n    input_ol = np.concatenate(input_ol, axis=1)\n\n    input = np.concatenate((input_hr, input_ol), axis=1)\n    \n    previous_layer_input = input\n    return previous_layer_input","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:09:33.569526Z","iopub.execute_input":"2021-07-12T18:09:33.570026Z","iopub.status.idle":"2021-07-12T18:09:33.717597Z","shell.execute_reply.started":"2021-07-12T18:09:33.569983Z","shell.execute_reply":"2021-07-12T18:09:33.716736Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"for i in range(1, NUM_HICO_LAYER):\n  print('Layer %d' %i)\n  ensemble = []\n  X_train_input_list = []\n  X_test_input_list = []\n\n  for j in range(NUM_TN[i]):\n    # Build model of HiCo layer i\n    connection = tuple(rn.sample(range(len(hico_layers[i-1])), k=NUM_CONNECTION[i]))\n    model = Sequential()\n    model.add(Dense(64, activation='relu', input_dim=64*NUM_CONNECTION[i]+NUM_CLASS*NUM_CONNECTION[i]))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(NUM_CLASS, activation = 'softmax'))\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    ensemble.append((model, connection))\n  hico_layers.append(ensemble)\n  print('HICO LENGTH')\n  print(len(hico_layers))\n\n  for j in range(NUM_TN[i]):\n    # Get train hidden representation from HiCo layer i-1\n    X_train_input_hr = []\n    X_train_input_ol = []\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n      X_train_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n    X_train_input_hr = np.array(X_train_input_hr)\n    X_train_input_hr = np.concatenate(X_train_input_hr, axis=1)\n\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n      X_train_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n    X_train_input_ol = np.array(X_train_input_ol)\n    X_train_input_ol = np.concatenate(X_train_input_ol, axis=1)\n\n    X_train_input = np.concatenate((X_train_input_hr, X_train_input_ol), axis=1)\n    X_train_input_list.append(X_train_input)\n\n    # Get test hidden representation from HiCo layer i-1\n    X_test_input_hr = []\n    X_test_input_ol = []\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n      X_test_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n    X_test_input_hr = np.array(X_test_input_hr)\n    X_test_input_hr = np.concatenate(X_test_input_hr, axis=1)\n\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n      X_test_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n    X_test_input_ol = np.array(X_test_input_ol)\n    X_test_input_ol = np.concatenate(X_test_input_ol, axis=1)\n\n    X_test_input = np.concatenate((X_test_input_hr, X_test_input_ol), axis=1)\n    X_test_input_list.append(X_test_input)\n\n  #train model of HiCo layer i\n  for j in range(NUM_TN[i]):\n    print('Model %d' %j)\n    hico_layers[i][j][0].fit(X_train_input_list[j], y_train_one_hot, validation_data=(X_test_input_list[j], y_test_one_hot), epochs=5, batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:09:33.719028Z","iopub.execute_input":"2021-07-12T18:09:33.719372Z","iopub.status.idle":"2021-07-12T18:11:13.698870Z","shell.execute_reply.started":"2021-07-12T18:09:33.719338Z","shell.execute_reply":"2021-07-12T18:11:13.697959Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Layer 1\nHICO LENGTH\n2\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 21ms/step - loss: 1.5445 - accuracy: 0.3048 - val_loss: 1.2967 - val_accuracy: 0.4180\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2381 - accuracy: 0.4509 - val_loss: 1.2632 - val_accuracy: 0.4388\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2339 - accuracy: 0.4721 - val_loss: 1.2721 - val_accuracy: 0.4550\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2114 - accuracy: 0.4906 - val_loss: 1.2449 - val_accuracy: 0.4758\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1521 - accuracy: 0.4958 - val_loss: 1.2580 - val_accuracy: 0.4573\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5504 - accuracy: 0.2897 - val_loss: 1.3163 - val_accuracy: 0.3903\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2380 - accuracy: 0.4505 - val_loss: 1.2710 - val_accuracy: 0.4619\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2289 - accuracy: 0.4683 - val_loss: 1.2765 - val_accuracy: 0.4573\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2040 - accuracy: 0.4935 - val_loss: 1.2575 - val_accuracy: 0.4642\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1501 - accuracy: 0.5023 - val_loss: 1.2656 - val_accuracy: 0.4550\nModel 2\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4677 - accuracy: 0.3578 - val_loss: 1.3101 - val_accuracy: 0.4157\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2384 - accuracy: 0.4506 - val_loss: 1.2765 - val_accuracy: 0.4203\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2351 - accuracy: 0.4820 - val_loss: 1.2833 - val_accuracy: 0.4619\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2189 - accuracy: 0.4828 - val_loss: 1.2563 - val_accuracy: 0.4642\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1619 - accuracy: 0.4879 - val_loss: 1.2674 - val_accuracy: 0.4249\nModel 3\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5144 - accuracy: 0.3073 - val_loss: 1.3255 - val_accuracy: 0.3926\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2433 - accuracy: 0.4476 - val_loss: 1.2764 - val_accuracy: 0.4411\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2312 - accuracy: 0.4740 - val_loss: 1.2838 - val_accuracy: 0.4527\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2110 - accuracy: 0.4854 - val_loss: 1.2538 - val_accuracy: 0.4573\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1679 - accuracy: 0.4957 - val_loss: 1.2689 - val_accuracy: 0.4434\nModel 4\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4933 - accuracy: 0.3154 - val_loss: 1.3133 - val_accuracy: 0.4365\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2288 - accuracy: 0.4608 - val_loss: 1.2784 - val_accuracy: 0.4573\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2309 - accuracy: 0.4862 - val_loss: 1.2738 - val_accuracy: 0.4781\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1948 - accuracy: 0.4941 - val_loss: 1.2604 - val_accuracy: 0.4665\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1588 - accuracy: 0.5096 - val_loss: 1.2695 - val_accuracy: 0.4527\nModel 5\nEpoch 1/5\n28/28 [==============================] - 1s 12ms/step - loss: 1.5342 - accuracy: 0.2968 - val_loss: 1.3130 - val_accuracy: 0.4042\nEpoch 2/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.2487 - accuracy: 0.4317 - val_loss: 1.2923 - val_accuracy: 0.4365\nEpoch 3/5\n28/28 [==============================] - 0s 5ms/step - loss: 1.2513 - accuracy: 0.4584 - val_loss: 1.3077 - val_accuracy: 0.4434\nEpoch 4/5\n28/28 [==============================] - 0s 5ms/step - loss: 1.2294 - accuracy: 0.4674 - val_loss: 1.2630 - val_accuracy: 0.4480\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1787 - accuracy: 0.4905 - val_loss: 1.2676 - val_accuracy: 0.4411\nModel 6\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4607 - accuracy: 0.3583 - val_loss: 1.3216 - val_accuracy: 0.4042\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2106 - accuracy: 0.4595 - val_loss: 1.2841 - val_accuracy: 0.4457\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2128 - accuracy: 0.4793 - val_loss: 1.2948 - val_accuracy: 0.4688\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1801 - accuracy: 0.5000 - val_loss: 1.2671 - val_accuracy: 0.4527\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1357 - accuracy: 0.5027 - val_loss: 1.2580 - val_accuracy: 0.4573\nModel 7\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4445 - accuracy: 0.3518 - val_loss: 1.3130 - val_accuracy: 0.4411\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2300 - accuracy: 0.4589 - val_loss: 1.2589 - val_accuracy: 0.4503\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2290 - accuracy: 0.4941 - val_loss: 1.2658 - val_accuracy: 0.4596\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.2027 - accuracy: 0.4860 - val_loss: 1.2411 - val_accuracy: 0.4734\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1618 - accuracy: 0.4971 - val_loss: 1.2395 - val_accuracy: 0.4804\nLayer 2\nHICO LENGTH\n3\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4849 - accuracy: 0.3445 - val_loss: 1.2918 - val_accuracy: 0.4527\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1843 - accuracy: 0.4903 - val_loss: 1.2522 - val_accuracy: 0.4596\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1885 - accuracy: 0.5107 - val_loss: 1.2596 - val_accuracy: 0.4457\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1608 - accuracy: 0.5310 - val_loss: 1.2478 - val_accuracy: 0.4434\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1213 - accuracy: 0.5297 - val_loss: 1.2543 - val_accuracy: 0.4573\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5223 - accuracy: 0.3151 - val_loss: 1.2786 - val_accuracy: 0.4319\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1789 - accuracy: 0.5056 - val_loss: 1.2543 - val_accuracy: 0.4873\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1843 - accuracy: 0.5072 - val_loss: 1.2559 - val_accuracy: 0.4804\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1497 - accuracy: 0.5317 - val_loss: 1.2359 - val_accuracy: 0.4711\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.5472 - val_loss: 1.2419 - val_accuracy: 0.4688\nModel 2\nEpoch 1/5\n28/28 [==============================] - 1s 15ms/step - loss: 1.4925 - accuracy: 0.3458 - val_loss: 1.2757 - val_accuracy: 0.4388\nEpoch 2/5\n28/28 [==============================] - 0s 6ms/step - loss: 1.1664 - accuracy: 0.4987 - val_loss: 1.2666 - val_accuracy: 0.4665\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1779 - accuracy: 0.5084 - val_loss: 1.2625 - val_accuracy: 0.4642\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1466 - accuracy: 0.5331 - val_loss: 1.2540 - val_accuracy: 0.4642\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1045 - accuracy: 0.5290 - val_loss: 1.2575 - val_accuracy: 0.4503\nModel 3\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4743 - accuracy: 0.3619 - val_loss: 1.2926 - val_accuracy: 0.4457\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1759 - accuracy: 0.4995 - val_loss: 1.2455 - val_accuracy: 0.4665\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1811 - accuracy: 0.4958 - val_loss: 1.2492 - val_accuracy: 0.4642\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1622 - accuracy: 0.5221 - val_loss: 1.2409 - val_accuracy: 0.4804\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1082 - accuracy: 0.5380 - val_loss: 1.2482 - val_accuracy: 0.4665\nModel 4\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4282 - accuracy: 0.3754 - val_loss: 1.2893 - val_accuracy: 0.4457\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1930 - accuracy: 0.4842 - val_loss: 1.2533 - val_accuracy: 0.4850\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1902 - accuracy: 0.5001 - val_loss: 1.2498 - val_accuracy: 0.4827\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1546 - accuracy: 0.5202 - val_loss: 1.2436 - val_accuracy: 0.4734\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1093 - accuracy: 0.5409 - val_loss: 1.2410 - val_accuracy: 0.4781\nModel 5\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4426 - accuracy: 0.3676 - val_loss: 1.2912 - val_accuracy: 0.4273\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1723 - accuracy: 0.4856 - val_loss: 1.2711 - val_accuracy: 0.4642\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1736 - accuracy: 0.5120 - val_loss: 1.2621 - val_accuracy: 0.4619\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1463 - accuracy: 0.5188 - val_loss: 1.2532 - val_accuracy: 0.4711\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1031 - accuracy: 0.5295 - val_loss: 1.2508 - val_accuracy: 0.4596\nLayer 3\nHICO LENGTH\n4\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4175 - accuracy: 0.3900 - val_loss: 1.2611 - val_accuracy: 0.4688\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1364 - accuracy: 0.5212 - val_loss: 1.2484 - val_accuracy: 0.4734\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1496 - accuracy: 0.5248 - val_loss: 1.2504 - val_accuracy: 0.4711\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1231 - accuracy: 0.5451 - val_loss: 1.2381 - val_accuracy: 0.4734\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0797 - accuracy: 0.5550 - val_loss: 1.2498 - val_accuracy: 0.4550\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.5349 - accuracy: 0.3747 - val_loss: 1.2761 - val_accuracy: 0.4688\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1432 - accuracy: 0.5301 - val_loss: 1.2490 - val_accuracy: 0.4665\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1416 - accuracy: 0.5333 - val_loss: 1.2411 - val_accuracy: 0.4596\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1201 - accuracy: 0.5495 - val_loss: 1.2426 - val_accuracy: 0.4988\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0758 - accuracy: 0.5557 - val_loss: 1.2475 - val_accuracy: 0.4550\nModel 2\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4626 - accuracy: 0.3636 - val_loss: 1.2747 - val_accuracy: 0.4642\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1451 - accuracy: 0.5248 - val_loss: 1.2407 - val_accuracy: 0.4758\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1478 - accuracy: 0.5322 - val_loss: 1.2370 - val_accuracy: 0.4827\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1169 - accuracy: 0.5419 - val_loss: 1.2365 - val_accuracy: 0.4896\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0785 - accuracy: 0.5531 - val_loss: 1.2424 - val_accuracy: 0.4711\nModel 3\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4159 - accuracy: 0.3537 - val_loss: 1.2777 - val_accuracy: 0.4619\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1386 - accuracy: 0.5218 - val_loss: 1.2491 - val_accuracy: 0.4827\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1441 - accuracy: 0.5348 - val_loss: 1.2459 - val_accuracy: 0.4758\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1171 - accuracy: 0.5488 - val_loss: 1.2427 - val_accuracy: 0.4919\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0770 - accuracy: 0.5568 - val_loss: 1.2468 - val_accuracy: 0.4781\nLayer 4\nHICO LENGTH\n5\nModel 0\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.4866 - accuracy: 0.3764 - val_loss: 1.2794 - val_accuracy: 0.4804\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1320 - accuracy: 0.5360 - val_loss: 1.2567 - val_accuracy: 0.4896\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1328 - accuracy: 0.5416 - val_loss: 1.2543 - val_accuracy: 0.5081\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1052 - accuracy: 0.5527 - val_loss: 1.2501 - val_accuracy: 0.5081\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0669 - accuracy: 0.5580 - val_loss: 1.2591 - val_accuracy: 0.4688\nModel 1\nEpoch 1/5\n28/28 [==============================] - 1s 9ms/step - loss: 1.3792 - accuracy: 0.4118 - val_loss: 1.2578 - val_accuracy: 0.4896\nEpoch 2/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1250 - accuracy: 0.5422 - val_loss: 1.2578 - val_accuracy: 0.5081\nEpoch 3/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1296 - accuracy: 0.5442 - val_loss: 1.2596 - val_accuracy: 0.4873\nEpoch 4/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.1039 - accuracy: 0.5560 - val_loss: 1.2486 - val_accuracy: 0.4919\nEpoch 5/5\n28/28 [==============================] - 0s 4ms/step - loss: 1.0676 - accuracy: 0.5611 - val_loss: 1.2571 - val_accuracy: 0.4711\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"# Predict on test image\ny_pred_list = []\nfor j in range(NUM_TN[0]):\n  y_pred = np.argmax(hico_layers[0][j][0].predict(X_test_cropped_list[j]), axis=1)\n  y_pred_list.append(y_pred)\n\nfor i in range(1, NUM_HICO_LAYER):\n  for j in range(NUM_TN[i]):\n\n    # Get test hidden representation from HiCo layer i-1\n    X_test_input_hr = []\n    X_test_input_ol = []\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n      X_test_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n    X_test_input_hr = np.array(X_test_input_hr)\n    X_test_input_hr = np.concatenate(X_test_input_hr, axis=1)\n\n    for k in range(NUM_CONNECTION[i]):\n      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n      X_test_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n    X_test_input_ol = np.array(X_test_input_ol)\n    X_test_input_ol = np.concatenate(X_test_input_ol, axis=1)\n\n    X_test_input = np.concatenate((X_test_input_hr, X_test_input_ol), axis=1)\n\n    y_pred = np.argmax(hico_layers[i][j][0].predict(X_test_input), axis=1)\n    y_pred_list.append(y_pred)\n\n# HiCo voting (mode)\ny_pred_list = np.array(y_pred_list)\ny_pred_list = np.transpose(y_pred_list, (1, 0))\ny_pred_list = stats.mode(y_pred_list, axis=1)[0]\ny_pred_list = np.squeeze(y_pred_list)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:11:13.700572Z","iopub.execute_input":"2021-07-12T18:11:13.700931Z","iopub.status.idle":"2021-07-12T18:11:44.496569Z","shell.execute_reply.started":"2021-07-12T18:11:13.700893Z","shell.execute_reply":"2021-07-12T18:11:44.495728Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"y_test = np.argmax(y_test_one_hot, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:11:44.497743Z","iopub.execute_input":"2021-07-12T18:11:44.498093Z","iopub.status.idle":"2021-07-12T18:11:44.504754Z","shell.execute_reply.started":"2021-07-12T18:11:44.498058Z","shell.execute_reply":"2021-07-12T18:11:44.503979Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred_list)\naccuracy","metadata":{"execution":{"iopub.status.busy":"2021-07-12T18:11:44.506200Z","iopub.execute_input":"2021-07-12T18:11:44.506559Z","iopub.status.idle":"2021-07-12T18:11:44.516821Z","shell.execute_reply.started":"2021-07-12T18:11:44.506523Z","shell.execute_reply":"2021-07-12T18:11:44.515713Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0.46882217090069284"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}