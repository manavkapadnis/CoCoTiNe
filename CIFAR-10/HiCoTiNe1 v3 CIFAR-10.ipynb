{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HiCoTiNe1 v3 CIFAR-10.ipynb","provenance":[{"file_id":"19guF-U3KgRWG2yOuNYWGUTWs2FP2582B","timestamp":1615843192315}],"collapsed_sections":[],"authorship_tag":"ABX9TyN5U2A4Mfmi6crZMdN5b4L6"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OVQ7Bo8hJIUb"},"source":["# Variants-Experiment 3.1, 3.2, 3.3.1, 3.3.2. Adapted from HiCoTiNe v2.1\n","## Concatenated hidden representations.\n","## No raw input"]},{"cell_type":"code","metadata":{"id":"AW5zp22ze_5Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620638427525,"user_tz":-480,"elapsed":26686,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"9b956c82-e890-4f5f-9574-57f193d25ca7"},"source":[" from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten\n","from keras.datasets import mnist\n","from keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import random\n","from scipy import stats\n","from sklearn.metrics import accuracy_score\n","from keras import backend as K\n","\n","import os\n","import pickle\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pL2zNY1Pqo43","executionInfo":{"status":"ok","timestamp":1620638427527,"user_tz":-480,"elapsed":26686,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["SUB_REGION_SCALE = 14\n","NUM_HICO_LAYER = 5\n","NUM_TN = [10, 8, 6 , 4, 2]\n","NUM_CONNECTION = [0, 5, 4, 3, 2]\n","ALPHA = 0.1\n","\n","#dataset specific parameters\n","NUM_CLASS = 10"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sV1QzfMXoD_c"},"source":["## Data Pre-Processing"]},{"cell_type":"code","metadata":{"id":"CK8Jo8eFjW0R","executionInfo":{"status":"ok","timestamp":1620638456853,"user_tz":-480,"elapsed":56010,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["with open('/content/drive/My Drive/fyp/CIFAR-10.pickle', 'rb') as f:\n","    X_train_cropped_list, y_train_one_hot, X_test_cropped_list, y_test_one_hot, coordinate_list, scale_list = pickle.load(f)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NYkFwl7RbAnt"},"source":["## HiCo Layer 1"]},{"cell_type":"code","metadata":{"id":"mZxSK0dGZsGo","executionInfo":{"status":"ok","timestamp":1620638457592,"user_tz":-480,"elapsed":56747,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["#build ANN model\n","ensemble = []\n","for i in range(NUM_TN[0]):\n","  model = Sequential()\n","  model.add(Dense(64, activation='relu', input_dim=SUB_REGION_SCALE*SUB_REGION_SCALE*3))\n","  model.add(Dense(64, activation='relu'))\n","  model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","  ensemble.append((model, i, coordinate_list[i], scale_list[i]))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2K4jfWOkcSz","executionInfo":{"status":"ok","timestamp":1620638459793,"user_tz":-480,"elapsed":58947,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["for i in range(NUM_TN[0]):\n","  ensemble[i][0].load_weights('/content/drive/My Drive/fyp/CIFAR-10_' + str(i) + '.h5')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"-r3DBZWMb9eX","executionInfo":{"status":"ok","timestamp":1620638459796,"user_tz":-480,"elapsed":58947,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["hico_layers = []\n","hico_layers.append(ensemble)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AKc-KKMj278","executionInfo":{"status":"ok","timestamp":1620638459796,"user_tz":-480,"elapsed":58944,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["del hico_layers[1:]"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CvSwQtBibHqz"},"source":["## HiCo Layer 2+"]},{"cell_type":"code","metadata":{"id":"MCxjRA6lqoaA","executionInfo":{"status":"ok","timestamp":1620638459797,"user_tz":-480,"elapsed":58944,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Function to get input of layer i-1\n","def get_previous_layer_input(hico_layers, layer, tn, train_image):\n","  input = []\n","    \n","  if layer == 0:\n","    previous_layer_input = train_image[tn[1]]\n","    return previous_layer_input\n","\n","  elif layer > 0:\n","    for i in range(NUM_CONNECTION[layer]):\n","      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[1].output))\n","      input.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n","      \n","    input = np.array(input)\n","    input = np.concatenate(input, axis=1)\n","    previous_layer_input = input\n","    return previous_layer_input"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZLXI5D6lneY","executionInfo":{"status":"ok","timestamp":1620638776219,"user_tz":-480,"elapsed":375336,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"330ae1ad-b6ae-4348-8432-777cfb459fb9"},"source":["for i in range(1, NUM_HICO_LAYER):\n","  print('Layer %d' %i)\n","  ensemble = []\n","  X_train_input_list = []\n","  X_test_input_list = []\n","\n","  for j in range(NUM_TN[i]):\n","    # Build model of HiCo layer i\n","    connection = tuple(random.sample(range(len(hico_layers[i-1])), k=NUM_CONNECTION[i]))\n","    model = Sequential()\n","    model.add(Dense(64, activation='relu', input_dim=64*NUM_CONNECTION[i]))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    ensemble.append((model, connection))\n","  hico_layers.append(ensemble)\n","  print('HICO LENGTH')\n","  print(len(hico_layers))\n","\n","  for j in range(NUM_TN[i]):\n","    # Get train hidden representation from HiCo layer i-1\n","    X_train_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_train_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n","    X_train_input = np.array(X_train_input)\n","    X_train_input = np.concatenate(X_train_input, axis=1)\n","    X_train_input_list.append(X_train_input)\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    X_test_input_list.append(X_test_input)\n","\n","  #train model of HiCo layer i\n","  for j in range(NUM_TN[i]):\n","    print('Model %d' %j)\n","    hico_layers[i][j][0].fit(X_train_input_list[j], y_train_one_hot, validation_data=(X_test_input_list[j], y_test_one_hot), epochs=5, batch_size=128)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Layer 1\n","HICO LENGTH\n","2\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 2s 4ms/step - loss: 1.7734 - accuracy: 0.3696 - val_loss: 1.5447 - val_accuracy: 0.4399\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.5041 - accuracy: 0.4575 - val_loss: 1.5082 - val_accuracy: 0.4580\n","Epoch 3/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4596 - accuracy: 0.4745 - val_loss: 1.4786 - val_accuracy: 0.4718\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4259 - accuracy: 0.4887 - val_loss: 1.4590 - val_accuracy: 0.4713\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4087 - accuracy: 0.4965 - val_loss: 1.4705 - val_accuracy: 0.4680\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.8396 - accuracy: 0.3321 - val_loss: 1.5753 - val_accuracy: 0.4360\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.5345 - accuracy: 0.4523 - val_loss: 1.5349 - val_accuracy: 0.4543\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4915 - accuracy: 0.4656 - val_loss: 1.5272 - val_accuracy: 0.4635\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4623 - accuracy: 0.4781 - val_loss: 1.5179 - val_accuracy: 0.4595\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4399 - accuracy: 0.4853 - val_loss: 1.5052 - val_accuracy: 0.4668\n","Model 2\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.8074 - accuracy: 0.3577 - val_loss: 1.5440 - val_accuracy: 0.4439\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.5202 - accuracy: 0.4552 - val_loss: 1.5064 - val_accuracy: 0.4624\n","Epoch 3/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4756 - accuracy: 0.4715 - val_loss: 1.4884 - val_accuracy: 0.4677\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4345 - accuracy: 0.4843 - val_loss: 1.4764 - val_accuracy: 0.4675\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4292 - accuracy: 0.4902 - val_loss: 1.4550 - val_accuracy: 0.4807\n","Model 3\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.7456 - accuracy: 0.3687 - val_loss: 1.5300 - val_accuracy: 0.4458\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4877 - accuracy: 0.4654 - val_loss: 1.4758 - val_accuracy: 0.4697\n","Epoch 3/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4333 - accuracy: 0.4851 - val_loss: 1.4498 - val_accuracy: 0.4834\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4057 - accuracy: 0.4995 - val_loss: 1.4402 - val_accuracy: 0.4866\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.3893 - accuracy: 0.5013 - val_loss: 1.4521 - val_accuracy: 0.4754\n","Model 4\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.8114 - accuracy: 0.3376 - val_loss: 1.6113 - val_accuracy: 0.4234\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.5536 - accuracy: 0.4470 - val_loss: 1.5490 - val_accuracy: 0.4525\n","Epoch 3/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.5138 - accuracy: 0.4595 - val_loss: 1.5303 - val_accuracy: 0.4578\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4781 - accuracy: 0.4717 - val_loss: 1.5272 - val_accuracy: 0.4609\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4744 - accuracy: 0.4753 - val_loss: 1.5148 - val_accuracy: 0.4648\n","Model 5\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.7353 - accuracy: 0.3800 - val_loss: 1.4797 - val_accuracy: 0.4681\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4525 - accuracy: 0.4795 - val_loss: 1.4634 - val_accuracy: 0.4786\n","Epoch 3/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4021 - accuracy: 0.4965 - val_loss: 1.4301 - val_accuracy: 0.4908\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.3793 - accuracy: 0.5107 - val_loss: 1.4227 - val_accuracy: 0.4932\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.3602 - accuracy: 0.5163 - val_loss: 1.4083 - val_accuracy: 0.5049\n","Model 6\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.7128 - accuracy: 0.3856 - val_loss: 1.4633 - val_accuracy: 0.4734\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4246 - accuracy: 0.4893 - val_loss: 1.4301 - val_accuracy: 0.4969\n","Epoch 3/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.3689 - accuracy: 0.5092 - val_loss: 1.4161 - val_accuracy: 0.4920\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.3580 - accuracy: 0.5139 - val_loss: 1.3910 - val_accuracy: 0.5046\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.3288 - accuracy: 0.5269 - val_loss: 1.4113 - val_accuracy: 0.4944\n","Model 7\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.7035 - accuracy: 0.3859 - val_loss: 1.4640 - val_accuracy: 0.4725\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4235 - accuracy: 0.4913 - val_loss: 1.4308 - val_accuracy: 0.4846\n","Epoch 3/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.3829 - accuracy: 0.5085 - val_loss: 1.4036 - val_accuracy: 0.4973\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.3587 - accuracy: 0.5175 - val_loss: 1.3928 - val_accuracy: 0.5029\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.3431 - accuracy: 0.5226 - val_loss: 1.3816 - val_accuracy: 0.5062\n","Layer 2\n","HICO LENGTH\n","3\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.5162 - accuracy: 0.4575 - val_loss: 1.3634 - val_accuracy: 0.5143\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2746 - accuracy: 0.5489 - val_loss: 1.3580 - val_accuracy: 0.5173\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2508 - accuracy: 0.5588 - val_loss: 1.3466 - val_accuracy: 0.5255\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2309 - accuracy: 0.5630 - val_loss: 1.3621 - val_accuracy: 0.5177\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2305 - accuracy: 0.5659 - val_loss: 1.3334 - val_accuracy: 0.5262\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.5390 - accuracy: 0.4537 - val_loss: 1.3881 - val_accuracy: 0.5048\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.3090 - accuracy: 0.5315 - val_loss: 1.3672 - val_accuracy: 0.5104\n","Epoch 3/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2758 - accuracy: 0.5457 - val_loss: 1.3493 - val_accuracy: 0.5190\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2692 - accuracy: 0.5480 - val_loss: 1.3545 - val_accuracy: 0.5140\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2637 - accuracy: 0.5481 - val_loss: 1.3642 - val_accuracy: 0.5137\n","Model 2\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.5289 - accuracy: 0.4614 - val_loss: 1.3638 - val_accuracy: 0.5132\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2797 - accuracy: 0.5449 - val_loss: 1.3441 - val_accuracy: 0.5219\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2640 - accuracy: 0.5522 - val_loss: 1.3339 - val_accuracy: 0.5302\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2398 - accuracy: 0.5598 - val_loss: 1.3350 - val_accuracy: 0.5287\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2454 - accuracy: 0.5593 - val_loss: 1.3452 - val_accuracy: 0.5252\n","Model 3\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.5512 - accuracy: 0.4546 - val_loss: 1.3717 - val_accuracy: 0.5146\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2977 - accuracy: 0.5355 - val_loss: 1.3593 - val_accuracy: 0.5157\n","Epoch 3/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2702 - accuracy: 0.5513 - val_loss: 1.3458 - val_accuracy: 0.5200\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2644 - accuracy: 0.5509 - val_loss: 1.3433 - val_accuracy: 0.5218\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2473 - accuracy: 0.5562 - val_loss: 1.3599 - val_accuracy: 0.5179\n","Model 4\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.5232 - accuracy: 0.4545 - val_loss: 1.3506 - val_accuracy: 0.5180\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2691 - accuracy: 0.5471 - val_loss: 1.3476 - val_accuracy: 0.5191\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2499 - accuracy: 0.5561 - val_loss: 1.3392 - val_accuracy: 0.5227\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2381 - accuracy: 0.5596 - val_loss: 1.3282 - val_accuracy: 0.5227\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2198 - accuracy: 0.5665 - val_loss: 1.3584 - val_accuracy: 0.5124\n","Model 5\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.5223 - accuracy: 0.4634 - val_loss: 1.3683 - val_accuracy: 0.5125\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2851 - accuracy: 0.5410 - val_loss: 1.3553 - val_accuracy: 0.5101\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2650 - accuracy: 0.5485 - val_loss: 1.3522 - val_accuracy: 0.5149\n","Epoch 4/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2503 - accuracy: 0.5555 - val_loss: 1.3567 - val_accuracy: 0.5141\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2425 - accuracy: 0.5570 - val_loss: 1.3336 - val_accuracy: 0.5234\n","Layer 3\n","HICO LENGTH\n","4\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.5060 - accuracy: 0.4787 - val_loss: 1.3312 - val_accuracy: 0.5281\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2275 - accuracy: 0.5679 - val_loss: 1.3266 - val_accuracy: 0.5328\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2169 - accuracy: 0.5665 - val_loss: 1.3324 - val_accuracy: 0.5264\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2097 - accuracy: 0.5714 - val_loss: 1.3331 - val_accuracy: 0.5288\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2016 - accuracy: 0.5757 - val_loss: 1.3142 - val_accuracy: 0.5333\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.4331 - accuracy: 0.4941 - val_loss: 1.3413 - val_accuracy: 0.5245\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2225 - accuracy: 0.5665 - val_loss: 1.3308 - val_accuracy: 0.5250\n","Epoch 3/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2181 - accuracy: 0.5690 - val_loss: 1.3387 - val_accuracy: 0.5262\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2101 - accuracy: 0.5731 - val_loss: 1.3196 - val_accuracy: 0.5271\n","Epoch 5/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2026 - accuracy: 0.5718 - val_loss: 1.3273 - val_accuracy: 0.5301\n","Model 2\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.4120 - accuracy: 0.4983 - val_loss: 1.3386 - val_accuracy: 0.5270\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2266 - accuracy: 0.5663 - val_loss: 1.3281 - val_accuracy: 0.5280\n","Epoch 3/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2074 - accuracy: 0.5708 - val_loss: 1.3152 - val_accuracy: 0.5301\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2095 - accuracy: 0.5712 - val_loss: 1.3190 - val_accuracy: 0.5342\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2017 - accuracy: 0.5740 - val_loss: 1.3206 - val_accuracy: 0.5256\n","Model 3\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.4757 - accuracy: 0.4882 - val_loss: 1.3292 - val_accuracy: 0.5312\n","Epoch 2/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.2172 - accuracy: 0.5707 - val_loss: 1.3382 - val_accuracy: 0.5240\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1961 - accuracy: 0.5777 - val_loss: 1.3129 - val_accuracy: 0.5347\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1988 - accuracy: 0.5765 - val_loss: 1.3181 - val_accuracy: 0.5323\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1930 - accuracy: 0.5780 - val_loss: 1.3175 - val_accuracy: 0.5281\n","Layer 4\n","HICO LENGTH\n","5\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4400 - accuracy: 0.4930 - val_loss: 1.3258 - val_accuracy: 0.5310\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2009 - accuracy: 0.5758 - val_loss: 1.3294 - val_accuracy: 0.5318\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1920 - accuracy: 0.5797 - val_loss: 1.3350 - val_accuracy: 0.5262\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1961 - accuracy: 0.5751 - val_loss: 1.3249 - val_accuracy: 0.5327\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1920 - accuracy: 0.5750 - val_loss: 1.3272 - val_accuracy: 0.5305\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.4379 - accuracy: 0.4983 - val_loss: 1.3312 - val_accuracy: 0.5304\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1980 - accuracy: 0.5761 - val_loss: 1.3155 - val_accuracy: 0.5327\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1887 - accuracy: 0.5796 - val_loss: 1.3212 - val_accuracy: 0.5304\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1918 - accuracy: 0.5801 - val_loss: 1.3236 - val_accuracy: 0.5331\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1850 - accuracy: 0.5804 - val_loss: 1.3172 - val_accuracy: 0.5359\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4ZCjVj0ioNb6"},"source":["## Model Evaluation"]},{"cell_type":"code","metadata":{"id":"hn8WGeu-rl-U","executionInfo":{"status":"ok","timestamp":1620638776219,"user_tz":-480,"elapsed":375334,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["y_test = np.argmax(y_test_one_hot, axis=1)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5hLPV9-XgZcY"},"source":["### HiCoTiNe1 v3.1\n","cc1. Mode. Compute classifications of all tiny networks, in all HiCo layers, and take the mode as the final classification."]},{"cell_type":"code","metadata":{"id":"-wsBlIBONSIN","executionInfo":{"status":"ok","timestamp":1620638819718,"user_tz":-480,"elapsed":418832,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = np.argmax(hico_layers[0][j][0].predict(X_test_cropped_list[j]), axis=1)\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = np.argmax(hico_layers[i][j][0].predict(X_test_input), axis=1)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0))\n","y_pred_list = stats.mode(y_pred_list, axis=1)[0]\n","y_pred_list = np.squeeze(y_pred_list)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZ6nor6wRK_k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620638819718,"user_tz":-480,"elapsed":418825,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"4c262215-6ed1-4e00-c3b0-4ad004562ec3"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5296"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"kSjNM3tzg4C9"},"source":["### HiCoTiNe v3.2\n","cc2. Sum the logits of all TNs. Take the max logit as the final classification."]},{"cell_type":"code","metadata":{"id":"7AKpmhMtg-IX","executionInfo":{"status":"ok","timestamp":1620638861690,"user_tz":-480,"elapsed":460795,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = hico_layers[0][j][0].predict(X_test_cropped_list[j])\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = hico_layers[i][j][0].predict(X_test_input)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0, 2))\n","y_pred_list = np.argmax(np.sum(y_pred_list, axis=1), axis=1)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3AmcOiQh4QM","executionInfo":{"status":"ok","timestamp":1620638861691,"user_tz":-480,"elapsed":460789,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"4f41b442-20f5-43d6-cb63-26955b5daef6"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.531"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"EvqdeEpVo0IU"},"source":["### HiCoTiNe v3.3.1\n","cc3. Weighted function. Compute classifications (votes) of all tiny networks, in all HiCo layers. Compute weight of each classifier/vote. Compute weighted sum of votes. Weights can be computed in different ways, e.g.:\n","- cc3w1. The weight of each classifier/TN is inversely proportional to the number of TNs in its HiCo layer, relative to the HiCo layer with the most TNs. E.g. if n is the number of TNs in the layer with the most TNs, then compute v/n for each layer, where v is the number of TNs in each layer; then compute the weight of each layer as (1+alpha)-(v/n), where alpha is some small threshold; and finally define the weight of each TN as the weight of its layer.\n"]},{"cell_type":"code","metadata":{"id":"1E2-2iH5pIzI","executionInfo":{"status":"ok","timestamp":1620638904092,"user_tz":-480,"elapsed":503188,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = hico_layers[0][j][0].predict(X_test_cropped_list[j])\n","  y_pred = y_pred * ((1 + ALPHA) - (NUM_TN[0] / max(NUM_TN)))\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = hico_layers[i][j][0].predict(X_test_input)\n","    y_pred = y_pred * ((1 + ALPHA) - (NUM_TN[i] / max(NUM_TN)))\n","    y_pred_list.append(y_pred)\n","\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0, 2))\n","y_pred_list = np.argmax(np.sum(y_pred_list, axis=1), axis=1)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K2HPvU_NvSvT","executionInfo":{"status":"ok","timestamp":1620638904093,"user_tz":-480,"elapsed":503182,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"3b3bf2f3-65f5-46b5-ab0d-3128394ff3c6"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5346"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"lCCv0nO9pJnb"},"source":["### HiCoTiNe v3.3.2\n","cc3. Weighted function. Compute classifications (votes) of all tiny networks, in all HiCo layers. Compute weight of each classifier/vote. Compute weighted sum of votes. Weights can be computed in different ways, e.g.:\n","- cc3w2. The weight of each classifier is directly proportional to the depth of the HiCo layer within which it resides. \n"]},{"cell_type":"code","metadata":{"id":"YqBbgiRqpQeC","executionInfo":{"status":"ok","timestamp":1620638946078,"user_tz":-480,"elapsed":545165,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = hico_layers[0][j][0].predict(X_test_cropped_list[j])\n","  y_pred = y_pred * (1 / NUM_HICO_LAYER)\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = hico_layers[i][j][0].predict(X_test_input)\n","    y_pred = y_pred * (i / NUM_HICO_LAYER)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0, 2))\n","y_pred_list = np.argmax(np.sum(y_pred_list, axis=1), axis=1)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfK2nrhzdX-e","executionInfo":{"status":"ok","timestamp":1620638946079,"user_tz":-480,"elapsed":545159,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"c45b8dfd-8efa-47f2-8bea-fdb7021d87ca"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5346"]},"metadata":{"tags":[]},"execution_count":18}]}]}