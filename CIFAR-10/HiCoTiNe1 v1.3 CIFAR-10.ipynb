{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HiCoTiNe1 v1.3 CIFAR-10.ipynb","provenance":[{"file_id":"19guF-U3KgRWG2yOuNYWGUTWs2FP2582B","timestamp":1615843192315}],"collapsed_sections":[],"authorship_tag":"ABX9TyOV/ee+juTiJnjf+TQM8OFw"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OVQ7Bo8hJIUb"},"source":["# Variants-Experiment 1.3\n","\n","## Concatenated hidden representations and summed output logits.\n","## Mode. Compute classifications of all tiny networks, in all HiCo layers, and take the mode as the final classification.\n"]},{"cell_type":"code","metadata":{"id":"AW5zp22ze_5Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620637660125,"user_tz":-480,"elapsed":134018,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"8083f20f-ed96-40db-a88b-c61b33b436c9"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten\n","from keras.datasets import mnist\n","from keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import random\n","from scipy import stats\n","from sklearn.metrics import accuracy_score\n","from keras import backend as K\n","\n","import os\n","import pickle\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pL2zNY1Pqo43","executionInfo":{"status":"ok","timestamp":1620637660126,"user_tz":-480,"elapsed":134010,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["SUB_REGION_SCALE = 14\n","NUM_HICO_LAYER = 5\n","NUM_TN = [10, 8, 6, 4, 2]\n","NUM_CONNECTION = [0, 5, 4, 3, 2]\n","\n","#dataset specific parameters\n","NUM_CLASS = 10"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sV1QzfMXoD_c"},"source":["## Data Pre-Processing"]},{"cell_type":"code","metadata":{"id":"VcXGU4GIuo8e","executionInfo":{"status":"ok","timestamp":1620637702080,"user_tz":-480,"elapsed":175959,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["with open('/content/drive/My Drive/fyp/CIFAR-10.pickle', 'rb') as f:\n","    X_train_cropped_list, y_train_one_hot, X_test_cropped_list, y_test_one_hot, coordinate_list, scale_list = pickle.load(f)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NYkFwl7RbAnt"},"source":["## HiCo Layer 1"]},{"cell_type":"code","metadata":{"id":"mZxSK0dGZsGo","executionInfo":{"status":"ok","timestamp":1620637702998,"user_tz":-480,"elapsed":176873,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["#build ANN model\n","ensemble = []\n","for i in range(NUM_TN[0]):\n","  model = Sequential()\n","  model.add(Dense(64, activation='relu', input_dim=SUB_REGION_SCALE*SUB_REGION_SCALE*3))\n","  model.add(Dense(64, activation='relu'))\n","  model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","  ensemble.append((model, i, coordinate_list[i], scale_list[i]))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"3QwQwq43usDt","executionInfo":{"status":"ok","timestamp":1620637706725,"user_tz":-480,"elapsed":180594,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["for i in range(NUM_TN[0]):\n","  ensemble[i][0].load_weights('/content/drive/My Drive/fyp/CIFAR-10_' + str(i) + '.h5')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"-r3DBZWMb9eX","executionInfo":{"status":"ok","timestamp":1620637706728,"user_tz":-480,"elapsed":180592,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["hico_layers = []\n","hico_layers.append(ensemble)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"IoJcjXQfkaBC","executionInfo":{"status":"ok","timestamp":1620637706728,"user_tz":-480,"elapsed":180587,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["del hico_layers[1:]"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CvSwQtBibHqz"},"source":["## HiCo Layer 2+"]},{"cell_type":"code","metadata":{"id":"MCxjRA6lqoaA","executionInfo":{"status":"ok","timestamp":1620637706729,"user_tz":-480,"elapsed":180583,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Function to get input of layer i-1\n","def get_previous_layer_input(hico_layers, layer, tn, train_image):\n","  input_hr = []\n","  input_ol = []\n","    \n","  if layer == 0:\n","    previous_layer_input = train_image[tn[1]]\n","    return previous_layer_input\n","\n","  elif layer > 0:\n","    for i in range(NUM_CONNECTION[layer]):\n","      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[1].output))\n","      input_hr.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n","      \n","    input_hr = np.array(input_hr)\n","    input_hr = np.concatenate(input_hr, axis=1)\n","\n","    for i in range(NUM_CONNECTION[layer]):\n","      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[2].output))\n","      input_ol.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n","\n","    input_ol = np.array(input_ol)\n","    input_ol = np.sum(input_ol, axis=0)\n","\n","    input = np.concatenate((input_hr, input_ol), axis=1)\n","    \n","    previous_layer_input = input\n","    return previous_layer_input"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZLXI5D6lneY","executionInfo":{"status":"ok","timestamp":1620639277670,"user_tz":-480,"elapsed":1751519,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"b9916126-b87c-4d21-c917-eff677b80e81"},"source":["for i in range(1, NUM_HICO_LAYER):\n","  print('Layer %d' %i)\n","  ensemble = []\n","  X_train_input_list = []\n","  X_test_input_list = []\n","\n","  for j in range(NUM_TN[i]):\n","    # Build model of HiCo layer i\n","    connection = tuple(random.sample(range(len(hico_layers[i-1])), k=NUM_CONNECTION[i]))\n","    model = Sequential()\n","    model.add(Dense(64, activation='relu', input_dim=64*NUM_CONNECTION[i]+NUM_CLASS))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    ensemble.append((model, connection))\n","  hico_layers.append(ensemble)\n","  print('HICO LENGTH')\n","  print(len(hico_layers))\n","\n","  for j in range(NUM_TN[i]):\n","    # Get train hidden representation from HiCo layer i-1\n","    X_train_input_hr = []\n","    X_train_input_ol = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_train_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n","    X_train_input_hr = np.array(X_train_input_hr)\n","    X_train_input_hr = np.concatenate(X_train_input_hr, axis=1)\n","\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n","      X_train_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n","    X_train_input_ol = np.array(X_train_input_ol)\n","    X_train_input_ol = np.sum(X_train_input_ol, axis=0)\n","\n","    X_train_input = np.concatenate((X_train_input_hr, X_train_input_ol), axis=1)\n","    X_train_input_list.append(X_train_input)\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input_hr = []\n","    X_test_input_ol = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input_hr = np.array(X_test_input_hr)\n","    X_test_input_hr = np.concatenate(X_test_input_hr, axis=1)\n","\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n","      X_test_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input_ol = np.array(X_test_input_ol)\n","    X_test_input_ol = np.sum(X_test_input_ol, axis=0)\n","\n","    X_test_input = np.concatenate((X_test_input_hr, X_test_input_ol), axis=1)\n","    X_test_input_list.append(X_test_input)\n","\n","  #train model of HiCo layer i\n","  for j in range(NUM_TN[i]):\n","    print('Model %d' %j)\n","    hico_layers[i][j][0].fit(X_train_input_list[j], y_train_one_hot, validation_data=(X_test_input_list[j], y_test_one_hot), epochs=5, batch_size=128)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Layer 1\n","HICO LENGTH\n","2\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.7303 - accuracy: 0.3793 - val_loss: 1.4632 - val_accuracy: 0.4710\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4390 - accuracy: 0.4866 - val_loss: 1.4454 - val_accuracy: 0.4824\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3936 - accuracy: 0.5029 - val_loss: 1.4277 - val_accuracy: 0.4913\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3804 - accuracy: 0.5071 - val_loss: 1.3988 - val_accuracy: 0.4968\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3557 - accuracy: 0.5152 - val_loss: 1.3955 - val_accuracy: 0.5014\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.7842 - accuracy: 0.3519 - val_loss: 1.5729 - val_accuracy: 0.4394\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5219 - accuracy: 0.4585 - val_loss: 1.5326 - val_accuracy: 0.4518\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4943 - accuracy: 0.4634 - val_loss: 1.5077 - val_accuracy: 0.4621\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4653 - accuracy: 0.4766 - val_loss: 1.4943 - val_accuracy: 0.4703\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4419 - accuracy: 0.4843 - val_loss: 1.4980 - val_accuracy: 0.4652\n","Model 2\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.7114 - accuracy: 0.3815 - val_loss: 1.4755 - val_accuracy: 0.4702\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4325 - accuracy: 0.4854 - val_loss: 1.4404 - val_accuracy: 0.4882\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3899 - accuracy: 0.5044 - val_loss: 1.4100 - val_accuracy: 0.4925\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3713 - accuracy: 0.5121 - val_loss: 1.4030 - val_accuracy: 0.5028\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3462 - accuracy: 0.5205 - val_loss: 1.4017 - val_accuracy: 0.4999\n","Model 3\n","Epoch 1/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.7285 - accuracy: 0.3716 - val_loss: 1.4926 - val_accuracy: 0.4624\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4598 - accuracy: 0.4752 - val_loss: 1.4563 - val_accuracy: 0.4845\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4182 - accuracy: 0.4913 - val_loss: 1.4345 - val_accuracy: 0.4913\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4033 - accuracy: 0.4996 - val_loss: 1.4205 - val_accuracy: 0.4954\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3830 - accuracy: 0.5030 - val_loss: 1.4376 - val_accuracy: 0.4878\n","Model 4\n","Epoch 1/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.7326 - accuracy: 0.3719 - val_loss: 1.5097 - val_accuracy: 0.4597\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4638 - accuracy: 0.4737 - val_loss: 1.4756 - val_accuracy: 0.4709\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4253 - accuracy: 0.4884 - val_loss: 1.4540 - val_accuracy: 0.4785\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4055 - accuracy: 0.4969 - val_loss: 1.4500 - val_accuracy: 0.4795\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3780 - accuracy: 0.5074 - val_loss: 1.4314 - val_accuracy: 0.4853\n","Model 5\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.7604 - accuracy: 0.3712 - val_loss: 1.5197 - val_accuracy: 0.4511\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4848 - accuracy: 0.4685 - val_loss: 1.4775 - val_accuracy: 0.4634\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4543 - accuracy: 0.4763 - val_loss: 1.4712 - val_accuracy: 0.4713\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4063 - accuracy: 0.4964 - val_loss: 1.4573 - val_accuracy: 0.4765\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3999 - accuracy: 0.5005 - val_loss: 1.4492 - val_accuracy: 0.4785\n","Model 6\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.7240 - accuracy: 0.3813 - val_loss: 1.4950 - val_accuracy: 0.4620\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4633 - accuracy: 0.4732 - val_loss: 1.4713 - val_accuracy: 0.4687\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4233 - accuracy: 0.4949 - val_loss: 1.4495 - val_accuracy: 0.4743\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3836 - accuracy: 0.5059 - val_loss: 1.4337 - val_accuracy: 0.4869\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3731 - accuracy: 0.5083 - val_loss: 1.4304 - val_accuracy: 0.4932\n","Model 7\n","Epoch 1/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.7959 - accuracy: 0.3465 - val_loss: 1.5799 - val_accuracy: 0.4384\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5516 - accuracy: 0.4455 - val_loss: 1.5411 - val_accuracy: 0.4556\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5161 - accuracy: 0.4563 - val_loss: 1.5257 - val_accuracy: 0.4578\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4951 - accuracy: 0.4643 - val_loss: 1.5073 - val_accuracy: 0.4667\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4686 - accuracy: 0.4764 - val_loss: 1.5049 - val_accuracy: 0.4641\n","Layer 2\n","HICO LENGTH\n","3\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5149 - accuracy: 0.4627 - val_loss: 1.3825 - val_accuracy: 0.5128\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2873 - accuracy: 0.5441 - val_loss: 1.3471 - val_accuracy: 0.5187\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2646 - accuracy: 0.5525 - val_loss: 1.3489 - val_accuracy: 0.5207\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2586 - accuracy: 0.5526 - val_loss: 1.3349 - val_accuracy: 0.5240\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2458 - accuracy: 0.5607 - val_loss: 1.3472 - val_accuracy: 0.5185\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5310 - accuracy: 0.4521 - val_loss: 1.3582 - val_accuracy: 0.5166\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2909 - accuracy: 0.5418 - val_loss: 1.3535 - val_accuracy: 0.5160\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2788 - accuracy: 0.5463 - val_loss: 1.3635 - val_accuracy: 0.5138\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2666 - accuracy: 0.5495 - val_loss: 1.3495 - val_accuracy: 0.5194\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2447 - accuracy: 0.5571 - val_loss: 1.3420 - val_accuracy: 0.5213\n","Model 2\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5225 - accuracy: 0.4639 - val_loss: 1.3909 - val_accuracy: 0.5036\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3243 - accuracy: 0.5274 - val_loss: 1.3856 - val_accuracy: 0.5067\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3041 - accuracy: 0.5355 - val_loss: 1.3825 - val_accuracy: 0.5071\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2823 - accuracy: 0.5459 - val_loss: 1.3748 - val_accuracy: 0.5075\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2762 - accuracy: 0.5493 - val_loss: 1.3728 - val_accuracy: 0.5143\n","Model 3\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4975 - accuracy: 0.4690 - val_loss: 1.3693 - val_accuracy: 0.5151\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2819 - accuracy: 0.5460 - val_loss: 1.3415 - val_accuracy: 0.5224\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2628 - accuracy: 0.5530 - val_loss: 1.3327 - val_accuracy: 0.5255\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2314 - accuracy: 0.5620 - val_loss: 1.3248 - val_accuracy: 0.5251\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2279 - accuracy: 0.5622 - val_loss: 1.3431 - val_accuracy: 0.5237\n","Model 4\n","Epoch 1/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.5244 - accuracy: 0.4629 - val_loss: 1.3659 - val_accuracy: 0.5165\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2864 - accuracy: 0.5414 - val_loss: 1.3542 - val_accuracy: 0.5182\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2672 - accuracy: 0.5521 - val_loss: 1.3464 - val_accuracy: 0.5228\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2435 - accuracy: 0.5609 - val_loss: 1.3314 - val_accuracy: 0.5226\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2378 - accuracy: 0.5614 - val_loss: 1.3418 - val_accuracy: 0.5248\n","Model 5\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5544 - accuracy: 0.4470 - val_loss: 1.4065 - val_accuracy: 0.5034\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3252 - accuracy: 0.5278 - val_loss: 1.3953 - val_accuracy: 0.5036\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3049 - accuracy: 0.5347 - val_loss: 1.3813 - val_accuracy: 0.5096\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2923 - accuracy: 0.5385 - val_loss: 1.3756 - val_accuracy: 0.5115\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2795 - accuracy: 0.5444 - val_loss: 1.3811 - val_accuracy: 0.5071\n","Layer 3\n","HICO LENGTH\n","4\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4421 - accuracy: 0.5005 - val_loss: 1.3370 - val_accuracy: 0.5241\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2177 - accuracy: 0.5687 - val_loss: 1.3219 - val_accuracy: 0.5303\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2136 - accuracy: 0.5712 - val_loss: 1.3253 - val_accuracy: 0.5304\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2132 - accuracy: 0.5682 - val_loss: 1.3278 - val_accuracy: 0.5311\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2001 - accuracy: 0.5753 - val_loss: 1.3244 - val_accuracy: 0.5309\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 2s 2ms/step - loss: 1.5263 - accuracy: 0.4625 - val_loss: 1.3390 - val_accuracy: 0.5215\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2320 - accuracy: 0.5653 - val_loss: 1.3332 - val_accuracy: 0.5259\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2209 - accuracy: 0.5665 - val_loss: 1.3202 - val_accuracy: 0.5315\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2061 - accuracy: 0.5730 - val_loss: 1.3325 - val_accuracy: 0.5271\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2030 - accuracy: 0.5728 - val_loss: 1.3136 - val_accuracy: 0.5335\n","Model 2\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4397 - accuracy: 0.4996 - val_loss: 1.3298 - val_accuracy: 0.5259\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2177 - accuracy: 0.5697 - val_loss: 1.3235 - val_accuracy: 0.5328\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2134 - accuracy: 0.5732 - val_loss: 1.3166 - val_accuracy: 0.5340\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2085 - accuracy: 0.5701 - val_loss: 1.3169 - val_accuracy: 0.5344\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1986 - accuracy: 0.5729 - val_loss: 1.3238 - val_accuracy: 0.5338\n","Model 3\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4185 - accuracy: 0.5101 - val_loss: 1.3255 - val_accuracy: 0.5276\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2198 - accuracy: 0.5720 - val_loss: 1.3453 - val_accuracy: 0.5234\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2098 - accuracy: 0.5731 - val_loss: 1.3127 - val_accuracy: 0.5313\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2067 - accuracy: 0.5722 - val_loss: 1.3426 - val_accuracy: 0.5244\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1990 - accuracy: 0.5751 - val_loss: 1.3141 - val_accuracy: 0.5341\n","Layer 4\n","HICO LENGTH\n","5\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3852 - accuracy: 0.5189 - val_loss: 1.3173 - val_accuracy: 0.5347\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2076 - accuracy: 0.5715 - val_loss: 1.3164 - val_accuracy: 0.5335\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1924 - accuracy: 0.5767 - val_loss: 1.3286 - val_accuracy: 0.5310\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1955 - accuracy: 0.5746 - val_loss: 1.3095 - val_accuracy: 0.5345\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1880 - accuracy: 0.5785 - val_loss: 1.3225 - val_accuracy: 0.5347\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5161 - accuracy: 0.4819 - val_loss: 1.3292 - val_accuracy: 0.5335\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.2063 - accuracy: 0.5765 - val_loss: 1.3159 - val_accuracy: 0.5346\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1914 - accuracy: 0.5797 - val_loss: 1.3211 - val_accuracy: 0.5287\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1919 - accuracy: 0.5813 - val_loss: 1.3133 - val_accuracy: 0.5354\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.1916 - accuracy: 0.5763 - val_loss: 1.3242 - val_accuracy: 0.5319\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4ZCjVj0ioNb6"},"source":["## Model Evaluation"]},{"cell_type":"code","metadata":{"id":"-wsBlIBONSIN","executionInfo":{"status":"ok","timestamp":1620639551238,"user_tz":-480,"elapsed":2025081,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = np.argmax(hico_layers[0][j][0].predict(X_test_cropped_list[j]), axis=1)\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input_hr = []\n","    X_test_input_ol = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input_hr = np.array(X_test_input_hr)\n","    X_test_input_hr = np.concatenate(X_test_input_hr, axis=1)\n","\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n","      X_test_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input_ol = np.array(X_test_input_ol)\n","    X_test_input_ol = np.sum(X_test_input_ol, axis=0)\n","\n","    X_test_input = np.concatenate((X_test_input_hr, X_test_input_ol), axis=1)\n","\n","    y_pred = np.argmax(hico_layers[i][j][0].predict(X_test_input), axis=1)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting (mode)\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0))\n","y_pred_list = stats.mode(y_pred_list, axis=1)[0]\n","y_pred_list = np.squeeze(y_pred_list)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"3su8cG_cuwDI","executionInfo":{"status":"ok","timestamp":1620639551239,"user_tz":-480,"elapsed":2025076,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["y_test = np.argmax(y_test_one_hot, axis=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZ6nor6wRK_k","executionInfo":{"status":"ok","timestamp":1620639551240,"user_tz":-480,"elapsed":2025069,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"fe2959fc-a8c1-4068-909c-c919126070c4"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5311"]},"metadata":{"tags":[]},"execution_count":12}]}]}