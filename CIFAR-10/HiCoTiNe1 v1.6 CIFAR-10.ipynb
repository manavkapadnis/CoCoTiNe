{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HiCoTiNe1 v1.6 CIFAR-10.ipynb","provenance":[{"file_id":"19guF-U3KgRWG2yOuNYWGUTWs2FP2582B","timestamp":1615843192315}],"collapsed_sections":[],"authorship_tag":"ABX9TyPQpH7wfFx5/aM4GZSO5tTj"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OVQ7Bo8hJIUb"},"source":["# Variants-Experiment 1.6\n","\n","## Summed hidden representations and concatenated output logits.\n","## Mode. Compute classifications of all tiny networks, in all HiCo layers, and take the mode as the final classification.\n"]},{"cell_type":"code","metadata":{"id":"AW5zp22ze_5Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620631277486,"user_tz":-480,"elapsed":18779,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"cf83fe61-3723-4a0d-f22a-8b448d033b5a"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten\n","from keras.datasets import mnist\n","from keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import random\n","from scipy import stats\n","from sklearn.metrics import accuracy_score\n","from keras import backend as K\n","\n","import os\n","import pickle\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pL2zNY1Pqo43","executionInfo":{"status":"ok","timestamp":1620631277486,"user_tz":-480,"elapsed":18773,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["SUB_REGION_SCALE = 14\n","NUM_HICO_LAYER = 5\n","NUM_TN = [10, 8, 6, 4, 2]\n","NUM_CONNECTION = [0, 5, 4, 3, 2]\n","\n","#dataset specific parameters\n","NUM_CLASS = 10"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sV1QzfMXoD_c"},"source":["## Data Pre-Processing"]},{"cell_type":"code","metadata":{"id":"p11MMf7IzjJm","executionInfo":{"status":"ok","timestamp":1620631307609,"user_tz":-480,"elapsed":48891,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["with open('/content/drive/My Drive/fyp/CIFAR-10.pickle', 'rb') as f:\n","    X_train_cropped_list, y_train_one_hot, X_test_cropped_list, y_test_one_hot, coordinate_list, scale_list = pickle.load(f)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NYkFwl7RbAnt"},"source":["## HiCo Layer 1"]},{"cell_type":"code","metadata":{"id":"mZxSK0dGZsGo","executionInfo":{"status":"ok","timestamp":1620631309122,"user_tz":-480,"elapsed":50400,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["#build ANN model\n","ensemble = []\n","for i in range(NUM_TN[0]):\n","  model = Sequential()\n","  model.add(Dense(64, activation='relu', input_dim=SUB_REGION_SCALE*SUB_REGION_SCALE*3))\n","  model.add(Dense(64, activation='relu'))\n","  model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","  ensemble.append((model, i, coordinate_list[i], scale_list[i]))"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"t2Efu9OmzlaZ","executionInfo":{"status":"ok","timestamp":1620631310935,"user_tz":-480,"elapsed":52211,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["for i in range(NUM_TN[0]):\n","  ensemble[i][0].load_weights('/content/drive/My Drive/fyp/CIFAR-10_' + str(i) + '.h5')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"-r3DBZWMb9eX","executionInfo":{"status":"ok","timestamp":1620631310942,"user_tz":-480,"elapsed":52215,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["hico_layers = []\n","hico_layers.append(ensemble)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"IoJcjXQfkaBC","executionInfo":{"status":"ok","timestamp":1620631310944,"user_tz":-480,"elapsed":52215,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["del hico_layers[1:]"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CvSwQtBibHqz"},"source":["## HiCo Layer 2+"]},{"cell_type":"code","metadata":{"id":"MCxjRA6lqoaA","executionInfo":{"status":"ok","timestamp":1620631310945,"user_tz":-480,"elapsed":52214,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Function to get input of layer i-1\n","def get_previous_layer_input(hico_layers, layer, tn, train_image):\n","  input_hr = []\n","  input_ol = []\n","    \n","  if layer == 0:\n","    previous_layer_input = train_image[tn[1]]\n","    return previous_layer_input\n","\n","  elif layer > 0:\n","    for i in range(NUM_CONNECTION[layer]):\n","      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[1].output))\n","      input_hr.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n","      \n","    input_hr = np.array(input_hr)\n","    input_hr = np.sum(input_hr, axis=0)\n","\n","    for i in range(NUM_CONNECTION[layer]):\n","      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[2].output))\n","      input_ol.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n","\n","    input_ol = np.array(input_ol)\n","    input_ol = np.concatenate(input_ol, axis=1)\n","\n","    input = np.concatenate((input_hr, input_ol), axis=1)\n","    \n","    previous_layer_input = input\n","    return previous_layer_input"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZLXI5D6lneY","executionInfo":{"status":"ok","timestamp":1620633056043,"user_tz":-480,"elapsed":1797304,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"6f1e34ab-6f3a-420f-9155-040fb7e15095"},"source":["for i in range(1, NUM_HICO_LAYER):\n","  print('Layer %d' %i)\n","  ensemble = []\n","  X_train_input_list = []\n","  X_test_input_list = []\n","\n","  for j in range(NUM_TN[i]):\n","    # Build model of HiCo layer i\n","    connection = tuple(random.sample(range(len(hico_layers[i-1])), k=NUM_CONNECTION[i]))\n","    model = Sequential()\n","    model.add(Dense(64, activation='relu', input_dim=64+NUM_CLASS*NUM_CONNECTION[i]))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    ensemble.append((model, connection))\n","  hico_layers.append(ensemble)\n","  print('HICO LENGTH')\n","  print(len(hico_layers))\n","\n","  for j in range(NUM_TN[i]):\n","    # Get train hidden representation from HiCo layer i-1\n","    X_train_input_hr = []\n","    X_train_input_ol = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_train_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n","    X_train_input_hr = np.array(X_train_input_hr)\n","    X_train_input_hr = np.sum(X_train_input_hr, axis=0)\n","\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n","      X_train_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n","    X_train_input_ol = np.array(X_train_input_ol)\n","    X_train_input_ol = np.concatenate(X_train_input_ol, axis=1)\n","\n","    X_train_input = np.concatenate((X_train_input_hr, X_train_input_ol), axis=1)\n","    X_train_input_list.append(X_train_input)\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input_hr = []\n","    X_test_input_ol = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input_hr = np.array(X_test_input_hr)\n","    X_test_input_hr = np.sum(X_test_input_hr, axis=0)\n","\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n","      X_test_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input_ol = np.array(X_test_input_ol)\n","    X_test_input_ol = np.concatenate(X_test_input_ol, axis=1)\n","\n","    X_test_input = np.concatenate((X_test_input_hr, X_test_input_ol), axis=1)\n","    X_test_input_list.append(X_test_input)\n","\n","  #train model of HiCo layer i\n","  for j in range(NUM_TN[i]):\n","    print('Model %d' %j)\n","    hico_layers[i][j][0].fit(X_train_input_list[j], y_train_one_hot, validation_data=(X_test_input_list[j], y_test_one_hot), epochs=5, batch_size=128)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Layer 1\n","HICO LENGTH\n","2\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.9133 - accuracy: 0.3060 - val_loss: 1.5927 - val_accuracy: 0.4337\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5589 - accuracy: 0.4435 - val_loss: 1.5698 - val_accuracy: 0.4415\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5235 - accuracy: 0.4567 - val_loss: 1.5339 - val_accuracy: 0.4599\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5070 - accuracy: 0.4607 - val_loss: 1.5274 - val_accuracy: 0.4630\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4886 - accuracy: 0.4671 - val_loss: 1.4997 - val_accuracy: 0.4681\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.8963 - accuracy: 0.3091 - val_loss: 1.6168 - val_accuracy: 0.4154\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5946 - accuracy: 0.4270 - val_loss: 1.5752 - val_accuracy: 0.4323\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5480 - accuracy: 0.4448 - val_loss: 1.5724 - val_accuracy: 0.4362\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5344 - accuracy: 0.4508 - val_loss: 1.5478 - val_accuracy: 0.4426\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5188 - accuracy: 0.4550 - val_loss: 1.5616 - val_accuracy: 0.4417\n","Model 2\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.9571 - accuracy: 0.3027 - val_loss: 1.6064 - val_accuracy: 0.4238\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5704 - accuracy: 0.4374 - val_loss: 1.5654 - val_accuracy: 0.4445\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5255 - accuracy: 0.4535 - val_loss: 1.5585 - val_accuracy: 0.4428\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5098 - accuracy: 0.4620 - val_loss: 1.5465 - val_accuracy: 0.4518\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5006 - accuracy: 0.4622 - val_loss: 1.5324 - val_accuracy: 0.4528\n","Model 3\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.8461 - accuracy: 0.3324 - val_loss: 1.5793 - val_accuracy: 0.4352\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5502 - accuracy: 0.4456 - val_loss: 1.5578 - val_accuracy: 0.4460\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5236 - accuracy: 0.4531 - val_loss: 1.5179 - val_accuracy: 0.4570\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4863 - accuracy: 0.4679 - val_loss: 1.5114 - val_accuracy: 0.4600\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4728 - accuracy: 0.4735 - val_loss: 1.5059 - val_accuracy: 0.4651\n","Model 4\n","Epoch 1/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.8762 - accuracy: 0.3245 - val_loss: 1.5966 - val_accuracy: 0.4226\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5564 - accuracy: 0.4418 - val_loss: 1.5562 - val_accuracy: 0.4430\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5232 - accuracy: 0.4497 - val_loss: 1.5591 - val_accuracy: 0.4435\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5044 - accuracy: 0.4621 - val_loss: 1.5267 - val_accuracy: 0.4544\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4874 - accuracy: 0.4659 - val_loss: 1.4963 - val_accuracy: 0.4681\n","Model 5\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.9075 - accuracy: 0.3176 - val_loss: 1.5498 - val_accuracy: 0.4428\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5201 - accuracy: 0.4534 - val_loss: 1.5098 - val_accuracy: 0.4572\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4848 - accuracy: 0.4680 - val_loss: 1.5066 - val_accuracy: 0.4590\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4670 - accuracy: 0.4777 - val_loss: 1.4859 - val_accuracy: 0.4706\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4455 - accuracy: 0.4837 - val_loss: 1.4781 - val_accuracy: 0.4721\n","Model 6\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.9006 - accuracy: 0.3167 - val_loss: 1.5808 - val_accuracy: 0.4269\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5320 - accuracy: 0.4480 - val_loss: 1.5202 - val_accuracy: 0.4528\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4858 - accuracy: 0.4668 - val_loss: 1.5013 - val_accuracy: 0.4571\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4768 - accuracy: 0.4694 - val_loss: 1.4908 - val_accuracy: 0.4581\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4492 - accuracy: 0.4807 - val_loss: 1.4654 - val_accuracy: 0.4728\n","Model 7\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.8585 - accuracy: 0.3230 - val_loss: 1.5921 - val_accuracy: 0.4221\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5745 - accuracy: 0.4307 - val_loss: 1.5559 - val_accuracy: 0.4453\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5238 - accuracy: 0.4497 - val_loss: 1.5409 - val_accuracy: 0.4454\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.5067 - accuracy: 0.4577 - val_loss: 1.5530 - val_accuracy: 0.4425\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4963 - accuracy: 0.4605 - val_loss: 1.5169 - val_accuracy: 0.4545\n","Layer 2\n","HICO LENGTH\n","3\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.7425 - accuracy: 0.3918 - val_loss: 1.4792 - val_accuracy: 0.4668\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4317 - accuracy: 0.4851 - val_loss: 1.4589 - val_accuracy: 0.4812\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4111 - accuracy: 0.4982 - val_loss: 1.4434 - val_accuracy: 0.4831\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4101 - accuracy: 0.4987 - val_loss: 1.4323 - val_accuracy: 0.4893\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3951 - accuracy: 0.5026 - val_loss: 1.4554 - val_accuracy: 0.4829\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.8398 - accuracy: 0.3841 - val_loss: 1.5025 - val_accuracy: 0.4668\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4390 - accuracy: 0.4873 - val_loss: 1.4631 - val_accuracy: 0.4773\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4135 - accuracy: 0.4968 - val_loss: 1.4377 - val_accuracy: 0.4898\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3939 - accuracy: 0.5030 - val_loss: 1.4458 - val_accuracy: 0.4894\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3955 - accuracy: 0.5042 - val_loss: 1.4380 - val_accuracy: 0.4863\n","Model 2\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.8223 - accuracy: 0.3727 - val_loss: 1.4824 - val_accuracy: 0.4732\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4250 - accuracy: 0.4957 - val_loss: 1.4785 - val_accuracy: 0.4760\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4111 - accuracy: 0.4978 - val_loss: 1.4641 - val_accuracy: 0.4801\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4006 - accuracy: 0.4993 - val_loss: 1.4385 - val_accuracy: 0.4836\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3829 - accuracy: 0.5060 - val_loss: 1.4354 - val_accuracy: 0.4831\n","Model 3\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.7173 - accuracy: 0.3910 - val_loss: 1.4774 - val_accuracy: 0.4739\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4402 - accuracy: 0.4875 - val_loss: 1.4517 - val_accuracy: 0.4838\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4128 - accuracy: 0.4965 - val_loss: 1.4443 - val_accuracy: 0.4883\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3976 - accuracy: 0.5011 - val_loss: 1.4459 - val_accuracy: 0.4901\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3921 - accuracy: 0.5012 - val_loss: 1.4393 - val_accuracy: 0.4832\n","Model 4\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.7911 - accuracy: 0.3705 - val_loss: 1.4828 - val_accuracy: 0.4722\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4366 - accuracy: 0.4881 - val_loss: 1.4665 - val_accuracy: 0.4755\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4257 - accuracy: 0.4910 - val_loss: 1.4503 - val_accuracy: 0.4831\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4037 - accuracy: 0.5013 - val_loss: 1.4459 - val_accuracy: 0.4830\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3893 - accuracy: 0.5045 - val_loss: 1.4374 - val_accuracy: 0.4863\n","Model 5\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.8066 - accuracy: 0.3982 - val_loss: 1.4759 - val_accuracy: 0.4757\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4286 - accuracy: 0.4902 - val_loss: 1.4492 - val_accuracy: 0.4846\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4129 - accuracy: 0.4971 - val_loss: 1.4460 - val_accuracy: 0.4862\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3933 - accuracy: 0.5054 - val_loss: 1.4537 - val_accuracy: 0.4810\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3861 - accuracy: 0.5070 - val_loss: 1.4396 - val_accuracy: 0.4841\n","Layer 3\n","HICO LENGTH\n","4\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.6872 - accuracy: 0.4148 - val_loss: 1.4570 - val_accuracy: 0.4834\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3952 - accuracy: 0.5058 - val_loss: 1.4387 - val_accuracy: 0.4912\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3867 - accuracy: 0.5064 - val_loss: 1.4335 - val_accuracy: 0.4877\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3736 - accuracy: 0.5104 - val_loss: 1.4242 - val_accuracy: 0.4947\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3643 - accuracy: 0.5137 - val_loss: 1.4183 - val_accuracy: 0.4922\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 2s 3ms/step - loss: 1.6659 - accuracy: 0.4119 - val_loss: 1.4622 - val_accuracy: 0.4772\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3907 - accuracy: 0.5057 - val_loss: 1.4268 - val_accuracy: 0.4902\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3837 - accuracy: 0.5078 - val_loss: 1.4303 - val_accuracy: 0.4900\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3779 - accuracy: 0.5105 - val_loss: 1.4294 - val_accuracy: 0.4913\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3635 - accuracy: 0.5152 - val_loss: 1.4148 - val_accuracy: 0.4935\n","Model 2\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.6877 - accuracy: 0.4194 - val_loss: 1.4476 - val_accuracy: 0.4871\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3916 - accuracy: 0.5031 - val_loss: 1.4263 - val_accuracy: 0.4948\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3821 - accuracy: 0.5091 - val_loss: 1.4214 - val_accuracy: 0.4919\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3695 - accuracy: 0.5120 - val_loss: 1.4168 - val_accuracy: 0.4964\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3756 - accuracy: 0.5098 - val_loss: 1.4098 - val_accuracy: 0.4958\n","Model 3\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.7454 - accuracy: 0.3999 - val_loss: 1.4437 - val_accuracy: 0.4856\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.4066 - accuracy: 0.4987 - val_loss: 1.4398 - val_accuracy: 0.4851\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3848 - accuracy: 0.5077 - val_loss: 1.4255 - val_accuracy: 0.4902\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3678 - accuracy: 0.5105 - val_loss: 1.4236 - val_accuracy: 0.4925\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3655 - accuracy: 0.5148 - val_loss: 1.4201 - val_accuracy: 0.4908\n","Layer 4\n","HICO LENGTH\n","5\n","Model 0\n","Epoch 1/5\n","391/391 [==============================] - 1s 3ms/step - loss: 1.5805 - accuracy: 0.4386 - val_loss: 1.4332 - val_accuracy: 0.4865\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3726 - accuracy: 0.5094 - val_loss: 1.4158 - val_accuracy: 0.4977\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3618 - accuracy: 0.5151 - val_loss: 1.4202 - val_accuracy: 0.4961\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3621 - accuracy: 0.5145 - val_loss: 1.4234 - val_accuracy: 0.4973\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3545 - accuracy: 0.5187 - val_loss: 1.4169 - val_accuracy: 0.4965\n","Model 1\n","Epoch 1/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.6001 - accuracy: 0.4393 - val_loss: 1.4429 - val_accuracy: 0.4888\n","Epoch 2/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3760 - accuracy: 0.5138 - val_loss: 1.4169 - val_accuracy: 0.4937\n","Epoch 3/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3590 - accuracy: 0.5177 - val_loss: 1.4176 - val_accuracy: 0.4944\n","Epoch 4/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3683 - accuracy: 0.5124 - val_loss: 1.4130 - val_accuracy: 0.4980\n","Epoch 5/5\n","391/391 [==============================] - 1s 2ms/step - loss: 1.3435 - accuracy: 0.5247 - val_loss: 1.4149 - val_accuracy: 0.4973\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4ZCjVj0ioNb6"},"source":["## Model Evaluation"]},{"cell_type":"code","metadata":{"id":"-wsBlIBONSIN","executionInfo":{"status":"ok","timestamp":1620633362548,"user_tz":-480,"elapsed":2103806,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = np.argmax(hico_layers[0][j][0].predict(X_test_cropped_list[j]), axis=1)\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input_hr = []\n","    X_test_input_ol = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input_hr.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input_hr = np.array(X_test_input_hr)\n","    X_test_input_hr = np.sum(X_test_input_hr, axis=0)\n","\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[2].output))\n","      X_test_input_ol.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input_ol = np.array(X_test_input_ol)\n","    X_test_input_ol = np.concatenate(X_test_input_ol, axis=1)\n","\n","    X_test_input = np.concatenate((X_test_input_hr, X_test_input_ol), axis=1)\n","\n","    y_pred = np.argmax(hico_layers[i][j][0].predict(X_test_input), axis=1)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting (mode)\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0))\n","y_pred_list = stats.mode(y_pred_list, axis=1)[0]\n","y_pred_list = np.squeeze(y_pred_list)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"T-Qjw55gzo6O","executionInfo":{"status":"ok","timestamp":1620633362549,"user_tz":-480,"elapsed":2103805,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["y_test = np.argmax(y_test_one_hot, axis=1)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZ6nor6wRK_k","executionInfo":{"status":"ok","timestamp":1620633362549,"user_tz":-480,"elapsed":2103797,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"774b1632-5052-4234-be94-898a4cbb8f7a"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.4965"]},"metadata":{"tags":[]},"execution_count":12}]}]}