{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HiCoTiNe1 v1.1 Fashion MNIST.ipynb","provenance":[{"file_id":"19guF-U3KgRWG2yOuNYWGUTWs2FP2582B","timestamp":1615843192315}],"collapsed_sections":[],"authorship_tag":"ABX9TyPjz3Edt76Hf4FxLZyl2+DK"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OVQ7Bo8hJIUb"},"source":["# Variants-Experiment 1.1\n","\n","## Concatenated hidden representations.\n","## Mode. Compute classifications of all tiny networks, in all HiCo layers, and take the mode as the final classification.\n"]},{"cell_type":"code","metadata":{"id":"AW5zp22ze_5Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620610831030,"user_tz":-480,"elapsed":15417,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"f46e637c-ede1-4869-aa71-c73638fd2585"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten\n","from keras.datasets import mnist\n","from keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import random\n","from scipy import stats\n","from sklearn.metrics import accuracy_score\n","from keras import backend as K\n","\n","import os\n","import pickle\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pL2zNY1Pqo43","executionInfo":{"status":"ok","timestamp":1620610831031,"user_tz":-480,"elapsed":15403,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["SUB_REGION_SCALE = 14\n","NUM_HICO_LAYER = 5\n","NUM_TN = [10, 8, 6, 4, 2]\n","NUM_CONNECTION = [0, 5, 4, 3, 2]\n","\n","#dataset specific parameters\n","NUM_CLASS = 10"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sV1QzfMXoD_c"},"source":["## Data Pre-Processing"]},{"cell_type":"code","metadata":{"id":"CK8Jo8eFjW0R","executionInfo":{"status":"ok","timestamp":1620610839533,"user_tz":-480,"elapsed":23900,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["with open('/content/drive/My Drive/fyp/Fashion MNIST.pickle', 'rb') as f:\n","    X_train_cropped_list, y_train_one_hot, X_test_cropped_list, y_test_one_hot, coordinate_list, scale_list = pickle.load(f)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NYkFwl7RbAnt"},"source":["## HiCo Layer 1"]},{"cell_type":"code","metadata":{"id":"mZxSK0dGZsGo","executionInfo":{"status":"ok","timestamp":1620610840034,"user_tz":-480,"elapsed":24396,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["#build ANN model\n","ensemble = []\n","for i in range(NUM_TN[0]):\n","  model = Sequential()\n","  model.add(Dense(64, activation='relu', input_dim=SUB_REGION_SCALE*SUB_REGION_SCALE))\n","  model.add(Dense(64, activation='relu'))\n","  model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","  ensemble.append((model, i, coordinate_list[i], scale_list[i]))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2K4jfWOkcSz","executionInfo":{"status":"ok","timestamp":1620610842394,"user_tz":-480,"elapsed":26752,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["for i in range(NUM_TN[0]):\n","  ensemble[i][0].load_weights('/content/drive/My Drive/fyp/Fashion MNIST_' + str(i) + '.h5')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"-r3DBZWMb9eX","executionInfo":{"status":"ok","timestamp":1620610842395,"user_tz":-480,"elapsed":26748,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["hico_layers = []\n","hico_layers.append(ensemble)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AKc-KKMj278","executionInfo":{"status":"ok","timestamp":1620610842395,"user_tz":-480,"elapsed":26743,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["del hico_layers[1:]"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CvSwQtBibHqz"},"source":["## HiCo Layer 2+"]},{"cell_type":"code","metadata":{"id":"MCxjRA6lqoaA","executionInfo":{"status":"ok","timestamp":1620610842396,"user_tz":-480,"elapsed":26738,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Function to get input of layer i-1\n","def get_previous_layer_input(hico_layers, layer, tn, train_image):\n","  input = []\n","    \n","  if layer == 0:\n","    previous_layer_input = train_image[tn[1]]\n","    return previous_layer_input\n","\n","  elif layer > 0:\n","    for i in range(NUM_CONNECTION[layer]):\n","      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[1].output))\n","      input.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n","      \n","    input = np.array(input)\n","    input = np.concatenate(input, axis=1)\n","    previous_layer_input = input\n","    return previous_layer_input"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZLXI5D6lneY","executionInfo":{"status":"ok","timestamp":1620611057080,"user_tz":-480,"elapsed":241416,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"cbd04c4b-5fef-4232-dc59-429b31ca0da9"},"source":["for i in range(1, NUM_HICO_LAYER):\n","  print('Layer %d' %i)\n","  ensemble = []\n","  X_train_input_list = []\n","  X_test_input_list = []\n","\n","  for j in range(NUM_TN[i]):\n","    # Build model of HiCo layer i\n","    connection = tuple(random.sample(range(len(hico_layers[i-1])), k=NUM_CONNECTION[i]))\n","    model = Sequential()\n","    model.add(Dense(64, activation='relu', input_dim=64*NUM_CONNECTION[i]))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    ensemble.append((model, connection))\n","  hico_layers.append(ensemble)\n","  print('HICO LENGTH')\n","  print(len(hico_layers))\n","\n","  for j in range(NUM_TN[i]):\n","    # Get train hidden representation from HiCo layer i-1\n","    X_train_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_train_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n","    X_train_input = np.array(X_train_input)\n","    X_train_input = np.concatenate(X_train_input, axis=1)\n","    X_train_input_list.append(X_train_input)\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    X_test_input_list.append(X_test_input)\n","\n","  #train model of HiCo layer i\n","  for j in range(NUM_TN[i]):\n","    print('Model %d' %j)\n","    hico_layers[i][j][0].fit(X_train_input_list[j], y_train_one_hot, validation_data=(X_test_input_list[j], y_test_one_hot), epochs=5, batch_size=128)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Layer 1\n","HICO LENGTH\n","2\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.7255 - accuracy: 0.7481 - val_loss: 0.4631 - val_accuracy: 0.8295\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4262 - accuracy: 0.8417 - val_loss: 0.4317 - val_accuracy: 0.8403\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3955 - accuracy: 0.8526 - val_loss: 0.4284 - val_accuracy: 0.8412\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3858 - accuracy: 0.8594 - val_loss: 0.4277 - val_accuracy: 0.8408\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3773 - accuracy: 0.8599 - val_loss: 0.4157 - val_accuracy: 0.8464\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.6708 - accuracy: 0.7601 - val_loss: 0.4526 - val_accuracy: 0.8343\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4117 - accuracy: 0.8437 - val_loss: 0.4506 - val_accuracy: 0.8315\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3877 - accuracy: 0.8535 - val_loss: 0.4371 - val_accuracy: 0.8374\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3865 - accuracy: 0.8526 - val_loss: 0.4374 - val_accuracy: 0.8370\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3796 - accuracy: 0.8555 - val_loss: 0.4219 - val_accuracy: 0.8428\n","Model 2\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.7031 - accuracy: 0.7482 - val_loss: 0.4874 - val_accuracy: 0.8185\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4478 - accuracy: 0.8333 - val_loss: 0.4657 - val_accuracy: 0.8306\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4195 - accuracy: 0.8429 - val_loss: 0.4495 - val_accuracy: 0.8331\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4166 - accuracy: 0.8452 - val_loss: 0.4448 - val_accuracy: 0.8357\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4029 - accuracy: 0.8482 - val_loss: 0.4655 - val_accuracy: 0.8234\n","Model 3\n","Epoch 1/5\n","469/469 [==============================] - 2s 2ms/step - loss: 0.7414 - accuracy: 0.7412 - val_loss: 0.4829 - val_accuracy: 0.8191\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4600 - accuracy: 0.8255 - val_loss: 0.4633 - val_accuracy: 0.8261\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4349 - accuracy: 0.8363 - val_loss: 0.4672 - val_accuracy: 0.8245\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4197 - accuracy: 0.8398 - val_loss: 0.4760 - val_accuracy: 0.8182\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4142 - accuracy: 0.8421 - val_loss: 0.4534 - val_accuracy: 0.8333\n","Model 4\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.6930 - accuracy: 0.7576 - val_loss: 0.4536 - val_accuracy: 0.8327\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4185 - accuracy: 0.8462 - val_loss: 0.4367 - val_accuracy: 0.8397\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3986 - accuracy: 0.8523 - val_loss: 0.4506 - val_accuracy: 0.8320\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3759 - accuracy: 0.8593 - val_loss: 0.4185 - val_accuracy: 0.8434\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3697 - accuracy: 0.8617 - val_loss: 0.4253 - val_accuracy: 0.8429\n","Model 5\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.7549 - accuracy: 0.7314 - val_loss: 0.4776 - val_accuracy: 0.8209\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4399 - accuracy: 0.8351 - val_loss: 0.4585 - val_accuracy: 0.8331\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4206 - accuracy: 0.8422 - val_loss: 0.4384 - val_accuracy: 0.8362\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4005 - accuracy: 0.8490 - val_loss: 0.4368 - val_accuracy: 0.8375\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3921 - accuracy: 0.8502 - val_loss: 0.4278 - val_accuracy: 0.8408\n","Model 6\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.6959 - accuracy: 0.7494 - val_loss: 0.4603 - val_accuracy: 0.8293\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4164 - accuracy: 0.8443 - val_loss: 0.4332 - val_accuracy: 0.8371\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3956 - accuracy: 0.8520 - val_loss: 0.4164 - val_accuracy: 0.8453\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3744 - accuracy: 0.8618 - val_loss: 0.4155 - val_accuracy: 0.8447\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8644 - val_loss: 0.4167 - val_accuracy: 0.8467\n","Model 7\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.7238 - accuracy: 0.7459 - val_loss: 0.4666 - val_accuracy: 0.8265\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4400 - accuracy: 0.8378 - val_loss: 0.4469 - val_accuracy: 0.8322\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4111 - accuracy: 0.8481 - val_loss: 0.4292 - val_accuracy: 0.8422\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8523 - val_loss: 0.4256 - val_accuracy: 0.8455\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3863 - accuracy: 0.8562 - val_loss: 0.4230 - val_accuracy: 0.8430\n","Layer 2\n","HICO LENGTH\n","3\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5826 - accuracy: 0.8045 - val_loss: 0.4158 - val_accuracy: 0.8503\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3604 - accuracy: 0.8646 - val_loss: 0.4077 - val_accuracy: 0.8544\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3442 - accuracy: 0.8716 - val_loss: 0.4033 - val_accuracy: 0.8529\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8697 - val_loss: 0.3916 - val_accuracy: 0.8548\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3362 - accuracy: 0.8749 - val_loss: 0.3879 - val_accuracy: 0.8556\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.8084 - val_loss: 0.3980 - val_accuracy: 0.8525\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8665 - val_loss: 0.3911 - val_accuracy: 0.8554\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8734 - val_loss: 0.3889 - val_accuracy: 0.8529\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8738 - val_loss: 0.3853 - val_accuracy: 0.8553\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3287 - accuracy: 0.8756 - val_loss: 0.3767 - val_accuracy: 0.8589\n","Model 2\n","Epoch 1/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5743 - accuracy: 0.8057 - val_loss: 0.4039 - val_accuracy: 0.8525\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3484 - accuracy: 0.8684 - val_loss: 0.4094 - val_accuracy: 0.8522\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8743 - val_loss: 0.3873 - val_accuracy: 0.8571\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3270 - accuracy: 0.8777 - val_loss: 0.3873 - val_accuracy: 0.8574\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8788 - val_loss: 0.3792 - val_accuracy: 0.8616\n","Model 3\n","Epoch 1/5\n","469/469 [==============================] - 2s 2ms/step - loss: 0.5394 - accuracy: 0.8197 - val_loss: 0.4083 - val_accuracy: 0.8483\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8681 - val_loss: 0.3898 - val_accuracy: 0.8555\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8761 - val_loss: 0.3902 - val_accuracy: 0.8559\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3321 - accuracy: 0.8753 - val_loss: 0.3778 - val_accuracy: 0.8603\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8797 - val_loss: 0.3753 - val_accuracy: 0.8587\n","Model 4\n","Epoch 1/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5843 - accuracy: 0.8062 - val_loss: 0.3946 - val_accuracy: 0.8525\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8712 - val_loss: 0.3911 - val_accuracy: 0.8523\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.8723 - val_loss: 0.3854 - val_accuracy: 0.8589\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8764 - val_loss: 0.3872 - val_accuracy: 0.8554\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3218 - accuracy: 0.8796 - val_loss: 0.3851 - val_accuracy: 0.8571\n","Model 5\n","Epoch 1/5\n","469/469 [==============================] - 2s 2ms/step - loss: 0.5869 - accuracy: 0.8054 - val_loss: 0.3958 - val_accuracy: 0.8511\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8711 - val_loss: 0.4113 - val_accuracy: 0.8458\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3407 - accuracy: 0.8725 - val_loss: 0.3893 - val_accuracy: 0.8546\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3367 - accuracy: 0.8723 - val_loss: 0.3849 - val_accuracy: 0.8566\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3249 - accuracy: 0.8778 - val_loss: 0.3845 - val_accuracy: 0.8570\n","Layer 3\n","HICO LENGTH\n","4\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5373 - accuracy: 0.8226 - val_loss: 0.3943 - val_accuracy: 0.8560\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3240 - accuracy: 0.8784 - val_loss: 0.3820 - val_accuracy: 0.8615\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3185 - accuracy: 0.8794 - val_loss: 0.3777 - val_accuracy: 0.8590\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3108 - accuracy: 0.8831 - val_loss: 0.3752 - val_accuracy: 0.8603\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3070 - accuracy: 0.8843 - val_loss: 0.3736 - val_accuracy: 0.8619\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 2s 2ms/step - loss: 0.4905 - accuracy: 0.8359 - val_loss: 0.3805 - val_accuracy: 0.8609\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3229 - accuracy: 0.8782 - val_loss: 0.3784 - val_accuracy: 0.8606\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3139 - accuracy: 0.8813 - val_loss: 0.3822 - val_accuracy: 0.8559\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3203 - accuracy: 0.8774 - val_loss: 0.3737 - val_accuracy: 0.8644\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3115 - accuracy: 0.8818 - val_loss: 0.3835 - val_accuracy: 0.8596\n","Model 2\n","Epoch 1/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5810 - accuracy: 0.8142 - val_loss: 0.3949 - val_accuracy: 0.8541\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8768 - val_loss: 0.3841 - val_accuracy: 0.8582\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3192 - accuracy: 0.8796 - val_loss: 0.3772 - val_accuracy: 0.8609\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3198 - accuracy: 0.8786 - val_loss: 0.3828 - val_accuracy: 0.8620\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3127 - accuracy: 0.8836 - val_loss: 0.3804 - val_accuracy: 0.8651\n","Model 3\n","Epoch 1/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.6097 - accuracy: 0.8109 - val_loss: 0.3804 - val_accuracy: 0.8626\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8780 - val_loss: 0.3872 - val_accuracy: 0.8603\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3160 - accuracy: 0.8804 - val_loss: 0.3861 - val_accuracy: 0.8594\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3179 - accuracy: 0.8782 - val_loss: 0.3782 - val_accuracy: 0.8622\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3141 - accuracy: 0.8819 - val_loss: 0.3734 - val_accuracy: 0.8620\n","Layer 4\n","HICO LENGTH\n","5\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5534 - accuracy: 0.8292 - val_loss: 0.3789 - val_accuracy: 0.8614\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3169 - accuracy: 0.8811 - val_loss: 0.3815 - val_accuracy: 0.8607\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8815 - val_loss: 0.3782 - val_accuracy: 0.8609\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3084 - accuracy: 0.8847 - val_loss: 0.3770 - val_accuracy: 0.8601\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3111 - accuracy: 0.8818 - val_loss: 0.3780 - val_accuracy: 0.8610\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.8308 - val_loss: 0.3918 - val_accuracy: 0.8608\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3178 - accuracy: 0.8810 - val_loss: 0.3859 - val_accuracy: 0.8558\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3106 - accuracy: 0.8825 - val_loss: 0.3759 - val_accuracy: 0.8640\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3109 - accuracy: 0.8813 - val_loss: 0.3793 - val_accuracy: 0.8618\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3078 - accuracy: 0.8833 - val_loss: 0.3751 - val_accuracy: 0.8629\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4ZCjVj0ioNb6"},"source":["## Model Evaluation"]},{"cell_type":"code","metadata":{"id":"-wsBlIBONSIN","executionInfo":{"status":"ok","timestamp":1620611085027,"user_tz":-480,"elapsed":269354,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = np.argmax(hico_layers[0][j][0].predict(X_test_cropped_list[j]), axis=1)\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = np.argmax(hico_layers[i][j][0].predict(X_test_input), axis=1)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting (mode)\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0))\n","y_pred_list = stats.mode(y_pred_list, axis=1)[0]\n","y_pred_list = np.squeeze(y_pred_list)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"hn8WGeu-rl-U","executionInfo":{"status":"ok","timestamp":1620611085702,"user_tz":-480,"elapsed":270024,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["y_test = np.argmax(y_test_one_hot, axis=1)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZ6nor6wRK_k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620611085702,"user_tz":-480,"elapsed":270020,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"853e5308-69bc-44ba-8654-c6f4332f0d85"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8609"]},"metadata":{"tags":[]},"execution_count":15}]}]}