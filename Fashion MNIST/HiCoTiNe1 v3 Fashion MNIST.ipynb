{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HiCoTiNe1 v3 Fashion MNIST.ipynb","provenance":[{"file_id":"19guF-U3KgRWG2yOuNYWGUTWs2FP2582B","timestamp":1615843192315}],"collapsed_sections":[],"authorship_tag":"ABX9TyNjXtQ32bIkjAPMSnEAeUJT"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OVQ7Bo8hJIUb"},"source":["# Variants-Experiment 3.1, 3.2, 3.3.1, 3.3.2. Adapted from HiCoTiNe v2.1\n","## Concatenated hidden representations.\n","## No raw input"]},{"cell_type":"code","metadata":{"id":"AW5zp22ze_5Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620640362746,"user_tz":-480,"elapsed":1068,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"9b05f04d-0c4a-49df-da05-f7218a57cdd6"},"source":["from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten\n","from keras.datasets import mnist\n","from keras.utils import to_categorical\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import random\n","from scipy import stats\n","from sklearn.metrics import accuracy_score\n","from keras import backend as K\n","\n","import os\n","import pickle\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pL2zNY1Pqo43","executionInfo":{"status":"ok","timestamp":1620640362746,"user_tz":-480,"elapsed":1056,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["SUB_REGION_SCALE = 14\n","NUM_HICO_LAYER = 5\n","NUM_TN = [10, 8, 6 , 4, 2]\n","NUM_CONNECTION = [0, 5, 4, 3, 2]\n","ALPHA = 0.1\n","\n","#dataset specific parameters\n","NUM_CLASS = 10"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sV1QzfMXoD_c"},"source":["## Data Pre-Processing"]},{"cell_type":"code","metadata":{"id":"CK8Jo8eFjW0R","executionInfo":{"status":"ok","timestamp":1620640374301,"user_tz":-480,"elapsed":12605,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["with open('/content/drive/My Drive/fyp/Fashion MNIST.pickle', 'rb') as f:\n","    X_train_cropped_list, y_train_one_hot, X_test_cropped_list, y_test_one_hot, coordinate_list, scale_list = pickle.load(f)"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NYkFwl7RbAnt"},"source":["## HiCo Layer 1"]},{"cell_type":"code","metadata":{"id":"mZxSK0dGZsGo","executionInfo":{"status":"ok","timestamp":1620640374779,"user_tz":-480,"elapsed":13078,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["#build ANN model\n","ensemble = []\n","for i in range(NUM_TN[0]):\n","  model = Sequential()\n","  model.add(Dense(64, activation='relu', input_dim=SUB_REGION_SCALE*SUB_REGION_SCALE))\n","  model.add(Dense(64, activation='relu'))\n","  model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","  ensemble.append((model, i, coordinate_list[i], scale_list[i]))"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"D2K4jfWOkcSz","executionInfo":{"status":"ok","timestamp":1620640374780,"user_tz":-480,"elapsed":13073,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["for i in range(NUM_TN[0]):\n","  ensemble[i][0].load_weights('/content/drive/My Drive/fyp/Fashion MNIST_' + str(i) + '.h5')"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"-r3DBZWMb9eX","executionInfo":{"status":"ok","timestamp":1620640374781,"user_tz":-480,"elapsed":13069,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["hico_layers = []\n","hico_layers.append(ensemble)"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"-AKc-KKMj278","executionInfo":{"status":"ok","timestamp":1620640374781,"user_tz":-480,"elapsed":13064,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["del hico_layers[1:]"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CvSwQtBibHqz"},"source":["## HiCo Layer 2+"]},{"cell_type":"code","metadata":{"id":"MCxjRA6lqoaA","executionInfo":{"status":"ok","timestamp":1620640374782,"user_tz":-480,"elapsed":13059,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Function to get input of layer i-1\n","def get_previous_layer_input(hico_layers, layer, tn, train_image):\n","  input = []\n","    \n","  if layer == 0:\n","    previous_layer_input = train_image[tn[1]]\n","    return previous_layer_input\n","\n","  elif layer > 0:\n","    for i in range(NUM_CONNECTION[layer]):\n","      get_input = (K.function(hico_layers[layer-1][tn[1][i]][0].layers[0].input, hico_layers[layer-1][tn[1][i]][0].layers[1].output))\n","      input.append(get_input(get_previous_layer_input(hico_layers, layer-1, hico_layers[layer-1][tn[1][i]], train_image)))\n","      \n","    input = np.array(input)\n","    input = np.concatenate(input, axis=1)\n","    previous_layer_input = input\n","    return previous_layer_input"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZLXI5D6lneY","executionInfo":{"status":"ok","timestamp":1620640608527,"user_tz":-480,"elapsed":246797,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"ceb95e3b-11e1-45fa-d3c1-5d36dc4760bb"},"source":["for i in range(1, NUM_HICO_LAYER):\n","  print('Layer %d' %i)\n","  ensemble = []\n","  X_train_input_list = []\n","  X_test_input_list = []\n","\n","  for j in range(NUM_TN[i]):\n","    # Build model of HiCo layer i\n","    connection = tuple(random.sample(range(len(hico_layers[i-1])), k=NUM_CONNECTION[i]))\n","    model = Sequential()\n","    model.add(Dense(64, activation='relu', input_dim=64*NUM_CONNECTION[i]))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dense(NUM_CLASS, activation = 'softmax'))\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","    ensemble.append((model, connection))\n","  hico_layers.append(ensemble)\n","  print('HICO LENGTH')\n","  print(len(hico_layers))\n","\n","  for j in range(NUM_TN[i]):\n","    # Get train hidden representation from HiCo layer i-1\n","    X_train_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_train_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_train_cropped_list)))\n","    X_train_input = np.array(X_train_input)\n","    X_train_input = np.concatenate(X_train_input, axis=1)\n","    X_train_input_list.append(X_train_input)\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    X_test_input_list.append(X_test_input)\n","\n","  #train model of HiCo layer i\n","  for j in range(NUM_TN[i]):\n","    print('Model %d' %j)\n","    hico_layers[i][j][0].fit(X_train_input_list[j], y_train_one_hot, validation_data=(X_test_input_list[j], y_test_one_hot), epochs=5, batch_size=128)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["Layer 1\n","HICO LENGTH\n","2\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.7436 - accuracy: 0.7338 - val_loss: 0.4807 - val_accuracy: 0.8229\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4535 - accuracy: 0.8275 - val_loss: 0.4818 - val_accuracy: 0.8207\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.8365 - val_loss: 0.4703 - val_accuracy: 0.8249\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4192 - accuracy: 0.8410 - val_loss: 0.4510 - val_accuracy: 0.8337\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4043 - accuracy: 0.8509 - val_loss: 0.4402 - val_accuracy: 0.8367\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.7060 - accuracy: 0.7483 - val_loss: 0.4749 - val_accuracy: 0.8288\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4412 - accuracy: 0.8350 - val_loss: 0.4545 - val_accuracy: 0.8302\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4170 - accuracy: 0.8448 - val_loss: 0.4417 - val_accuracy: 0.8358\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4031 - accuracy: 0.8492 - val_loss: 0.4308 - val_accuracy: 0.8396\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3941 - accuracy: 0.8519 - val_loss: 0.4245 - val_accuracy: 0.8424\n","Model 2\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.7240 - accuracy: 0.7442 - val_loss: 0.4889 - val_accuracy: 0.8194\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.8365 - val_loss: 0.4544 - val_accuracy: 0.8266\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4069 - accuracy: 0.8466 - val_loss: 0.4304 - val_accuracy: 0.8385\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4059 - accuracy: 0.8463 - val_loss: 0.4309 - val_accuracy: 0.8394\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3859 - accuracy: 0.8531 - val_loss: 0.4423 - val_accuracy: 0.8374\n","Model 3\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.6976 - accuracy: 0.7582 - val_loss: 0.4461 - val_accuracy: 0.8346\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4039 - accuracy: 0.8484 - val_loss: 0.4473 - val_accuracy: 0.8330\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8534 - val_loss: 0.4205 - val_accuracy: 0.8445\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3727 - accuracy: 0.8596 - val_loss: 0.4171 - val_accuracy: 0.8463\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3679 - accuracy: 0.8611 - val_loss: 0.4163 - val_accuracy: 0.8441\n","Model 4\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.7538 - accuracy: 0.7314 - val_loss: 0.4865 - val_accuracy: 0.8210\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4570 - accuracy: 0.8303 - val_loss: 0.4632 - val_accuracy: 0.8280\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4307 - accuracy: 0.8380 - val_loss: 0.4573 - val_accuracy: 0.8361\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4095 - accuracy: 0.8496 - val_loss: 0.4390 - val_accuracy: 0.8361\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4045 - accuracy: 0.8497 - val_loss: 0.4590 - val_accuracy: 0.8310\n","Model 5\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.6896 - accuracy: 0.7567 - val_loss: 0.4535 - val_accuracy: 0.8305\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.4169 - accuracy: 0.8458 - val_loss: 0.4321 - val_accuracy: 0.8421\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3888 - accuracy: 0.8545 - val_loss: 0.4459 - val_accuracy: 0.8324\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3873 - accuracy: 0.8566 - val_loss: 0.4242 - val_accuracy: 0.8424\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3731 - accuracy: 0.8601 - val_loss: 0.4329 - val_accuracy: 0.8341\n","Model 6\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.7071 - accuracy: 0.7512 - val_loss: 0.4432 - val_accuracy: 0.8348\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4039 - accuracy: 0.8508 - val_loss: 0.4291 - val_accuracy: 0.8385\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3717 - accuracy: 0.8604 - val_loss: 0.4325 - val_accuracy: 0.8381\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3649 - accuracy: 0.8617 - val_loss: 0.4127 - val_accuracy: 0.8464\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3552 - accuracy: 0.8661 - val_loss: 0.4105 - val_accuracy: 0.8466\n","Model 7\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.6688 - accuracy: 0.7662 - val_loss: 0.4601 - val_accuracy: 0.8250\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.4049 - accuracy: 0.8489 - val_loss: 0.4494 - val_accuracy: 0.8302\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3815 - accuracy: 0.8567 - val_loss: 0.4183 - val_accuracy: 0.8491\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3672 - accuracy: 0.8638 - val_loss: 0.4075 - val_accuracy: 0.8457\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3636 - accuracy: 0.8629 - val_loss: 0.4081 - val_accuracy: 0.8482\n","Layer 2\n","HICO LENGTH\n","3\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5810 - accuracy: 0.8124 - val_loss: 0.4285 - val_accuracy: 0.8392\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3512 - accuracy: 0.8697 - val_loss: 0.3981 - val_accuracy: 0.8526\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3397 - accuracy: 0.8724 - val_loss: 0.3916 - val_accuracy: 0.8544\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3343 - accuracy: 0.8732 - val_loss: 0.3952 - val_accuracy: 0.8511\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8743 - val_loss: 0.3995 - val_accuracy: 0.8538\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5217 - accuracy: 0.8169 - val_loss: 0.3999 - val_accuracy: 0.8545\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3404 - accuracy: 0.8727 - val_loss: 0.3908 - val_accuracy: 0.8575\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8731 - val_loss: 0.3925 - val_accuracy: 0.8530\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8767 - val_loss: 0.3868 - val_accuracy: 0.8577\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8750 - val_loss: 0.3886 - val_accuracy: 0.8578\n","Model 2\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5367 - accuracy: 0.8171 - val_loss: 0.3995 - val_accuracy: 0.8529\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8701 - val_loss: 0.3980 - val_accuracy: 0.8526\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8743 - val_loss: 0.4031 - val_accuracy: 0.8508\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3401 - accuracy: 0.8738 - val_loss: 0.4125 - val_accuracy: 0.8507\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3358 - accuracy: 0.8743 - val_loss: 0.3833 - val_accuracy: 0.8563\n","Model 3\n","Epoch 1/5\n","469/469 [==============================] - 3s 4ms/step - loss: 0.5946 - accuracy: 0.8113 - val_loss: 0.4048 - val_accuracy: 0.8496\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3440 - accuracy: 0.8703 - val_loss: 0.4024 - val_accuracy: 0.8540\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3382 - accuracy: 0.8738 - val_loss: 0.3916 - val_accuracy: 0.8557\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3302 - accuracy: 0.8756 - val_loss: 0.3892 - val_accuracy: 0.8553\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8765 - val_loss: 0.4068 - val_accuracy: 0.8512\n","Model 4\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5223 - accuracy: 0.8208 - val_loss: 0.4029 - val_accuracy: 0.8499\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3451 - accuracy: 0.8701 - val_loss: 0.3940 - val_accuracy: 0.8535\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3345 - accuracy: 0.8750 - val_loss: 0.3942 - val_accuracy: 0.8559\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3335 - accuracy: 0.8753 - val_loss: 0.3990 - val_accuracy: 0.8500\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3357 - accuracy: 0.8736 - val_loss: 0.3861 - val_accuracy: 0.8562\n","Model 5\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.6598 - accuracy: 0.7862 - val_loss: 0.3981 - val_accuracy: 0.8534\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3425 - accuracy: 0.8708 - val_loss: 0.3853 - val_accuracy: 0.8587\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3347 - accuracy: 0.8730 - val_loss: 0.3834 - val_accuracy: 0.8581\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3238 - accuracy: 0.8783 - val_loss: 0.3938 - val_accuracy: 0.8536\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3178 - accuracy: 0.8785 - val_loss: 0.3885 - val_accuracy: 0.8546\n","Layer 3\n","HICO LENGTH\n","4\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5418 - accuracy: 0.8297 - val_loss: 0.3891 - val_accuracy: 0.8556\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8809 - val_loss: 0.3858 - val_accuracy: 0.8563\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3195 - accuracy: 0.8789 - val_loss: 0.3911 - val_accuracy: 0.8587\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3186 - accuracy: 0.8794 - val_loss: 0.3884 - val_accuracy: 0.8562\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3178 - accuracy: 0.8797 - val_loss: 0.3876 - val_accuracy: 0.8520\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5539 - accuracy: 0.8187 - val_loss: 0.4005 - val_accuracy: 0.8543\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8784 - val_loss: 0.3880 - val_accuracy: 0.8573\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8796 - val_loss: 0.3844 - val_accuracy: 0.8554\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3165 - accuracy: 0.8795 - val_loss: 0.3898 - val_accuracy: 0.8568\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3161 - accuracy: 0.8794 - val_loss: 0.3845 - val_accuracy: 0.8577\n","Model 2\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5999 - accuracy: 0.8117 - val_loss: 0.3823 - val_accuracy: 0.8575\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3220 - accuracy: 0.8794 - val_loss: 0.3901 - val_accuracy: 0.8556\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3269 - accuracy: 0.8768 - val_loss: 0.3865 - val_accuracy: 0.8587\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3143 - accuracy: 0.8817 - val_loss: 0.3757 - val_accuracy: 0.8615\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3105 - accuracy: 0.8808 - val_loss: 0.3829 - val_accuracy: 0.8585\n","Model 3\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.6610 - accuracy: 0.8007 - val_loss: 0.4041 - val_accuracy: 0.8495\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8759 - val_loss: 0.3840 - val_accuracy: 0.8553\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8777 - val_loss: 0.3848 - val_accuracy: 0.8576\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3197 - accuracy: 0.8795 - val_loss: 0.3854 - val_accuracy: 0.8590\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.8789 - val_loss: 0.3843 - val_accuracy: 0.8575\n","Layer 4\n","HICO LENGTH\n","5\n","Model 0\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.6006 - accuracy: 0.8098 - val_loss: 0.3950 - val_accuracy: 0.8574\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3200 - accuracy: 0.8793 - val_loss: 0.3851 - val_accuracy: 0.8601\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3089 - accuracy: 0.8839 - val_loss: 0.3810 - val_accuracy: 0.8579\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3144 - accuracy: 0.8808 - val_loss: 0.3829 - val_accuracy: 0.8577\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3056 - accuracy: 0.8839 - val_loss: 0.3871 - val_accuracy: 0.8602\n","Model 1\n","Epoch 1/5\n","469/469 [==============================] - 2s 3ms/step - loss: 0.5661 - accuracy: 0.8193 - val_loss: 0.3875 - val_accuracy: 0.8553\n","Epoch 2/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3135 - accuracy: 0.8812 - val_loss: 0.3825 - val_accuracy: 0.8574\n","Epoch 3/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3129 - accuracy: 0.8815 - val_loss: 0.3848 - val_accuracy: 0.8590\n","Epoch 4/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3148 - accuracy: 0.8808 - val_loss: 0.3770 - val_accuracy: 0.8600\n","Epoch 5/5\n","469/469 [==============================] - 1s 2ms/step - loss: 0.3081 - accuracy: 0.8823 - val_loss: 0.3820 - val_accuracy: 0.8584\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4ZCjVj0ioNb6"},"source":["## Model Evaluation"]},{"cell_type":"code","metadata":{"id":"hn8WGeu-rl-U","executionInfo":{"status":"ok","timestamp":1620640608529,"user_tz":-480,"elapsed":246793,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["y_test = np.argmax(y_test_one_hot, axis=1)"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5hLPV9-XgZcY"},"source":["### HiCoTiNe1 v3.1\n","cc1. Mode. Compute classifications of all tiny networks, in all HiCo layers, and take the mode as the final classification."]},{"cell_type":"code","metadata":{"id":"-wsBlIBONSIN","executionInfo":{"status":"ok","timestamp":1620640636085,"user_tz":-480,"elapsed":274343,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = np.argmax(hico_layers[0][j][0].predict(X_test_cropped_list[j]), axis=1)\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = np.argmax(hico_layers[i][j][0].predict(X_test_input), axis=1)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0))\n","y_pred_list = stats.mode(y_pred_list, axis=1)[0]\n","y_pred_list = np.squeeze(y_pred_list)"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"HZ6nor6wRK_k","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620640636085,"user_tz":-480,"elapsed":274337,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"eb644c26-6977-420f-8ab4-133ff95ccabe"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8583"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"markdown","metadata":{"id":"kSjNM3tzg4C9"},"source":["### HiCoTiNe v3.2\n","cc2. Sum the logits of all TNs. Take the max logit as the final classification."]},{"cell_type":"code","metadata":{"id":"7AKpmhMtg-IX","executionInfo":{"status":"ok","timestamp":1620640662430,"user_tz":-480,"elapsed":300675,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = hico_layers[0][j][0].predict(X_test_cropped_list[j])\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = hico_layers[i][j][0].predict(X_test_input)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0, 2))\n","y_pred_list = np.argmax(np.sum(y_pred_list, axis=1), axis=1)"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3AmcOiQh4QM","executionInfo":{"status":"ok","timestamp":1620640662439,"user_tz":-480,"elapsed":300679,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"fe1eb906-2bb9-4218-86c7-7405fc19f305"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8605"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"EvqdeEpVo0IU"},"source":["### HiCoTiNe v3.3.1\n","cc3. Weighted function. Compute classifications (votes) of all tiny networks, in all HiCo layers. Compute weight of each classifier/vote. Compute weighted sum of votes. Weights can be computed in different ways, e.g.:\n","- cc3w1. The weight of each classifier/TN is inversely proportional to the number of TNs in its HiCo layer, relative to the HiCo layer with the most TNs. E.g. if n is the number of TNs in the layer with the most TNs, then compute v/n for each layer, where v is the number of TNs in each layer; then compute the weight of each layer as (1+alpha)-(v/n), where alpha is some small threshold; and finally define the weight of each TN as the weight of its layer.\n"]},{"cell_type":"code","metadata":{"id":"1E2-2iH5pIzI","executionInfo":{"status":"ok","timestamp":1620640689302,"user_tz":-480,"elapsed":327534,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = hico_layers[0][j][0].predict(X_test_cropped_list[j])\n","  y_pred = y_pred * ((1 + ALPHA) - (NUM_TN[0] / max(NUM_TN)))\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = hico_layers[i][j][0].predict(X_test_input)\n","    y_pred = y_pred * ((1 + ALPHA) - (NUM_TN[i] / max(NUM_TN)))\n","    y_pred_list.append(y_pred)\n","\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0, 2))\n","y_pred_list = np.argmax(np.sum(y_pred_list, axis=1), axis=1)"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K2HPvU_NvSvT","executionInfo":{"status":"ok","timestamp":1620640689305,"user_tz":-480,"elapsed":327529,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"2eb7adc5-00b9-439f-8cbf-53eb0a013600"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8612"]},"metadata":{"tags":[]},"execution_count":54}]},{"cell_type":"markdown","metadata":{"id":"lCCv0nO9pJnb"},"source":["### HiCoTiNe v3.3.2\n","cc3. Weighted function. Compute classifications (votes) of all tiny networks, in all HiCo layers. Compute weight of each classifier/vote. Compute weighted sum of votes. Weights can be computed in different ways, e.g.:\n","- cc3w2. The weight of each classifier is directly proportional to the depth of the HiCo layer within which it resides. \n"]},{"cell_type":"code","metadata":{"id":"YqBbgiRqpQeC","executionInfo":{"status":"ok","timestamp":1620640715827,"user_tz":-480,"elapsed":354043,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}}},"source":["# Predict on test image\n","y_pred_list = []\n","for j in range(NUM_TN[0]):\n","  y_pred = hico_layers[0][j][0].predict(X_test_cropped_list[j])\n","  y_pred = y_pred * (1 / NUM_HICO_LAYER)\n","  y_pred_list.append(y_pred)\n","\n","for i in range(1, NUM_HICO_LAYER):\n","  for j in range(NUM_TN[i]):\n","\n","    # Get test hidden representation from HiCo layer i-1\n","    X_test_input = []\n","    for k in range(NUM_CONNECTION[i]):\n","      get_input = (K.function(hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[0].input, hico_layers[i-1][hico_layers[i][j][1][k]][0].layers[1].output))\n","      X_test_input.append(get_input(get_previous_layer_input(hico_layers, i-1, hico_layers[i-1][hico_layers[i][j][1][k]], X_test_cropped_list)))\n","    X_test_input = np.array(X_test_input)\n","    X_test_input = np.concatenate(X_test_input, axis=1)\n","    y_pred = hico_layers[i][j][0].predict(X_test_input)\n","    y_pred = y_pred * (i / NUM_HICO_LAYER)\n","    y_pred_list.append(y_pred)\n","\n","# HiCo voting\n","y_pred_list = np.array(y_pred_list)\n","y_pred_list = np.transpose(y_pred_list, (1, 0, 2))\n","y_pred_list = np.argmax(np.sum(y_pred_list, axis=1), axis=1)"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfK2nrhzdX-e","executionInfo":{"status":"ok","timestamp":1620640715828,"user_tz":-480,"elapsed":354038,"user":{"displayName":"eg","photoUrl":"https://lh3.googleusercontent.com/-8La9cm4PmPY/AAAAAAAAAAI/AAAAAAAAg4o/vZYgtM9yN3A/s64/photo.jpg","userId":"00406320900359727475"}},"outputId":"b368970d-0241-4ed0-8c45-911e0585e126"},"source":["accuracy = accuracy_score(y_test, y_pred_list)\n","accuracy"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8612"]},"metadata":{"tags":[]},"execution_count":56}]}]}